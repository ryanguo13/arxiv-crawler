id         ,title                                                                                                                                                                                   ,categories                                               ,abstract                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ,doi                                                                     ,created    ,updated    ,authors
1708.02190 ,intrinsically motivated goal exploration processes with automatic   curriculum learning                                                                                                 ,cs.ai cs.lg                                              ,"intrinsically motivated spontaneous exploration is a key enabler of autonomous developmental learning in human children. it enables the discovery of skill repertoires through autotelic learning, i.e. the self-generation, self-selection, self-ordering and self-experimentation of learning goals. we present an algorithmic approach called intrinsically motivated goal exploration processes (imgep) to enable similar properties of autonomous learning in machines. the imgep architecture relies on several principles: 1) self-generation of goals, generalized as parameterized fitness functions; 2) selection of goals based on intrinsic rewards; 3) exploration with incremental goal-parameterized policy search and exploitation with a batch learning algorithm; 4) systematic reuse of information acquired when targeting a goal for improving towards other goals. we present a particularly efficient form of imgep, called amb, that uses a population-based policy and an object-centered spatio-temporal modularity. we provide several implementations of this architecture and demonstrate their ability to automatically generate a learning curriculum within several experimental setups. one of these experiments includes a real humanoid robot exploring multiple spaces of goals with several hundred continuous dimensions and with distractors. while no particular target goal is provided to these autotelic agents, this curriculum allows the discovery of diverse skills that act as stepping stones for learning more complex skills, e.g. nested tool use."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ,                                                                        ,2017-08-07 ,2022-05-05 ,"['sébastien forestier', 'rémy portelas', 'yoan mollard', 'pierre-yves oudeyer']"
1809.03225 ,gait learning for soft microrobots controlled by light fields                                                                                                                           ,cs.ro cs.lg cs.sy                                        ,"soft microrobots based on photoresponsive materials and controlled by light fields can generate a variety of different gaits. this inherent flexibility can be exploited to maximize their locomotion performance in a given environment and used to adapt them to changing conditions. albeit, because of the lack of accurate locomotion models, and given the intrinsic variability among microrobots, analytical control design is not possible. common data-driven approaches, on the other hand, require running prohibitive numbers of experiments and lead to very sample-specific results. here we propose a probabilistic learning approach for light-controlled soft microrobots based on bayesian optimization (bo) and gaussian processes (gps). the proposed approach results in a learning scheme that is data-efficient, enabling gait optimization with a limited experimental budget, and robust against differences among microrobot samples. these features are obtained by designing the learning scheme through the comparison of different gp priors and bo settings on a semi-synthetic data set. the developed learning scheme is validated in microrobot experiments, resulting in a 115% improvement in a microrobot's locomotion performance with an experimental budget of only 20 tests. these encouraging results lead the way toward self-adaptive microrobotic systems based on light-controlled soft microrobots and probabilistic learning control."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ,10.1109/iros.2018.8594092                                               ,2018-09-10 ,           ,"['alexander von rohr', 'sebastian trimpe', 'alonso marco', 'peer fischer', 'stefano palagi']"
1904.00942 ,controlling for biasing signals in images for prognostic models:   survival predictions for lung cancer with deep learning                                                              ,cs.lg stat.ml                                            ,"deep learning has shown remarkable results for image analysis and is expected to aid individual treatment decisions in health care. to achieve this, deep learning methods need to be promoted from the level of mere associations to being able to answer causal questions. we present a scenario with real-world medical images (ct-scans of lung cancers) and simulated outcome data. through the sampling scheme, the images contain two distinct factors of variation that represent a collider and a prognostic factor. we show that when this collider can be quantified, unbiased individual prognosis predictions are attainable with deep learning. this is achieved by (1) setting a dual task for the network to predict both the outcome and the collider and (2) enforcing independence of the activation distributions of the last layer with ordinary least squares. our method provides an example of combining deep learning and structural causal models for unbiased individual prognosis predictions."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,10.1038/s41746-019-0194-x                                               ,2019-04-01 ,           ,"['wouter a. c. van amsterdam', 'marinus j. c. eijkemans']"
1906.04675 ,taxonomy of saliency metrics for channel pruning                                                                                                                                        ,cs.lg stat.ml                                            ,"pruning unimportant parameters can allow deep neural networks (dnns) to reduce their heavy computation and memory requirements. a saliency metric estimates which parameters can be safely pruned with little impact on the classification performance of the dnn. many saliency metrics have been proposed, each within the context of a wider pruning algorithm. the result is that it is difficult to separate the effectiveness of the saliency metric from the wider pruning algorithm that surrounds it. similar-looking saliency metrics can yield very different results because of apparently minor design choices. we propose a taxonomy of saliency metrics based on four mostly-orthogonal principal components. we show that a broad range of metrics from the pruning literature can be grouped according to these components. our taxonomy not only serves as a guide to prior work, but allows us to construct new saliency metrics by exploring novel combinations of our taxonomic components. we perform an in-depth experimental investigation of more than 300 saliency metrics. our results provide decisive answers to open research questions, and demonstrate the importance of reduction and scaling when pruning groups of weights. we find that some of our constructed metrics can outperform the best existing state-of-the-art metrics for convolutional neural network channel pruning."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,10.1109/access.2021.3108545                                             ,2019-06-11 ,2021-07-04 ,"['kaveena persand', 'andrew anderson', 'david gregg']"
1909.00426 ,global entity disambiguation with bert                                                                                                                                                  ,cs.cl cs.lg                                              ,"we propose a global entity disambiguation (ed) model based on bert. to capture global contextual information for ed, our model treats not only words but also entities as input tokens, and solves the task by sequentially resolving mentions to their referent entities and using resolved entities as inputs at each step. we train the model using a large entity-annotated corpus obtained from wikipedia. we achieve new state-of-the-art results on five standard ed datasets: aida-conll, msnbc, aquaint, ace2004, and wned-wiki. the source code and model checkpoint are available at https://github.com/studio-ousia/luke."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,                                                                        ,2019-09-01 ,2022-05-01 ,"['ikuya yamada', 'koki washio', 'hiroyuki shindo', 'yuji matsumoto']"
1910.01713 ,reds: rule extraction for discovering scenarios                                                                                                                                         ,cs.lg stat.ml                                            ,"scenario discovery is the process of finding areas of interest, known as scenarios, in data spaces resulting from simulations. for instance, one might search for conditions, i.e., inputs of the simulation model, where the system is unstable. subgroup discovery methods are commonly used for scenario discovery. they find scenarios in the form of hyperboxes, which are easy to comprehend. given a computational budget, results tend to get worse as the number of inputs of the simulation model and the cost of simulations increase. we propose a new procedure for scenario discovery from few simulations, dubbed reds. a key ingredient is using an intermediate machine learning model to label data for subsequent use by conventional subgroup discovery methods. we provide statistical arguments why this is an improvement. in our experiments, reds reduces the number of simulations required by 50--75\% on average, depending on the quality measure. it is also useful as a semi-supervised subgroup discovery method and for discovering better scenarios from third-party data, when a simulation model is not available."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ,10.1145/3448016.3457301                                                 ,2019-10-03 ,2022-05-05 ,"['vadim arzamasov', 'klemens böhm']"
1910.02760 ,negative sampling in variational autoencoders                                                                                                                                           ,cs.lg stat.ml                                            ,"modern deep artificial neural networks have achieved great success in the domain of computer vision and beyond. however, their application to many real-world tasks is undermined by certain limitations, such as overconfident uncertainty estimates on out-of-distribution data or performance deterioration under data distribution shifts. several types of deep learning models used for density estimation through probabilistic generative modeling have been shown to fail to detect out-of-distribution samples by assigning higher likelihoods to anomalous data. we investigate this failure mode in variational autoencoder models, which are also prone to this, and improve upon the out-of-distribution generalization performance of the model by employing an alternative training scheme utilizing negative samples. we present a fully unsupervised version: when the model is trained in an adversarial manner, the generator's own outputs can be used as negative samples. we demonstrate empirically the effectiveness of the approach in reducing the overconfident likelihood estimates of out-of-distribution inputs on image data."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ,                                                                        ,2019-10-07 ,2022-05-04 ,"['adrián csiszárik', 'beatrix benkő', 'dániel varga']"
1910.05954 ,quantitative stability of optimal transport maps and linearization of   the 2-wasserstein space                                                                                         ,stat.ml cs.lg cs.na math.mg math.na                      ,"this work studies an explicit embedding of the set of probability measures into a hilbert space, defined using optimal transport maps from a reference probability density. this embedding linearizes to some extent the 2-wasserstein space, and enables the direct use of generic supervised and unsupervised learning algorithms on measure data. our main result is that the embedding is (bi-)h\""older continuous, when the reference density is uniform over a convex set, and can be equivalently phrased as a dimension-independent h\""older-stability results for optimal transport maps."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,                                                                        ,2019-10-14 ,           ,"['quentin mérigot', 'alex delalande', 'frédéric chazal']"
1910.13213 ,overcoming catastrophic interference in online reinforcement learning   with dynamic self-organizing maps                                                                               ,cs.ai cs.lg                                              ,"using neural networks in the reinforcement learning (rl) framework has achieved notable successes. yet, neural networks tend to forget what they learned in the past, especially when they learn online and fully incrementally, a setting in which the weights are updated after each sample is received and the sample is then discarded. under this setting, an update can lead to overly global generalization by changing too many weights. the global generalization interferes with what was previously learned and deteriorates performance, a phenomenon known as catastrophic interference. many previous works use mechanisms such as experience replay (er) buffers to mitigate interference by performing minibatch updates, ensuring the data distribution is approximately independent-and-identically-distributed (i.i.d.). but using er would become infeasible in terms of memory as problem complexity increases. thus, it is crucial to look for more memory-efficient alternatives. interference can be averted if we replace global updates with more local ones, so only weights responsible for the observed data sample are updated. in this work, we propose the use of dynamic self-organizing map (dsom) with neural networks to induce such locality in the updates without er buffers. our method learns a dsom to produce a mask to reweigh each hidden unit's output, modulating its degree of use. it prevents interference by replacing global updates with local ones, conditioned on the agent's state. we validate our method on standard rl benchmarks including mountain car and lunar lander, where existing methods often fail to learn without er. empirically, we show that our online and fully incremental method is on par with and in some cases, better than state-of-the-art in terms of final performance and learning speed. we provide visualizations and quantitative measures to show that our method indeed mitigates interference."                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2019-10-29 ,           ,"['yat long lo', 'sina ghiassian']"
1911.07381 ,visual similarity attention                                                                                                                                                             ,cs.cv cs.lg                                              ,"while there has been substantial progress in learning suitable distance metrics, these techniques in general lack transparency and decision reasoning, i.e., explaining why the input set of images is similar or dissimilar. in this work, we solve this key problem by proposing the first method to generate generic visual similarity explanations with gradient-based attention. we demonstrate that our technique is agnostic to the specific similarity model type, e.g., we show applicability to siamese, triplet, and quadruplet models. furthermore, we make our proposed similarity attention a principled part of the learning process, resulting in a new paradigm for learning similarity functions. we demonstrate that our learning mechanism results in more generalizable, as well as explainable, similarity models. finally, we demonstrate the generality of our framework by means of experiments on a variety of tasks, including image retrieval, person re-identification, and low-shot semantic segmentation."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2019-11-17 ,2022-05-03 ,"['meng zheng', 'srikrishna karanam', 'terrence chen', 'richard j. radke', 'ziyan wu']"
1911.09032 ,outside the box: abstraction-based monitoring of neural networks                                                                                                                        ,cs.lg cs.ai cs.lo stat.ml                                ,"neural networks have demonstrated unmatched performance in a range of classification tasks. despite numerous efforts of the research community, novelty detection remains one of the significant limitations of neural networks. the ability to identify previously unseen inputs as novel is crucial for our understanding of the decisions made by neural networks. at runtime, inputs not falling into any of the categories learned during training cannot be classified correctly by the neural network. existing approaches treat the neural network as a black box and try to detect novel inputs based on the confidence of the output predictions. however, neural networks are not trained to reduce their confidence for novel inputs, which limits the effectiveness of these approaches. we propose a framework to monitor a neural network by observing the hidden layers. we employ a common abstraction from program analysis - boxes - to identify novel behaviors in the monitored layers, i.e., inputs that cause behaviors outside the box. for each neuron, the boxes range over the values seen in training. the framework is efficient and flexible to achieve a desired trade-off between raising false warnings and detecting novel inputs. we illustrate the performance and the robustness to variability in the unknown classes on popular image-classification benchmarks."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,10.3233/faia200375                                                      ,2019-11-20 ,2020-02-19 ,"['thomas a. henzinger', 'anna lukina', 'christian schilling']"
1912.02655 ,obesity prediction with ehr data: a deep learning approach with   interpretable elements                                                                                                ,stat.ap cs.lg q-bio.qm                                   ,"childhood obesity is a major public health challenge. early prediction and identification of the children at a high risk of developing childhood obesity may help in engaging earlier and more effective interventions to prevent and manage obesity. most existing predictive tools for childhood obesity primarily rely on traditional regression-type methods using only a few hand-picked features and without exploiting longitudinal patterns of children data. deep learning methods allow the use of high-dimensional longitudinal datasets. in this paper, we present a deep learning model designed for predicting future obesity patterns from generally available items on children medical history. to do this, we use a large unaugmented electronic health records dataset from a large pediatric health system. we adopt a general lstm network architecture which are known to better represent the longitudinal data. we train our proposed model on both dynamic and static ehr data. our model is used to predict obesity for ages between 2-20 years. we compared the performance of our lstm model with other machine learning methods that aggregate over sequential data and ignore temporality. to add interpretability, we have additionally included an attention layer to calculate the attention scores for the timestamps and rank features of each timestamp."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,10.1145/3506719                                                         ,2019-12-05 ,2021-10-22 ,"['mehak gupta', 'thao-ly t. phan', 'timothy bunnell', 'rahmatollah beheshti']"
2002.03309 ,a physiology-driven computational model for post-cardiac arrest outcome   prediction                                                                                                    ,cs.lg stat.ml                                            ,"patients resuscitated from cardiac arrest (ca) face a high risk of neurological disability and death, however pragmatic methods are lacking for accurate and reliable prognostication. the aim of this study was to build computational models to predict post-ca outcome by leveraging high-dimensional patient data available early after admission to the intensive care unit (icu). we hypothesized that model performance could be enhanced by integrating physiological time series (pts) data and by training machine learning (ml) classifiers. we compared three models integrating features extracted from the electronic health records (ehr) alone, features derived from pts collected in the first 24hrs after icu admission (pts24), and models integrating pts24 and ehr. outcomes of interest were survival and neurological outcome at icu discharge. combined ehr-pts24 models had higher discrimination (area under the receiver operating characteristic curve [auc]) than models which used either ehr or pts24 alone, for the prediction of survival (auc 0.85, 0.80 and 0.68 respectively) and neurological outcome (0.87, 0.83 and 0.78). the best ml classifier achieved higher discrimination than the reference logistic regression model (apache iii) for survival (auc 0.85 vs 0.70) and neurological outcome prediction (auc 0.87 vs 0.75). feature analysis revealed previously unknown factors to be associated with post-ca recovery. results attest to the effectiveness of ml models for post-ca predictive modeling and suggest that pts recorded in very early phase after resuscitation encode short-term outcome probabilities."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,10.1016/j.accpm.2021.101015                                             ,2020-02-09 ,2020-02-11 ,"['han b. kim', 'hieu nguyen', 'qingchu jin', 'sharmila tamby', 'tatiana gelaf romer', 'eric sung', 'ran liu', 'joseph greenstein', 'jose i. suarez', 'christian storm', 'raimond winslow', 'robert d. stevens']"
2002.12815 ,few-shot learning on graphs via super-classes based on graph spectral   measures                                                                                                        ,cs.lg stat.ml                                            ,"we propose to study the problem of few shot graph classification in graph neural networks (gnns) to recognize unseen classes, given limited labeled graph examples. despite several interesting gnn variants being proposed recently for node and graph classification tasks, when faced with scarce labeled examples in the few shot setting, these gnns exhibit significant loss in classification performance. here, we present an approach where a probability measure is assigned to each graph based on the spectrum of the graphs normalized laplacian. this enables us to accordingly cluster the graph base labels associated with each graph into super classes, where the lp wasserstein distance serves as our underlying distance metric. subsequently, a super graph constructed based on the super classes is then fed to our proposed gnn framework which exploits the latent inter class relationships made explicit by the super graph to achieve better class label separation among the graphs. we conduct exhaustive empirical evaluations of our proposed method and show that it outperforms both the adaptation of state of the art graph classification methods to few shot scenario and our naive baseline gnns. additionally, we also extend and study the behavior of our method to semi supervised and active learning scenarios."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,                                                                        ,2020-02-27 ,           ,"['jatin chauhan', 'deepak nathani', 'manohar kaul']"
2003.01373 ,learning context-aware task reasoning for efficient meta-reinforcement   learning                                                                                                       ,cs.lg cs.ai stat.ml                                      ,"despite recent success of deep network-based reinforcement learning (rl), it remains elusive to achieve human-level efficiency in learning novel tasks. while previous efforts attempt to address this challenge using meta-learning strategies, they typically suffer from sampling inefficiency with on-policy rl algorithms or meta-overfitting with off-policy learning. in this work, we propose a novel meta-rl strategy to address those limitations. in particular, we decompose the meta-rl problem into three sub-tasks, task-exploration, task-inference and task-fulfillment, instantiated with two deep network agents and a task encoder. during meta-training, our method learns a task-conditioned actor network for task-fulfillment, an explorer network with a self-supervised reward shaping that encourages task-informative experiences in task-exploration, and a context-aware graph-based task encoder for task inference. we validate our approach with extensive experiments on several public benchmarks and the results show that our algorithm effectively performs exploration for task inference, improves sample efficiency during both training and testing, and mitigates the meta-overfitting problem."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,10.5555/3398761.3398927                                                 ,2020-03-03 ,2022-05-02 ,"['haozhe wang', 'jiale zhou', 'xuming he']"
2003.03274 ,dropout strikes back: improved uncertainty estimation via diversity   sampling                                                                                                          ,cs.lg stat.ml                                            ,"uncertainty estimation for machine learning models is of high importance in many scenarios such as constructing the confidence intervals for model predictions and detection of out-of-distribution or adversarially generated points. in this work, we show that modifying the sampling distributions for dropout layers in neural networks improves the quality of uncertainty estimation. our main idea consists of two main steps: computing data-driven correlations between neurons and generating samples, which include maximally diverse neurons. in a series of experiments on simulated and real-world data, we demonstrate that the diversification via determinantal point processes-based sampling achieves state-of-the-art results in uncertainty estimation for regression and classification tasks. an important feature of our approach is that it does not require any modification to the models or training procedures, allowing straightforward application to any deep learning model with dropout layers."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,                                                                        ,2020-03-06 ,2022-05-04 ,"['kirill fedyanin', 'evgenii tsymbalov', 'maxim panov']"
2004.07229 ,network medicine framework for identifying drug repurposing   opportunities for covid-19                                                                                                ,q-bio.mn cs.lg q-bio.qm stat.ml                          ,"the current pandemic has highlighted the need for methodologies that can quickly and reliably prioritize clinically approved compounds for their potential effectiveness for sars-cov-2 infections. in the past decade, network medicine has developed and validated multiple predictive algorithms for drug repurposing, exploiting the sub-cellular network-based relationship between a drug's targets and disease genes. here, we deployed algorithms relying on artificial intelligence, network diffusion, and network proximity, tasking each of them to rank 6,340 drugs for their expected efficacy against sars-cov-2. to test the predictions, we used as ground truth 918 drugs that had been experimentally screened in veroe6 cells, and the list of drugs under clinical trial, that capture the medical community's assessment of drugs with potential covid-19 efficacy. we find that while most algorithms offer predictive power for these ground truth data, no single method offers consistently reliable outcomes across all datasets and metrics. this prompted us to develop a multimodal approach that fuses the predictions of all algorithms, showing that a consensus among the different predictive methods consistently exceeds the performance of the best individual pipelines. we find that 76 of the 77 drugs that successfully reduced viral infection do not bind the proteins targeted by sars-cov-2, indicating that these drugs rely on network-based actions that cannot be identified using docking-based strategies. these advances offer a methodological pathway to identify repurposable drugs for future pathogens and neglected diseases underserved by the costs and extended timeline of de novo drug development."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ,10.1073/pnas.2025581118                                                 ,2020-04-15 ,2020-08-09 ,"['deisy morselli gysi', 'ítalo do valle', 'marinka zitnik', 'asher ameli', 'xiao gan', 'onur varol', 'susan dina ghiassian', 'jj patten', 'robert davey', 'joseph loscalzo', 'albert-lászló barabási']"
2004.11532 ,a comparison of methods for treatment assignment with an application to   playlist generation                                                                                           ,econ.em cs.lg stat.me stat.ml                            ,"this study presents a systematic comparison of methods for individual treatment assignment, a general problem that arises in many applications and has received significant attention from economists, computer scientists, and social scientists. we group the various methods proposed in the literature into three general classes of algorithms (or metalearners): learning models to predict outcomes (the o-learner), learning models to predict causal effects (the e-learner), and learning models to predict optimal treatment assignments (the a-learner). we compare the metalearners in terms of (1) their level of generality and (2) the objective function they use to learn models from data; we then discuss the implications that these characteristics have for modeling and decision making. notably, we demonstrate analytically and empirically that optimizing for the prediction of outcomes or causal effects is not the same as optimizing for treatment assignments, suggesting that in general the a-learner should lead to better treatment assignments than the other metalearners. we demonstrate the practical implications of our findings in the context of choosing, for each user, the best algorithm for playlist generation in order to optimize engagement. this is the first comparison of the three different metalearners on a real-world application at scale (based on more than half a billion individual treatment assignments). in addition to supporting our analytical findings, the results show how large a/b tests can provide substantial value for learning treatment assignment policies, rather than simply choosing the variant that performs best on average."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,                                                                        ,2020-04-24 ,2022-04-30 ,"['carlos fernández-loría', 'foster provost', 'jesse anderton', 'benjamin carterette', 'praveen chandar']"
2005.06377 ,suenes: a weakly supervised approach to evaluating single-document   summarization via negative sampling                                                                                ,cs.cl cs.ir cs.lg                                        ,"canonical automatic summary evaluation metrics, such as rouge, focus on lexical similarity which cannot well capture semantics nor linguistic quality and require a reference summary which is costly to obtain. recently, there have been a growing number of efforts to alleviate either or both of the two drawbacks. in this paper, we present a proof-of-concept study to a weakly supervised summary evaluation approach without the presence of reference summaries. massive data in existing summarization datasets are transformed for training by pairing documents with corrupted reference summaries. in cross-domain tests, our strategy outperforms baselines with promising improvements, and show a great advantage in gauging linguistic qualities over all metrics."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,                                                                        ,2020-05-13 ,2022-05-05 ,"['forrest sheng bao', 'hebi li', 'ge luo', 'minghui qiu', 'yinfei yang', 'youbiao he', 'cen chen']"
2006.00425 ,momentum-based variance-reduced proximal stochastic gradient method for   composite nonconvex stochastic optimization                                                                   ,math.oc cs.lg cs.na math.na                              ,"stochastic gradient methods (sgms) have been extensively used for solving stochastic problems or large-scale machine learning problems. recent works employ various techniques to improve the convergence rate of sgms for both convex and nonconvex cases. most of them require a large number of samples in some or all iterations of the improved sgms. in this paper, we propose a new sgm, named pstorm, for solving nonconvex nonsmooth stochastic problems. with a momentum-based variance reduction technique, pstorm can achieve the optimal complexity result $o(\varepsilon^{-3})$ to produce a stochastic $\varepsilon$-stationary solution, if a mean-squared smoothness condition holds. different from existing optimal methods, pstorm can achieve the ${o}(\varepsilon^{-3})$ result by using only one or $o(1)$ samples in every update. with this property, pstorm can be applied to online learning problems that favor real-time decisions based on one or $o(1)$ new observations. in addition, for large-scale machine learning problems, pstorm can generalize better by small-batch training than other optimal methods that require large-batch training and the vanilla sgm, as we demonstrate on training a sparse fully-connected neural network and a sparse convolutional neural network."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2020-05-30 ,2022-04-29 ,"['yangyang xu', 'yibo xu']"
2006.03869 ,learning mixtures of random utility models with features from incomplete   preferences                                                                                                  ,cs.lg stat.ml                                            ,"random utility models (rums), which subsume plackett-luce model (pl) as a special case, are among the most popular models for preference learning. in this paper, we consider rums with features and their mixtures, where each alternative has a vector of features, possibly different across agents. such models significantly generalize the standard pl and rums, but are not as well investigated in the literature. we extend mixtures of rums with features to models that generate incomplete preferences and characterize their identifiability. for pl, we prove that when pl with features is identifiable, its mle is consistent with a strictly concave objective function under mild assumptions, by characterizing a bound on root-mean-square-error (rmse), which naturally leads to a sample complexity bound. we also characterize identifiability of more general rums with features and propose a generalized rbcml to learn them. our experiments on synthetic data demonstrate the effectiveness of mle on pl with features with tradeoffs between statistical efficiency and computational efficiency. our experiments on real-world data show the prediction power of pl with features and its mixtures."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,                                                                        ,2020-06-06 ,2022-05-02 ,"['zhibing zhao', 'ao liu', 'lirong xia']"
2006.05256 ,recurrent flow networks: a recurrent latent variable model for density   modelling of urban mobility                                                                                    ,stat.ml cs.lg                                            ,"mobility-on-demand (mod) systems represent a rapidly developing mode of transportation wherein travel requests are dynamically handled by a coordinated fleet of vehicles. crucially, the efficiency of an mod system highly depends on how well supply and demand distributions are aligned in spatio-temporal space (i.e., to satisfy user demand, cars have to be available in the correct place and at the desired time). to do so, we argue that predictive models should aim to explicitly disentangle between temporal} and spatial variability in the evolution of urban mobility demand. however, current approaches typically ignore this distinction by either treating both sources of variability jointly, or completely ignoring their presence in the first place. in this paper, we propose recurrent flow networks (rfn), where we explore the inclusion of (i) latent random variables in the hidden state of recurrent neural networks to model temporal variability, and (ii) normalizing flows to model the spatial distribution of mobility demand. we demonstrate how predictive models explicitly disentangling between spatial and temporal variability exhibit several desirable properties, and empirically show how this enables the generation of distributions matching potentially complex urban topologies."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,                                                                        ,2020-06-09 ,2022-05-04 ,"['daniele gammelli', 'filipe rodrigues']"
2006.07507 ,better parameter-free stochastic optimization with ode updates for   coin-betting                                                                                                       ,cs.lg stat.ml                                            ,"parameter-free stochastic gradient descent (pfsgd) algorithms do not require setting learning rates while achieving optimal theoretical performance. in practical applications, however, there remains an empirical gap between tuned stochastic gradient descent (sgd) and pfsgd. in this paper, we close the empirical gap with a new parameter-free algorithm based on continuous-time coin-betting on truncated models. the new update is derived through the solution of an ordinary differential equation (ode) and solved in a closed form. we show empirically that this new parameter-free algorithm outperforms algorithms with the ""best default"" learning rates and almost matches the performance of finely tuned baselines without anything to tune."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,                                                                        ,2020-06-12 ,2022-05-03 ,"['keyi chen', 'john langford', 'francesco orabona']"
2006.07968 ,relational reasoning and generalization using non-symbolic neural   networks                                                                                                            ,cs.lg cs.ai cs.cl                                        ,"the notion of equality (identity) is simple and ubiquitous, making it a key case study for broader questions about the representations supporting abstract relational reasoning. previous work suggested that neural networks were not suitable models of human relational reasoning because they could not represent mathematically identity, the most basic form of equality. we revisit this question. in our experiments, we assess out-of-sample generalization of equality using both arbitrary representations and representations that have been pretrained on separate tasks to imbue them with structure. we find neural networks are able to learn (1) basic equality (mathematical identity), (2) sequential equality problems (learning aba-patterned sequences) with only positive training instances, and (3) a complex, hierarchical equality problem with only basic equality training instances (""zero-shot'"" generalization). in the two latter cases, our models perform tasks proposed in previous work to demarcate human-unique symbolic abilities. these results suggest that essential aspects of symbolic reasoning can emerge from data-driven, non-symbolic learning processes."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ,                                                                        ,2020-06-14 ,2022-05-01 ,"['atticus geiger', 'alexandra carstensen', 'michael c. frank', 'christopher potts']"
2007.04800 ,a bandit model for human-machine decision making with private   information and opacity                                                                                                 ,cs.lg stat.ml                                            ,"applications of machine learning inform human decision makers in a broad range of tasks. the resulting problem is usually formulated in terms of a single decision maker. we argue that it should rather be described as a two-player learning problem where one player is the machine and the other the human. while both players try to optimize the final decision, the setup is often characterized by (1) the presence of private information and (2) opacity, that is imperfect understanding between the decision makers. we prove that both properties can complicate decision making considerably. a lower bound quantifies the worst-case hardness of optimally advising a decision maker who is opaque or has access to private information. an upper bound shows that a simple coordination strategy is nearly minimax optimal. more efficient learning is possible under certain assumptions on the problem, for example that both players learn to take actions independently. such assumptions are implicit in existing literature, for example in medical applications of machine learning, but have not been described or justified theoretically."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ,                                                                        ,2020-07-09 ,2022-05-03 ,"['sebastian bordt', 'ulrike von luxburg']"
2007.09600 ,ellseg: an ellipse segmentation framework for robust gaze tracking                                                                                                                      ,cs.cv cs.lg                                              ,"ellipse fitting, an essential component in pupil or iris tracking based video oculography, is performed on previously segmented eye parts generated using various computer vision techniques. several factors, such as occlusions due to eyelid shape, camera position or eyelashes, frequently break ellipse fitting algorithms that rely on well-defined pupil or iris edge segments. in this work, we propose training a convolutional neural network to directly segment entire elliptical structures and demonstrate that such a framework is robust to occlusions and offers superior pupil and iris tracking performance (at least 10$\%$ and 24$\%$ increase in pupil and iris center detection rate respectively within a two-pixel error margin) compared to using standard eye parts segmentation for multiple publicly available synthetic segmentation datasets."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ,10.1109/tvcg.2021.3067765                                               ,2020-07-19 ,2022-05-04 ,"['rakshit s. kothari', 'aayush k. chaudhary', 'reynold j. bailey', 'jeff b. pelz', 'gabriel j. diaz']"
2009.04382 ,finite-sample guarantees for wasserstein distributionally robust   optimization: breaking the curse of dimensionality                                                                   ,cs.lg math.pr stat.ml                                    ,"wasserstein distributionally robust optimization (dro) aims to find robust and generalizable solutions by hedging against data perturbations in wasserstein distance. despite its recent empirical success in operations research and machine learning, existing performance guarantees for generic loss functions are either overly conservative due to the curse of dimensionality, or plausible only in large sample asymptotics. in this paper, we develop a non-asymptotic framework for analyzing the out-of-sample performance for wasserstein robust learning and the generalization bound for its related lipschitz and gradient regularization problems. to the best of our knowledge, this gives the first finite-sample guarantee for generic wasserstein dro problems without suffering from the curse of dimensionality. our results highlight that wasserstein dro, with a properly chosen radius, balances between the empirical mean of the loss and the variation of the loss, measured by the lipschitz norm or the gradient norm of the loss. our analysis is based on two novel methodological developments that are of independent interest: 1) a new concentration inequality controlling the decay rate of large deviation probabilities by the variation of the loss and, 2) a localized rademacher complexity theory based on the variation of the loss."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,                                                                        ,2020-09-09 ,2022-04-30 ,['rui gao']
2009.04822 ,generalized multi-output gaussian process censored regression                                                                                                                           ,stat.ml cs.lg                                            ,"when modelling censored observations, a typical approach in current regression methods is to use a censored-gaussian (i.e. tobit) model to describe the conditional output distribution. in this paper, as in the case of missing data, we argue that exploiting correlations between multiple outputs can enable models to better address the bias introduced by censored data. to do so, we introduce a heteroscedastic multi-output gaussian process model which combines the non-parametric flexibility of gps with the ability to leverage information from correlated outputs under input-dependent noise conditions. to address the resulting inference intractability, we further devise a variational bound to the marginal log-likelihood suitable for stochastic optimization. we empirically evaluate our model against other generative models for censored data on both synthetic and real world tasks and further show how it can be generalized to deal with arbitrary likelihood functions. results show how the added flexibility allows our model to better estimate the underlying non-censored (i.e. true) process under potentially complex censoring dynamics."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,                                                                        ,2020-09-10 ,2022-05-04 ,"['daniele gammelli', 'kasper pryds rolsted', 'dario pacino', 'filipe rodrigues']"
2009.06429 ,into the unknown: active monitoring of neural networks                                                                                                                                  ,cs.lg cs.ai cs.lo                                        ,"neural-network classifiers achieve high accuracy when predicting the class of an input that they were trained to identify. maintaining this accuracy in dynamic environments, where inputs frequently fall outside the fixed set of initially known classes, remains a challenge. the typical approach is to detect inputs from novel classes and retrain the classifier on an augmented dataset. however, not only the classifier but also the detection mechanism needs to adapt in order to distinguish between newly learned and yet unknown input classes. to address this challenge, we introduce an algorithmic framework for active monitoring of a neural network. a monitor wrapped in our framework operates in parallel with the neural network and interacts with a human user via a series of interpretable labeling queries for incremental adaptation. in addition, we propose an adaptive quantitative monitor to improve precision. an experimental evaluation on a diverse set of benchmarks with varying numbers of classes confirms the benefits of our active monitoring framework in dynamic scenarios."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,10.1007/978-3-030-88494-9_3                                             ,2020-09-14 ,2021-11-12 ,"['anna lukina', 'christian schilling', 'thomas a. henzinger']"
2010.03600 ,anomaly detection in large labeled multi-graph databases                                                                                                                                ,cs.db cs.ai cs.lg                                        ,"within a large database g containing graphs with labeled nodes and directed, multi-edges; how can we detect the anomalous graphs? most existing work are designed for plain (unlabeled) and/or simple (unweighted) graphs. we introduce codetect, the first approach that addresses the anomaly detection task for graph databases with such complex nature. to this end, it identifies a small representative set s of structural patterns (i.e., node-labeled network motifs) that losslessly compress database g as concisely as possible. graphs that do not compress well are flagged as anomalous. codetect exhibits two novel building blocks: (i) a motif-based lossless graph encoding scheme, and (ii) fast memory-efficient search algorithms for s. we show the effectiveness of codetect on transaction graph databases from three different corporations, where existing baselines adjusted for the task fall behind significantly, across different types of anomalies and performance metrics."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,                                                                        ,2020-10-07 ,2022-05-01 ,"['hung t. nguyen', 'pierre j. liang', 'leman akoglu']"
2010.04466 ,learning not to learn: nature versus nurture in silico                                                                                                                                  ,cs.lg cs.ai cs.ne q-bio.nc                               ,"animals are equipped with a rich innate repertoire of sensory, behavioral and motor skills, which allows them to interact with the world immediately after birth. at the same time, many behaviors are highly adaptive and can be tailored to specific environments by means of learning. in this work, we use mathematical analysis and the framework of meta-learning (or 'learning to learn') to answer when it is beneficial to learn such an adaptive strategy and when to hard-code a heuristic behavior. we find that the interplay of ecological uncertainty, task complexity and the agents' lifetime has crucial effects on the meta-learned amortized bayesian inference performed by an agent. there exist two regimes: one in which meta-learning yields a learning algorithm that implements task-dependent information-integration and a second regime in which meta-learning imprints a heuristic or 'hard-coded' behavior. further analysis reveals that non-adaptive behaviors are not only optimal for aspects of the environment that are stable across individuals, but also in situations where an adaptation to the environment would in fact be highly beneficial, but could not be done quickly enough to be exploited within the remaining lifetime. hard-coded behaviors should hence not only be those that always work, but also those that are too complex to be learned within a reasonable time frame."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ,                                                                        ,2020-10-09 ,2022-05-01 ,"['robert tjarko lange', 'henning sprekeler']"
2010.04678 ,concurrent alternating least squares for multiple simultaneous canonical   polyadic decompositions                                                                                      ,cs.ms cs.lg cs.na math.na                                ,"tensor decompositions, such as candecomp/parafac (cp), are widely used in a variety of applications, such as chemometrics, signal processing, and machine learning. a broadly used method for computing such decompositions relies on the alternating least squares (als) algorithm. when the number of components is small, regardless of its implementation, als exhibits low arithmetic intensity, which severely hinders its performance and makes gpu offloading ineffective. we observe that, in practice, experts often have to compute multiple decompositions of the same tensor, each with a small number of components (typically fewer than 20), to ultimately find the best ones to use for the application at hand. in this paper, we illustrate how multiple decompositions of the same tensor can be fused together at the algorithmic level to increase the arithmetic intensity. therefore, it becomes possible to make efficient use of gpus for further speedups; at the same time the technique is compatible with many enhancements typically used in als, such as line search, extrapolation, and non-negativity constraints. we introduce the concurrent als algorithm and library, which offers an interface to matlab, and a mechanism to effectively deal with the issue that decompositions complete at different times. experimental results on artificial and real datasets demonstrate a shorter time to completion due to increased arithmetic intensity."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ,10.1145/3519383                                                         ,2020-10-09 ,2021-09-08 ,"['christos psarras', 'lars karlsson', 'rasmus bro', 'paolo bientinesi']"
2010.07650 ,altruist: argumentative explanations through local interpretations of   predictive models                                                                                               ,cs.lg cs.ai cs.lo                                        ,"explainable ai is an emerging field providing solutions for acquiring insights into automated systems' rationale. it has been put on the ai map by suggesting ways to tackle key ethical and societal issues. existing explanation techniques are often not comprehensible to the end user. lack of evaluation and selection criteria also makes it difficult for the end user to choose the most suitable technique. in this study, we combine logic-based argumentation with interpretable machine learning, introducing a preliminary meta-explanation methodology that identifies the truthful parts of feature importance oriented interpretations. this approach, in addition to being used as a meta-explanation technique, can be used as an evaluation or selection tool for multiple feature importance techniques. experimentation strongly indicates that an ensemble of multiple interpretation techniques yields considerably more truthful explanations."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,                                                                        ,2020-10-15 ,2022-04-29 ,"['ioannis mollas', 'nick bassiliades', 'grigorios tsoumakas']"
2010.11289 ,shedding light on blind spots: developing a reference architecture to   leverage video data for process mining                                                                          ,cs.cv cs.ai cs.lg                                        ,"process mining is one of the most active research streams in business process management. in recent years, numerous methods have been proposed for analyzing structured process data. yet, in many cases, it is only the digitized parts of processes that are directly captured from process-aware information systems, and manual activities often result in blind spots. while the use of video cameras to observe these activities could help to fill this gap, a standardized approach to extracting event logs from unstructured video data remains lacking. here, we propose a reference architecture to bridge the gap between computer vision and process mining. various evaluation activities (i.e., competing artifact analysis, prototyping, and real-world application) ensured that the proposed reference architecture allows flexible, use-case-driven, and context-specific instantiations. our results also show that an exemplary software prototype instantiation of the proposed reference architecture is capable of automatically extracting most of the process-relevant events from unstructured video data."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ,10.1016/j.dss.2022.113794                                               ,2020-10-21 ,2022-05-02 ,"['wolfgang kratsch', 'fabian koenig', 'maximilian roeglinger']"
2011.07142 ,sparse representations of positive functions via first and second-order   pseudo-mirror descent                                                                                         ,stat.ml cs.cv cs.lg math.oc                              ,"we consider expected risk minimization problems when the range of the estimator is required to be nonnegative, motivated by the settings of maximum likelihood estimation (mle) and trajectory optimization. to facilitate nonlinear interpolation, we hypothesize that the search space is a reproducing kernel hilbert space (rkhs). we develop first and second-order variants of stochastic mirror descent employing (i) \emph{pseudo-gradients} and (ii) complexity-reducing projections. compressive projection in the first-order scheme is executed via kernel orthogonal matching pursuit (komp), which overcomes the fact that the vanilla rkhs parameterization grows unbounded with the iteration index in the stochastic setting. moreover, pseudo-gradients are needed when gradient estimates for cost are only computable up to some numerical error, which arise in, e.g., integral approximations. under constant step-size and compression budget, we establish tradeoffs between the radius of convergence of the expected sub-optimality and the projection budget parameter, as well as non-asymptotic bounds on the model complexity. to refine the solution's precision, we develop a second-order extension which employs recursively averaged pseudo-gradient outer-products to approximate the hessian inverse, whose convergence in mean is established under an additional eigenvalue decay condition on the hessian of the optimal rkhs element, which is unique to this work. experiments demonstrate favorable performance on inhomogeneous poisson process intensity estimation in practice."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ,                                                                        ,2020-11-13 ,2022-05-03 ,"['abhishek chakraborty', 'ketan rajawat', 'alec koppel']"
2011.08470 ,towards all-around knowledge transferring: learning from task-irrelevant   labels                                                                                                       ,cs.lg                                                    ,"deep neural models have hitherto achieved significant performances on numerous classification tasks, but meanwhile require sufficient manually annotated data. since it is extremely time-consuming and expensive to annotate adequate data for each classification task, learning an empirically effective model with generalization on small dataset has received increased attention. existing efforts mainly focus on transferring task-relevant knowledge from other similar data to tackle the issue. these approaches have yielded remarkable improvements, yet neglecting the fact that the task-irrelevant features could bring out massive negative transfer effects. to date, no large-scale studies have been performed to investigate the impact of task-irrelevant features, let alone the utilization of this kind of features. in this paper, we firstly propose task-irrelevant transfer learning (tirtl) to exploit task-irrelevant features, which mainly are extracted from task-irrelevant labels. particularly, we suppress the expression of task-irrelevant information and facilitate the learning process of classification. we also provide a theoretical explanation of our method. in addition, tirtl does not conflict with those that have previously exploited task-relevant knowledge and can be well combined to enable the simultaneous utilization of task-relevant and task-irrelevant features for the first time. in order to verify the effectiveness of our theory and method, we conduct extensive experiments on facial expression recognition and digit recognition tasks. our source code will be also available in the future for reproducibility."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,                                                                        ,2020-11-17 ,2022-05-04 ,"['yinghui li', 'ruiyang liu', 'zihao zhang', 'ning ding', 'ying shen', 'linmi tao', 'hai-tao zheng']"
2011.08981 ,ramp-cnn: a novel neural network for enhanced automotive radar object   recognition                                                                                                     ,eess.sp cs.ai cs.cv cs.lg cs.ro                          ,"millimeter-wave radars are being increasingly integrated into commercial vehicles to support new advanced driver-assistance systems by enabling robust and high-performance object detection, localization, as well as recognition - a key component of new environmental perception. in this paper, we propose a novel radar multiple-perspectives convolutional neural network (ramp-cnn) that extracts the location and class of objects based on further processing of the range-velocity-angle (rva) heatmap sequences. to bypass the complexity of 4d convolutional neural networks (nn), we propose to combine several lower-dimension nn models within our ramp-cnn model that nonetheless approaches the performance upper-bound with lower complexity. the extensive experiments show that the proposed ramp-cnn model achieves better average recall and average precision than prior works in all testing scenarios. besides, the ramp-cnn model is validated to work robustly under nighttime, which enables low-cost radars as a potential substitute for pure optical sensing under severe conditions."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,10.1109/jsen.2020.3036047                                               ,2020-11-13 ,2022-04-28 ,"['xiangyu gao', 'guanbin xing', 'sumit roy', 'hui liu']"
2012.00489 ,deep gravity: enhancing mobility flows generation with deep neural   networks and geographic information                                                                                ,cs.lg cs.si                                              ,"the movements of individuals within and among cities influence critical aspects of our society, such as well-being, the spreading of epidemics, and the quality of the environment. when information about mobility flows is not available for a particular region of interest, we must rely on mathematical models to generate them. in this work, we propose the deep gravity model, an effective method to generate flow probabilities that exploits many variables (e.g., land use, road network, transport, food, health facilities) extracted from voluntary geographic data, and uses deep neural networks to discover non-linear relationships between those variables and mobility flows. our experiments, conducted on mobility flows in england, italy, and new york state, show that deep gravity has good geographic generalization capability, achieving a significant increase in performance (especially in densely populated regions of interest) with respect to the classic gravity model and models that do not use deep neural networks or geographic data. we also show how flows generated by deep gravity may be explained in terms of the geographic features using explainable ai techniques."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,                                                                        ,2020-12-01 ,2022-01-21 ,"['filippo simini', 'gianni barlacchi', 'massimiliano luca', 'luca pappalardo']"
2012.01685 ,cross-loss influence functions to explain deep network representations                                                                                                                  ,cs.lg                                                    ,"as machine learning is increasingly deployed in the real world, it is paramount that we develop the tools necessary to analyze the decision-making of the models we train and deploy to end-users. recently, researchers have shown that influence functions, a statistical measure of sample impact, can approximate the effects of training samples on classification accuracy for deep neural networks. however, this prior work only applies to supervised learning, where training and testing share an objective function. no approaches currently exist for estimating the influence of unsupervised training examples for deep learning models. to bring explainability to unsupervised and semi-supervised training regimes, we derive the first theoretical and empirical demonstration that influence functions can be extended to handle mismatched training and testing (i.e., ""cross-loss"") settings. our formulation enables us to compute the influence in an unsupervised learning setup, explain cluster memberships, and identify and augment biases in language models. our experiments show that our cross-loss influence estimates even exceed matched-objective influence estimation relative to ground-truth sample impact."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,                                                                        ,2020-12-02 ,2022-05-03 ,"['andrew silva', 'rohit chopra', 'matthew gombolay']"
2012.02825 ,a survey on deep learning for human mobility                                                                                                                                            ,cs.lg cs.ai cs.si                                        ,"the study of human mobility is crucial due to its impact on several aspects of our society, such as disease spreading, urban planning, well-being, pollution, and more. the proliferation of digital mobility data, such as phone records, gps traces, and social media posts, combined with the predictive power of artificial intelligence, triggered the application of deep learning to human mobility. existing surveys focus on single tasks, data sources, mechanistic or traditional machine learning approaches, while a comprehensive description of deep learning solutions is missing. this survey provides a taxonomy of mobility tasks, a discussion on the challenges related to each task and how deep learning may overcome the limitations of traditional models, a description of the most relevant solutions to the mobility tasks described above and the relevant challenges for the future. our survey is a guide to the leading deep learning solutions to next-location prediction, crowd flow prediction, trajectory generation, and flow generation. at the same time, it helps deep learning scientists and practitioners understand the fundamental concepts and the open challenges of the study of human mobility."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,                                                                        ,2020-12-04 ,2021-06-27 ,"['massimiliano luca', 'gianni barlacchi', 'bruno lepri', 'luca pappalardo']"
2012.08241 ,cossgd: communication-efficient federated learning with a simple   cosine-based quantization                                                                                            ,cs.lg cs.cv                                              ,"federated learning is a promising framework to mitigate data privacy and computation concerns. however, the communication cost between the server and clients has become the major bottleneck for successful deployment. despite notable progress in gradient compression, the existing quantization methods require further improvement when low-bits compression is applied, especially the overall systems often degenerate a lot when quantization are applied in double directions to compress model weights and gradients. in this work, we propose a simple cosine-based nonlinear quantization and achieve impressive results in compressing round-trip communication costs. we are not only able to compress model weights and gradients at higher ratios than previous methods, but also achieve competing model performance at the same time. further, our approach is highly suitable for federated learning problems since it has low computational complexity and requires only a little additional data to recover the compressed information. extensive experiments have been conducted on image classification and brain tumor semantic segmentation using the cifar-10, and brats datasets where we show state-of-the-art effectiveness and impressive communication efficiency."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,                                                                        ,2020-12-15 ,2022-05-01 ,"['yang he', 'hui-po wang', 'maximilian zenk', 'mario fritz']"
2012.11073 ,regularization in network optimization via trimmed stochastic gradient   descent with noisy label                                                                                       ,cs.lg                                                    ,"regularization is essential for avoiding over-fitting to training data in network optimization, leading to better generalization of the trained networks. the label noise provides a strong implicit regularization by replacing the target ground truth labels of training examples by uniform random labels. however, it can cause undesirable misleading gradients due to the large loss associated with incorrect labels. we propose a first-order optimization method (label-noised trim-sgd) that uses the label noise with the example trimming in order to remove the outliers based on the loss. the proposed algorithm is simple yet enables us to impose a large label-noise and obtain a better regularization effect than the original methods. the quantitative analysis is performed by comparing the behavior of the label noise, the example trimming, and the proposed algorithm. we also present empirical results that demonstrate the effectiveness of our algorithm using the major benchmarks and the fundamental networks, where our method has successfully outperformed the state-of-the-art optimization methods."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,                                                                        ,2020-12-20 ,2022-05-02 ,"['kensuke nakamura', 'bong-soo sohn', 'kyoung-jae won', 'byung-woo hong']"
2012.15085 ,is pessimism provably efficient for offline rl?                                                                                                                                         ,cs.lg cs.ai math.oc math.st stat.ml stat.th              ,"we study offline reinforcement learning (rl), which aims to learn an optimal policy based on a dataset collected a priori. due to the lack of further interactions with the environment, offline rl suffers from the insufficient coverage of the dataset, which eludes most existing theoretical analysis. in this paper, we propose a pessimistic variant of the value iteration algorithm (pevi), which incorporates an uncertainty quantifier as the penalty function. such a penalty function simply flips the sign of the bonus function for promoting exploration in online rl, which makes it easily implementable and compatible with general function approximators.   without assuming the sufficient coverage of the dataset, we establish a data-dependent upper bound on the suboptimality of pevi for general markov decision processes (mdps). when specialized to linear mdps, it matches the information-theoretic lower bound up to multiplicative factors of the dimension and horizon. in other words, pessimism is not only provably efficient but also minimax optimal. in particular, given the dataset, the learned policy serves as the ""best effort"" among all policies, as no other policies can do better. our theoretical analysis identifies the critical role of pessimism in eliminating a notion of spurious correlation, which emerges from the ""irrelevant"" trajectories that are less covered by the dataset and not informative for the optimal policy."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,                                                                        ,2020-12-30 ,2022-05-04 ,"['ying jin', 'zhuoran yang', 'zhaoran wang']"
2101.01673 ,characterizing intersectional group fairness with worst-case comparisons                                                                                                                ,cs.lg cs.ai cs.cy                                        ,"machine learning or artificial intelligence algorithms have gained considerable scrutiny in recent times owing to their propensity towards imitating and amplifying existing prejudices in society. this has led to a niche but growing body of work that identifies and attempts to fix these biases. a first step towards making these algorithms more fair is designing metrics that measure unfairness. most existing work in this field deals with either a binary view of fairness (protected vs. unprotected groups) or politically defined categories (race or gender). such categorization misses the important nuance of intersectionality - biases can often be amplified in subgroups that combine membership from different categories, especially if such a subgroup is particularly underrepresented in historical platforms of opportunity.   in this paper, we discuss why fairness metrics need to be looked at under the lens of intersectionality, identify existing work in intersectional fairness, suggest a simple worst case comparison method to expand the definitions of existing group fairness metrics to incorporate intersectionality, and finally conclude with the social, legal and political framework to handle intersectional fairness in the modern context."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ,                                                                        ,2021-01-05 ,2022-05-04 ,"['avijit ghosh', 'lea genuit', 'mary reagan']"
2101.02931 ,block-term tensor decomposition model selection and computation: the   bayesian way                                                                                                     ,stat.me cs.lg cs.na math.na                              ,"the so-called block-term decomposition (btd) tensor model, especially in its rank-$(l_r,l_r,1)$ version, has been recently receiving increasing attention due to its enhanced ability of representing systems and signals that are composed of \emph{blocks} of rank higher than one, a scenario encountered in numerous and diverse applications. uniqueness conditions and fitting methods have thus been thoroughly studied. nevertheless, the challenging problem of estimating the btd model structure, namely the number of block terms, $r$, and their individual ranks, $l_r$, has only recently started to attract significant attention, mainly through regularization-based approaches which entail the need to tune the regularization parameter(s). in this work, we build on ideas of sparse bayesian learning (sbl) and put forward a fully automated bayesian approach. through a suitably crafted multi-level \emph{hierarchical} probabilistic model, which gives rise to heavy-tailed prior distributions for the btd factors, structured sparsity is \emph{jointly} imposed. ranks are then estimated from the numbers of blocks ($r$) and columns ($l_r$) of non-negligible energy. approximate posterior inference is implemented, within the variational inference framework. the resulting iterative algorithm completely avoids hyperparameter tuning, which is a significant defect of regularization-based methods. alternative probabilistic models are also explored and the connections with their regularization-based counterparts are brought to light with the aid of the associated maximum a-posteriori (map) estimators. we report simulation results with both synthetic and real-word data, which demonstrate the merits of the proposed method in terms of both rank estimation and model fitting as compared to state-of-the-art relevant methods."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,10.1109/tsp.2022.3159029                                                ,2021-01-08 ,2021-07-05 ,"['paris v. giampouras', 'athanasios a. rontogiannis', 'eleftherios kofidis']"
2101.06482 ,a renormalization group approach to connect discrete- and   continuous-time descriptions of gaussian processes                                                                          ,stat.ml cond-mat.stat-mech cs.lg                         ,"discretization of continuous stochastic processes is needed to numerically simulate them or to infer models from experimental time series. however, depending on the nature of the process, the same discretization scheme, if not accurate enough, may perform very differently for the two tasks. exact discretizations, which work equally well at any scale, are characterized by the property of invariance under coarse-graining. motivated by this observation, we build an explicit renormalization group approach for gaussian time series generated by auto-regressive models. we show that the rg fixed points correspond to discretizations of linear sdes, and only come in the form of first order markov processes or non-markovian ones. this fact provides an alternative explanation of why standard delay-vector embedding procedures fail in reconstructing partially observed noise-driven systems. we also suggest a possible effective markovian discretization for the inference of partially observed underdamped equilibrium processes based on the exploitation of the einstein relation."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,10.1103/physreve.105.044133                                             ,2021-01-16 ,2021-12-07 ,"['federica ferretti', 'victor chardès', 'thierry mora', 'aleksandra m walczak', 'irene giardina']"
2101.10902 ,maximum n-times coverage for vaccine design                                                                                                                                             ,q-bio.qm cs.lg                                           ,"we introduce the maximum $n$-times coverage problem that selects $k$ overlays to maximize the summed coverage of weighted elements, where each element must be covered at least $n$ times. we also define the min-cost $n$-times coverage problem where the objective is to select the minimum set of overlays such that the sum of the weights of elements that are covered at least $n$ times is at least $\tau$. maximum $n$-times coverage is a generalization of the multi-set multi-cover problem, is np-complete, and is not submodular. we introduce two new practical solutions for $n$-times coverage based on integer linear programming and sequential greedy optimization. we show that maximum $n$-times coverage is a natural way to frame peptide vaccine design, and find that it produces a pan-strain covid-19 vaccine design that is superior to 29 other published designs in predicted population coverage and the expected number of peptides displayed by each individual's hla molecules."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,                                                                        ,2021-01-24 ,2022-05-04 ,"['ge liu', 'alexander dimitrakakis', 'brandon carter', 'david gifford']"
2101.12081 ,generalising via meta-examples for continual learning in the wild                                                                                                                       ,cs.lg cs.cv                                              ,"future deep learning systems call for techniques that can deal with the evolving nature of temporal data and scarcity of annotations when new problems occur. as a step towards this goal, we present fusion (few-shot unsupervised continual learning), a learning strategy that enables a neural network to learn quickly and continually on streams of unlabelled data and unbalanced tasks. the objective is to maximise the knowledge extracted from the unlabelled data stream (unsupervised), favor the forward transfer of previously learnt tasks and features (continual) and exploit as much as possible the supervised information when available (few-shot). the core of fusion is meml - meta-example meta-learning - that consolidates a meta-representation through the use of a self-attention mechanism during a single inner loop in the meta-optimisation stage. to further enhance the capability of meml to generalise from few data, we extend it by creating various augmented surrogate tasks and by optimising over the hardest. an extensive experimental evaluation on public computer vision benchmarks shows that fusion outperforms existing state-of-the-art solutions both in the few-shot and continual learning experimental settings."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ,                                                                        ,2021-01-28 ,2022-05-03 ,"['alessia bertugli', 'stefano vincenzi', 'simone calderara', 'andrea passerini']"
2102.04320 ,derivation of the backpropagation algorithm based on derivative   amplification coefficients                                                                                            ,cs.lg                                                    ,"the backpropagation algorithm for neural networks is widely felt hard to understand, despite the existence of some well-written explanations and/or derivations. this paper provides a new derivation of this algorithm based on the concept of derivative amplification coefficients. first proposed by this author for fully connected cascade networks, this concept is found to well carry over to conventional feedforward neural networks and it paves the way for the use of mathematical induction in establishing a key result that enables backpropagation for derivative amplification coefficients. then we establish the connection between derivative amplification coefficients and error coefficients (commonly referred to as errors in the literature), and show that the same backpropagation procedure can be used for error coefficients. the entire derivation is thus rigorous, simple, and elegant."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,                                                                        ,2021-02-08 ,2022-04-30 ,['yiping cheng']
2102.06515 ,mediastinal lymph nodes segmentation using 3d convolutional neural   network ensembles and anatomical priors guiding                                                                    ,eess.iv cs.cv cs.lg physics.med-ph                       ,"as lung cancer evolves, the presence of enlarged and potentially malignant lymph nodes must be assessed to properly estimate disease progression and select the best treatment strategy. following the clinical guidelines, estimation of short-axis diameter and mediastinum station are paramount for correct diagnosis. a method for accurate and automatic segmentation is hence decisive for quantitatively describing lymph nodes. in this study, the use of 3d convolutional neural networks, either through slab-wise schemes or the leveraging of downsampled entire volumes, is investigated. furthermore, the potential impact from simple ensemble strategies is considered. as lymph nodes have similar attenuation values to nearby anatomical structures, we suggest using the knowledge of other organs as prior information to guide the segmentation task. to assess the segmentation and instance detection performances, a 5-fold cross-validation strategy was followed over a dataset of 120 contrast-enhanced ct volumes. for the 1178 lymph nodes with a short-axis diameter $\geq10$ mm, our best performing approach reached a patient-wise recall of 92%, a false positive per patient ratio of 5, and a segmentation overlap of 80.5%. the method performs similarly well across all stations. fusing a slab-wise and a full volume approach within an ensemble scheme generated the best performances. the anatomical priors guiding strategy is promising, yet a larger set than four organs appears needed to generate an optimal benefit. a larger dataset is also mandatory, given the wide range of expressions a lymph node can exhibit (i.e., shape, location, and attenuation), and contrast uptake variations."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,10.1080/21681163.2022.2043778                                           ,2021-02-11 ,           ,"['david bouget', 'andré pedersen', 'johanna vanel', 'haakon o. leira', 'thomas langø']"
2102.07711 ,saving stochastic bandits from poisoning attacks via limited data   verification                                                                                                        ,cs.lg cs.ai cs.cr stat.ml                                ,"we study bandit algorithms under data poisoning attacks in a bounded reward setting. we consider a strong attacker model in which the attacker can observe both the selected actions and their corresponding rewards and can contaminate the rewards with additive noise. we show that any bandit algorithm with regret $o(\log t)$ can be forced to suffer a regret $\omega(t)$ with an expected amount of contamination $o(\log t)$. this amount of contamination is also necessary, as we prove that there exists an $o(\log t)$ regret bandit algorithm, specifically the classical ucb, that requires $\omega(\log t)$ amount of contamination to suffer regret $\omega(t)$. to combat such attacks, our second main contribution is to propose verification based mechanisms, which use limited verification to access a limited number of uncontaminated rewards. in particular, for the case of unlimited verifications, we show that with $o(\log t)$ expected number of verifications, a simple modified version of the etc type bandit algorithm can restore the order optimal $o(\log t)$ regret irrespective of the amount of contamination used by the attacker. we also provide a ucb-like verification scheme, called secure-ucb, that also enjoys full recovery from any attacks, also with $o(\log t)$ expected number of verifications. to derive a matching lower bound on the number of verifications, we prove that for any order-optimal bandit algorithm, this number of verifications $\omega(\log t)$ is necessary to recover the order-optimal regret. on the other hand, when the number of verifications is bounded above by a budget $b$, we propose a novel algorithm, secure-barbar, which provably achieves $o(\min\{c,t/\sqrt{b} \})$ regret with high probability against weak attackers where $c$ is the total amount of contamination by the attacker, which breaks the known $\omega(c)$ lower bound of the non-verified setting if $c$ is large."                                                                                                                                                                                                                                                                                                                                                                                                                                        ,                                                                        ,2021-02-15 ,2022-05-03 ,"['anshuka rangi', 'long tran-thanh', 'haifeng xu', 'massimo franceschetti']"
2102.09604 ,privacy-preserving graph convolutional networks for text classification                                                                                                                 ,cs.si cs.cl cs.cr cs.lg                                  ,"graph convolutional networks (gcns) are a powerful architecture for representation learning on documents that naturally occur as graphs, e.g., citation or social networks. however, sensitive personal information, such as documents with people's profiles or relationships as edges, are prone to privacy leaks, as the trained model might reveal the original input. although differential privacy (dp) offers a well-founded privacy-preserving framework, gcns pose theoretical and practical challenges due to their training specifics. we address these challenges by adapting differentially-private gradient-based training to gcns and conduct experiments using two optimizers on five nlp datasets in two languages. we propose a simple yet efficient method based on random graph splits that not only improves the baseline privacy bounds by a factor of 2.7 while retaining competitive f1 scores, but also provides strong privacy guarantees of epsilon = 1.0. we show that, under certain modeling choices, privacy-preserving gcns perform up to 90% of their non-private variants, while formally guaranteeing strong privacy measures."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,                                                                        ,2021-02-10 ,2022-05-02 ,"['timour igamberdiev', 'ivan habernal']"
2102.11010 ,resilience of bayesian layer-wise explanations under adversarial attacks                                                                                                                ,cs.lg stat.ml                                            ,"we consider the problem of the stability of saliency-based explanations of neural network predictions under adversarial attacks in a classification task. saliency interpretations of deterministic neural networks are remarkably brittle even when the attacks fail, i.e. for attacks that do not change the classification label. we empirically show that interpretations provided by bayesian neural networks are considerably more stable under adversarial perturbations of the inputs and even under direct attacks to the explanations. by leveraging recent results, we also provide a theoretical explanation of this result in terms of the geometry of the data manifold. additionally, we discuss the stability of the interpretations of high level representations of the inputs in the internal layers of a network. our results demonstrate that bayesian methods, in addition to being more robust to adversarial attacks, have the potential to provide more stable and interpretable assessments of neural network predictions."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,                                                                        ,2021-02-22 ,2022-05-05 ,"['ginevra carbone', 'guido sanguinetti', 'luca bortolussi']"
2103.00111 ,graph self-supervised learning: a survey                                                                                                                                                ,cs.lg                                                    ,"deep learning on graphs has attracted significant interests recently. however, most of the works have focused on (semi-) supervised learning, resulting in shortcomings including heavy label reliance, poor generalization, and weak robustness. to address these issues, self-supervised learning (ssl), which extracts informative knowledge through well-designed pretext tasks without relying on manual labels, has become a promising and trending learning paradigm for graph data. different from ssl on other domains like computer vision and natural language processing, ssl on graphs has an exclusive background, design ideas, and taxonomies. under the umbrella of graph self-supervised learning, we present a timely and comprehensive review of the existing approaches which employ ssl techniques for graph data. we construct a unified framework that mathematically formalizes the paradigm of graph ssl. according to the objectives of pretext tasks, we divide these approaches into four categories: generation-based, auxiliary property-based, contrast-based, and hybrid approaches. we further describe the applications of graph ssl across various research fields and summarize the commonly used datasets, evaluation benchmark, performance comparison and open-source codes of graph ssl. finally, we discuss the remaining challenges and potential future directions in this research field."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ,10.1109/tkde.2022.3172903                                               ,2021-02-26 ,2022-05-04 ,"['yixin liu', 'ming jin', 'shirui pan', 'chuan zhou', 'yu zheng', 'feng xia', 'philip s. yu']"
2103.01278 ,non-euclidean differentially private stochastic convex optimization:   optimal rates in linear time                                                                                     ,cs.lg math.oc stat.ml                                    ,"differentially private (dp) stochastic convex optimization (sco) is a fundamental problem, where the goal is to approximately minimize the population risk with respect to a convex loss function, given a dataset of $n$ i.i.d. samples from a distribution, while satisfying differential privacy with respect to the dataset. most of the existing works in the literature of private convex optimization focus on the euclidean (i.e., $\ell_2$) setting, where the loss is assumed to be lipschitz (and possibly smooth) w.r.t. the $\ell_2$ norm over a constraint set with bounded $\ell_2$ diameter. algorithms based on noisy stochastic gradient descent (sgd) are known to attain the optimal excess risk in this setting.   in this work, we conduct a systematic study of dp-sco for $\ell_p$-setups under a standard smoothness assumption on the loss. for $1< p\leq 2$, under a standard smoothness assumption, we give a new, linear-time dp-sco algorithm with optimal excess risk. previously known constructions with optimal excess risk for $1< p <2$ run in super-linear time in $n$. for $p=1$, we give an algorithm with nearly optimal excess risk. our result for the $\ell_1$-setup also extends to general polyhedral norms and feasible sets. moreover, we show that the excess risk bounds resulting from our algorithms for $1\leq p \leq 2$ are attained with high probability. for $2 < p \leq \infty$, we show that existing linear-time constructions for the euclidean setup attain a nearly optimal excess risk in the low-dimensional regime. as a consequence, we show that such constructions attain a nearly optimal excess risk for $p=\infty$. our work draws upon concepts from the geometry of normed spaces, such as the notions of regularity, uniform convexity, and uniform smoothness."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ,                                                                        ,2021-03-01 ,2022-05-04 ,"['raef bassily', 'cristóbal guzmán', 'anupama nandi']"
2103.06257 ,maximum entropy rl (provably) solves some robust rl problems                                                                                                                            ,cs.lg cs.ro                                              ,"many potential applications of reinforcement learning (rl) require guarantees that the agent will perform well in the face of disturbances to the dynamics or reward function. in this paper, we prove theoretically that maximum entropy (maxent) rl maximizes a lower bound on a robust rl objective, and thus can be used to learn policies that are robust to some disturbances in the dynamics and the reward function. while this capability of maxent rl has been observed empirically in prior work, to the best of our knowledge our work provides the first rigorous proof and theoretical characterization of the maxent rl robust set. while a number of prior robust rl algorithms have been designed to handle similar disturbances to the reward function or dynamics, these methods typically require additional moving parts and hyperparameters on top of a base rl algorithm. in contrast, our results suggest that maxent rl by itself is robust to certain disturbances, without requiring any additional modifications. while this does not imply that maxent rl is the best available robust rl method, maxent rl is a simple robust rl method with appealing formal guarantees."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,                                                                        ,2021-03-10 ,2022-05-05 ,"['benjamin eysenbach', 'sergey levine']"
2103.06263 ,"semi-discrete optimal transport: hardness, regularization and numerical   solution"                                                                                                    ,cs.lg math.oc stat.ml                                    ,"semi-discrete optimal transport problems, which evaluate the wasserstein distance between a discrete and a generic (possibly non-discrete) probability measure, are believed to be computationally hard. even though such problems are ubiquitous in statistics, machine learning and computer vision, however, this perception has not yet received a theoretical justification. to fill this gap, we prove that computing the wasserstein distance between a discrete probability measure supported on two points and the lebesgue measure on the standard hypercube is already #p-hard. this insight prompts us to seek approximate solutions for semi-discrete optimal transport problems. we thus perturb the underlying transportation cost with an additive disturbance governed by an ambiguous probability distribution, and we introduce a distributionally robust dual optimal transport problem whose objective function is smoothed with the most adverse disturbance distributions from within a given ambiguity set. we further show that smoothing the dual objective function is equivalent to regularizing the primal objective function, and we identify several ambiguity sets that give rise to several known and new regularization schemes. as a byproduct, we discover an intimate relation between semi-discrete optimal transport problems and discrete choice models traditionally studied in psychology and economics. to solve the regularized optimal transport problems efficiently, we use a stochastic gradient descent algorithm with imprecise stochastic gradient oracles. a new convergence analysis reveals that this algorithm improves the best known convergence guarantee for semi-discrete optimal transport problems with entropic regularizers."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,                                                                        ,2021-03-10 ,2022-04-29 ,"['bahar taskesen', 'soroosh shafieezadeh-abadeh', 'daniel kuhn']"
2103.12827 ,fisher task distance and its application in neural architecture search                                                                                                                  ,cs.lg eess.iv stat.ml                                    ,"we formulate an asymmetric (or non-commutative) distance between tasks based on fisher information matrices, called fisher task distance. this distance represents the complexity of transferring the knowledge from one task to another. we provide a proof of consistency for our distance through theorems and experiments on various classification tasks from mnist, cifar-10, cifar-100, imagenet, and taskonomy datasets. next, we construct an online neural architecture search framework using the fisher task distance, in which we have access to the past learned tasks. by using the fisher task distance, we can identify the closest learned tasks to the target task, and utilize the knowledge learned from these related tasks for the target task. here, we show how the proposed distance between a target task and a set of learned tasks can be used to reduce the neural architecture search space for the target task. the complexity reduction in search space for task-specific architectures is achieved by building on the optimized architectures for similar tasks instead of doing a full search and without using this side information. experimental results for tasks in mnist, cifar-10, cifar-100, imagenet datasets demonstrate the efficacy of the proposed approach and its improvements, in terms of the performance and the number of parameters, over other gradient-based search methods, such as enas, darts, pc-darts."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,10.1109/access.2022.3171741                                             ,2021-03-23 ,2022-04-30 ,"['cat p. le', 'mohammadreza soltani', 'juncheng dong', 'vahid tarokh']"
2103.14158 ,inversionnet3d: efficient and scalable learning for 3d full waveform   inversion                                                                                                        ,cs.lg eess.sp physics.geo-ph                             ,"seismic full-waveform inversion (fwi) techniques aim to find a high-resolution subsurface geophysical model provided with waveform data. some recent effort in data-driven fwi has shown some encouraging results in obtaining 2d velocity maps. however, due to high computational complexity and large memory consumption, the reconstruction of 3d high-resolution velocity maps via deep networks is still a great challenge. in this paper, we present inversionnet3d, an efficient and scalable encoder-decoder network for 3d fwi. the proposed method employs group convolution in the encoder to establish an effective hierarchy for learning information from multiple sources while cutting down unnecessary parameters and operations at the same time. the introduction of invertible layers further reduces the memory consumption of intermediate features during training and thus enables the development of deeper networks with more layers and higher capacity as required by different application scenarios. experiments on the 3d kimberlina dataset demonstrate that inversionnet3d achieves state-of-the-art reconstruction performance with lower computational cost and lower memory footprint compared to the baseline."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,10.1109/tgrs.2021.3135354                                               ,2021-03-25 ,2021-10-27 ,"['qili zeng', 'shihang feng', 'brendt wohlberg', 'youzuo lin']"
2104.00222 ,embedded self-distillation in compact multi-branch ensemble network for   remote sensing scene classification                                                                           ,cs.cv cs.lg                                              ,"remote sensing (rs) image scene classification task faces many challenges due to the interference from different characteristics of different geographical elements. to solve this problem, we propose a multi-branch ensemble network to enhance the feature representation ability by fusing features in final output logits and intermediate feature maps. however, simply adding branches will increase the complexity of models and decline the inference efficiency. on this issue, we embed self-distillation (sd) method to transfer knowledge from ensemble network to main-branch in it. through optimizing with sd, main-branch will have close performance as ensemble network. during inference, we can cut other branches to simplify the whole model. in this paper, we first design compact multi-branch ensemble network, which can be trained in an end-to-end manner. then, we insert sd method on output logits and feature maps. compared to previous methods, our proposed architecture (esd-mbenet) performs strongly on classification accuracy with compact design. extensive experiments are applied on three benchmark rs datasets aid, nwpu-resisc45 and uc-merced with three classic baseline models, vgg16, resnet50 and densenet121. results prove that our proposed esd-mbenet can achieve better accuracy than previous state-of-the-art (sota) complex models. moreover, abundant visualization analysis make our method more convincing and interpretable."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ,10.1109/tgrs.2021.3126770                                               ,2021-03-31 ,           ,"['qi zhao', 'yujing ma', 'shuchang lyu', 'lijiang chen']"
2104.05025 ,new insights on reducing abrupt representation change in online   continual learning                                                                                                    ,cs.lg                                                    ,"in the online continual learning paradigm, agents must learn from a changing distribution while respecting memory and compute constraints. experience replay (er), where a small subset of past data is stored and replayed alongside new data, has emerged as a simple and effective learning strategy. in this work, we focus on the change in representations of observed data that arises when previously unobserved classes appear in the incoming data stream, and new classes must be distinguished from previous ones. we shed new light on this question by showing that applying er causes the newly added classes' representations to overlap significantly with the previous classes, leading to highly disruptive parameter updates. based on this empirical analysis, we propose a new method which mitigates this issue by shielding the learned representations from drastic adaptation to accommodate new classes. we show that using an asymmetric update rule pushes new classes to adapt to the older ones (rather than the reverse), which is more effective especially at task boundaries, where much of the forgetting typically occurs. empirical results show significant gains over strong baselines on standard continual learning benchmarks."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ,                                                                        ,2021-04-11 ,2022-05-02 ,"['lucas caccia', 'rahaf aljundi', 'nader asadi', 'tinne tuytelaars', 'joelle pineau', 'eugene belilovsky']"
2104.08142 ,supervising model attention with human explanations for robust natural   language inference                                                                                             ,cs.cl cs.lg                                              ,"natural language inference (nli) models are known to learn from biases and artefacts within their training data, impacting how well they generalise to other unseen datasets. existing de-biasing approaches focus on preventing the models from learning these biases, which can result in restrictive models and lower performance. we instead investigate teaching the model how a human would approach the nli task, in order to learn features that will generalise better to previously unseen examples. using natural language explanations, we supervise the model's attention weights to encourage more attention to be paid to the words present in the explanations, significantly improving model performance. our experiments show that the in-distribution improvements of this method are also accompanied by out-of-distribution improvements, with the supervised models learning from features that generalise better to other nli datasets. analysis of the model indicates that human explanations encourage increased attention on the important words, with more attention paid to words in the premise and less attention paid to punctuation and stop-words."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,                                                                        ,2021-04-16 ,2022-05-01 ,"['joe stacey', 'yonatan belinkov', 'marek rei']"
2104.09083 ,multi-fold correlation attention network for predicting traffic speeds   with heterogeneous frequency                                                                                   ,cs.lg cs.ai                                              ,"substantial efforts have been devoted to the investigation of spatiotemporal correlations for improving traffic speed prediction accuracy. however, existing works typically model the correlations based solely on the observed traffic state (e.g. traffic speed) without due consideration that different correlation measurements of the traffic data could exhibit a diverse set of patterns under different traffic situations. in addition, the existing works assume that all road segments can employ the same sampling frequency of traffic states, which is impractical. in this paper, we propose new measurements to model the spatial correlations among traffic data and show that the resulting correlation patterns vary significantly under various traffic situations. we propose a heterogeneous spatial correlation (hsc) model to capture the spatial correlation based on a specific measurement, where the traffic data of varying road segments can be heterogeneous (i.e. obtained with different sampling frequency). we propose a multi-fold correlation attention network (mcan), which relies on the hsc model to explore multi-fold spatial correlations and leverage lstm networks to capture multi-fold temporal correlations to provide discriminating features in order to achieve accurate traffic prediction. the learned multi-fold spatiotemporal correlations together with contextual factors are fused with attention mechanism to make the final predictions. experiments on real-world datasets demonstrate that the proposed mcan model outperforms the state-of-the-art baselines."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,                                                                        ,2021-04-19 ,2022-05-04 ,"['yidan sun', 'guiyuan jiang', 'siew-kei lam', 'peilan he', 'fangxin ning']"
2105.00373 ,investigating the impact of multi-lidar placement on object detection   for autonomous driving                                                                                          ,cs.ro cs.ai cs.cv cs.lg                                  ,"the past few years have witnessed an increasing interest in improving the perception performance of lidars on autonomous vehicles. while most of the existing works focus on developing new deep learning algorithms or model architectures, we study the problem from the physical design perspective, i.e., how different placements of multiple lidars influence the learning-based perception. to this end, we introduce an easy-to-compute information-theoretic surrogate metric to quantitatively and fast evaluate lidar placement for 3d detection of different types of objects. we also present a new data collection, detection model training and evaluation framework in the realistic carla simulator to evaluate disparate multi-lidar configurations. using several prevalent placements inspired by the designs of self-driving companies, we show the correlation between our surrogate metric and object detection performance of different representative algorithms on kitti through extensive experiments, validating the effectiveness of our lidar placement evaluation approach. our results show that sensor placement is non-negligible in 3d point cloud-based object detection, which will contribute up to 10% performance discrepancy in terms of average precision in challenging 3d object detection settings. we believe that this is one of the first studies to quantitatively investigate the influence of lidar placement on perception performance. the code is available on https://github.com/hanjianghu/multi-lidar-placement-for-3d-detection."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2021-05-01 ,2022-05-04 ,"['hanjiang hu', 'zuxin liu', 'sharad chitlangia', 'akhil agnihotri', 'ding zhao']"
2105.02091 ,when fair ranking meets uncertain inference                                                                                                                                             ,cs.ir cs.cy cs.lg                                        ,"existing fair ranking systems, especially those designed to be demographically fair, assume that accurate demographic information about individuals is available to the ranking algorithm. in practice, however, this assumption may not hold -- in real-world contexts like ranking job applicants or credit seekers, social and legal barriers may prevent algorithm operators from collecting peoples' demographic information. in these cases, algorithm operators may attempt to infer peoples' demographics and then supply these inferences as inputs to the ranking algorithm.   in this study, we investigate how uncertainty and errors in demographic inference impact the fairness offered by fair ranking algorithms. using simulations and three case studies with real datasets, we show how demographic inferences drawn from real systems can lead to unfair rankings. our results suggest that developers should not use inferred demographic data as input to fair ranking algorithms, unless the inferences are extremely accurate."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,10.1145/3404835.3462850                                                 ,2021-05-05 ,2022-05-04 ,"['avijit ghosh', 'ritam dutt', 'christo wilson']"
2105.14372 ,ten quick tips for deep learning in biology                                                                                                                                             ,q-bio.ot cs.lg                                           ,"machine learning is a modern approach to problem-solving and task automation. in particular, machine learning is concerned with the development and applications of algorithms that can recognize patterns in data and use them for predictive modeling. artificial neural networks are a particular class of machine learning algorithms and models that evolved into what is now described as deep learning. given the computational advances made in the last decade, deep learning can now be applied to massive data sets and in innumerable contexts. therefore, deep learning has become its own subfield of machine learning. in the context of biological research, it has been increasingly used to derive novel insights from high-dimensional biological data. to make the biological applications of deep learning more accessible to scientists who have some experience with machine learning, we solicited input from a community of researchers with varied biological and deep learning interests. these individuals collaboratively contributed to this manuscript's writing using the github version control platform and the manubot manuscript generation toolset. the goal was to articulate a practical, accessible, and concise set of guidelines and suggestions to follow when using deep learning. in the course of our discussions, several themes became clear: the importance of understanding and applying machine learning fundamentals as a baseline for utilizing deep learning, the necessity for extensive model comparisons with careful evaluation, and the need for critical thought in interpreting results generated by deep learning, among others."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,10.1371/journal.pcbi.1009803                                            ,2021-05-29 ,           ,"['benjamin d. lee', 'anthony gitter', 'casey s. greene', 'sebastian raschka', 'finlay maguire', 'alexander j. titus', 'michael d. kessler', 'alexandra j. lee', 'marc g. chevrette', 'paul allen stewart', 'thiago britto-borges', 'evan m. cofer', 'kun-hsing yu', 'juan jose carmona', 'elana j. fertig', 'alexandr a. kalinin', 'beth signal', 'benjamin j. lengerich', 'timothy j. triche', 'simina m. boca']"
2106.00072 ,early detection of covid-19 hotspots using spatio-temporal data                                                                                                                         ,stat.ml cs.lg stat.ap                                    ,"recently, the centers for disease control and prevention (cdc) has worked with other federal agencies to identify counties with increasing coronavirus disease 2019 (covid-19) incidence (hotspots) and offers support to local health departments to limit the spread of the disease. understanding the spatio-temporal dynamics of hotspot events is of great importance to support policy decisions and prevent large-scale outbreaks. this paper presents a spatio-temporal bayesian framework for early detection of covid-19 hotspots (at the county level) in the united states. we assume both the observed number of cases and hotspots depend on a class of latent random variables, which encode the underlying spatio-temporal dynamics of the transmission of covid-19. such latent variables follow a zero-mean gaussian process, whose covariance is specified by a non-stationary kernel function. the most salient feature of our kernel function is that deep neural networks are introduced to enhance the model's representative power while still enjoying the interpretability of the kernel. we derive a sparse model and fit the model using a variational learning strategy to circumvent the computational intractability for large data sets. our model demonstrates better interpretability and superior hotspot-detection performance compared to other baseline methods."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ,10.1109/jstsp.2022.3154972                                              ,2021-05-31 ,2021-10-31 ,"['shixiang zhu', 'alexander bukharin', 'liyan xie', 'khurram yamin', 'shihao yang', 'pinar keskinocak', 'yao xie']"
2106.02680 ,algorithms from invariants: smoothed analysis of orbit recovery over   $so(3)$                                                                                                          ,cs.ds cs.lg stat.ml                                      ,"in this work we study orbit recovery over $so(3)$, where the goal is to recover a function on the sphere from noisy, randomly rotated copies of it. we assume that the function is a linear combination of low-degree spherical harmonics. this is a natural abstraction for the problem of recovering the three-dimensional structure of a molecule through cryo-electron tomography. for provably learning the parameters of a generative model, the method of moments is the standard workhorse of theoretical machine learning. it turns out that there is a natural incarnation of the method of moments for orbit recovery based on invariant theory. bandeira et al. [bbsk+18] used invariant theory to give tight bounds on the sample complexity in terms of the noise level. however many of the key challenges remain: can we prove bounds on the sample complexity that are polynomial in $n$, the dimension of the signal? the bounds in [bbsk+18] hide constants that have an unspecified dependence on $n$ and only hold in the limit as $\sigma^2 \rightarrow \infty$ where $\sigma^2$ is the variance of the noise. moreover can we give efficient algorithms? we revisit these challenges from the perspective of smoothed analysis, where we assume that the coefficients of the signal, in the basis of spherical harmonics, are subject to small random perturbations. our main result is a quasi-polynomial time algorithm for orbit recovery over $so(3)$ in this model. our approach is based on frequency marching, which sequentially solves linear systems to find higher degree coefficients. our main technical contribution is to show that these linear systems have unique solutions, are well-conditioned, and that the error can be made to compound over at most a logarithmic number of rounds. we believe that our work takes an important first step towards uncovering the algorithmic implications of invariant theory."                                                                                                                                                                                                                                                                                                                                                                                                                                                                ,                                                                        ,2021-06-04 ,2022-05-01 ,"['allen liu', 'ankur moitra']"
2106.04509 ,mocl: data-driven molecular fingerprint via knowledge-aware contrastive   learning from molecular graph                                                                                 ,physics.bio-ph cs.lg                                     ,"recent years have seen a rapid growth of utilizing graph neural networks (gnns) in the biomedical domain for tackling drug-related problems. however, like any other deep architectures, gnns are data hungry. while requiring labels in real world is often expensive, pretraining gnns in an unsupervised manner has been actively explored. among them, graph contrastive learning, by maximizing the mutual information between paired graph augmentations, has been shown to be effective on various downstream tasks. however, the current graph contrastive learning framework has two limitations. first, the augmentations are designed for general graphs and thus may not be suitable or powerful enough for certain domains. second, the contrastive scheme only learns representations that are invariant to local perturbations and thus does not consider the global structure of the dataset, which may also be useful for downstream tasks. therefore, in this paper, we study graph contrastive learning in the context of biomedical domain, where molecular graphs are present. we propose a novel framework called mocl, which utilizes domain knowledge at both local- and global-level to assist representation learning. the local-level domain knowledge guides the augmentation process such that variation is introduced without changing graph semantics. the global-level knowledge encodes the similarity information between graphs in the entire dataset and helps to learn representations with richer semantics. the entire model is learned through a double contrast objective. we evaluate mocl on various molecular datasets under both linear and semi-supervised settings and results show that mocl achieves state-of-the-art performance."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ,                                                                        ,2021-06-05 ,2022-05-02 ,"['mengying sun', 'jing xing', 'huijun wang', 'bin chen', 'jiayu zhou']"
2106.07825 ,site-agnostic 3d dose distribution prediction with deep learning neural   networks                                                                                                      ,cs.lg cs.ai physics.med-ph                               ,"typically, the current dose prediction models are limited to small amounts of data and require re-training for a specific site, often leading to suboptimal performance. we propose a site-agnostic, 3d dose distribution prediction model using deep learning that can leverage data from any treatment site, thus increasing the total data available to train the model. applying our proposed model to a new target treatment site requires only a brief fine-tuning of the model to the new data and involves no modifications to the model input channels or its parameters. thus, it can be efficiently adapted to a different treatment site, even with a small training dataset."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ,10.1002/mp.15461                                                        ,2021-06-14 ,           ,"['maryam mashayekhi', 'itzel ramirez tapia', 'anjali balagopal', 'xinran zhong', 'azar sadeghnejad barkousaraie', 'rafe mcbeth', 'mu-han lin', 'steve jiang', 'dan nguyen']"
2106.08043 ,causalnlp: a practical toolkit for causal inference with text                                                                                                                           ,cs.cl cs.lg                                              ,"causal inference is the process of estimating the effect or impact of a treatment on an outcome with other covariates as potential confounders (and mediators) that may need to be controlled. the vast majority of existing methods and systems for causal inference assume that all variables under consideration are categorical or numerical (e.g., gender, price, enrollment). in this paper, we present causalnlp, a toolkit for inferring causality with observational data that includes text in addition to traditional numerical and categorical variables. causalnlp employs the use of meta learners for treatment effect estimation and supports using raw text and its linguistic properties as a treatment, an outcome, or a ""controlled-for"" variable (e.g., confounder). the library is open source and available at: https://github.com/amaiya/causalnlp."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ,                                                                        ,2021-06-15 ,2022-05-03 ,['arun s. maiya']
2106.08771 ,reinforcement learning for markovian bandits: is posterior sampling more   scalable than optimism?                                                                                      ,cs.lg cs.ai                                              ,"we study learning algorithms for the classical markovian bandit problem with discount. we explain how to adapt psrl [24] and ucrl2 [2] to exploit the problem structure. these variants are called mb-psrl and mb-ucrl2. while the regret bound and runtime of vanilla implementations of psrl and ucrl2 are exponential in the number of bandits, we show that the episodic regret of mb-psrl and mb-ucrl2 is $\tilde{o}(s\sqrt{nk})$ where $k$ is the number of episodes, $n$ is the number of bandits and $s$ is the number of states of each bandit (the exact bound in s, n and k is given in the paper). up to a factor $\sqrt s$, this matches the lower bound of $\omega(\sqrt{snk})$ that we also derive in the paper. mb-psrl is also computationally efficient: its runtime is linear in the number of bandits. we further show that this linear runtime cannot be achieved by adapting classical non-bayesian algorithms such as ucrl2 or ucbvi to markovian bandit problems. finally, we perform numerical experiments that confirm that mb-psrl outperforms other existing algorithms in practice, both in terms of regret and of computation time."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,                                                                        ,2021-06-16 ,2022-05-03 ,"['nicolas gast', 'bruno gaujal', 'kimang khun']"
2106.09385 ,on deep neural network calibration by regularization and its impact on   refinement                                                                                                     ,cs.lg cs.cv                                              ,"deep neural networks have been shown to be highly miscalibrated. often they tend to be overconfident in their predictions. it poses a significant challenge for safety-critical systems to utilise deep neural networks (dnns), reliably. many recently proposed approaches to mitigate this have demonstrated substantial progress in improving dnn calibration. however, they hardly touch upon refinement, which historically has been an essential aspect of calibration. refinement indicates separability of a network's correct and incorrect predictions. this paper presents a theoretically and empirically supported exposition reviewing refinement of a calibrated model. firstly, we show the breakdown of expected calibration error (ece), into predicted confidence and refinement under the assumption of over-confident predictions. secondly, linking with this result, we highlight that regularization based calibration only focuses on naively reducing a model's confidence. this logically has a severe downside to a model's refinement as correct and incorrect predictions become tightly coupled. lastly, connecting refinement with ece also provides support to existing refinement based approaches which improve calibration but do not explain the reasoning behind it. we support our claims through rigorous empirical evaluations of many state of the art calibration approaches on widely used datasets and neural networks. we find that many calibration approaches with the likes of label smoothing, mixup etc. lower the usefulness of a dnn by degrading its refinement. even under natural data shift, this calibration-refinement trade-off holds for the majority of calibration methods."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2021-06-17 ,2022-05-04 ,"['aditya singh', 'alessandro bay', 'biswa sengupta', 'andrea mirabile']"
2106.11053 ,leveraging language to learn program abstractions and search heuristics                                                                                                                 ,cs.lg cs.ai cs.cl                                        ,"inductive program synthesis, or inferring programs from examples of desired behavior, offers a general paradigm for building interpretable, robust, and generalizable machine learning systems. effective program synthesis depends on two key ingredients: a strong library of functions from which to build programs, and an efficient search strategy for finding programs that solve a given task. we introduce laps (language for abstraction and program search), a technique for using natural language annotations to guide joint learning of libraries and neurally-guided search models for synthesis. when integrated into a state-of-the-art library learning system (dreamcoder), laps produces higher-quality libraries and improves search efficiency and generalization on three domains -- string editing, image composition, and abstract reasoning about scenes -- even when no natural language hints are available at test time."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,                                                                        ,2021-06-18 ,2022-05-03 ,"['catherine wong', 'kevin ellis', 'joshua b. tenenbaum', 'jacob andreas']"
2106.13044 ,personalized federated learning with contextualized generalization                                                                                                                      ,cs.lg cs.dc                                              ,"the prevalent personalized federated learning (pfl) usually pursues a trade-off between personalization and generalization by maintaining a shared global model to guide the training process of local models. however, the sole global model may easily transfer deviated context knowledge to some local models when multiple latent contexts exist across the local datasets. in this paper, we propose a novel concept called contextualized generalization (cg) to provide each client with fine-grained context knowledge that can better fit the local data distributions and facilitate faster model convergence, based on which we properly design a framework of pfl, dubbed cgpfl. we conduct detailed theoretical analysis, in which the convergence guarantee is presented and $\mathcal{o}(\sqrt{k})$ speedup over most existing methods is granted. to quantitatively study the generalization-personalization trade-off, we introduce the 'generalization error' measure and prove that the proposed cgpfl can achieve a better trade-off than existing solutions. moreover, our theoretical analysis further inspires a heuristic algorithm to find a near-optimal trade-off in cgpfl. experimental results on multiple real-world datasets show that our approach surpasses the state-of-the-art methods on test accuracy by a significant margin."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,                                                                        ,2021-06-24 ,2022-05-01 ,"['xueyang tang', 'song guo', 'jingcai guo']"
2106.13061 ,fea2fea: exploring structural feature correlations via graph neural   networks                                                                                                          ,cs.lg cs.ai cs.si                                        ,"structural features are important features in a geometrical graph. although there are some correlation analysis of features based on covariance, there is no relevant research on structural feature correlation analysis with graph neural networks. in this paper, we introuduce graph feature to feature (fea2fea) prediction pipelines in a low dimensional space to explore some preliminary results on structural feature correlation, which is based on graph neural network. the results show that there exists high correlation between some of the structural features. an irredundant feature combination with initial node features, which is filtered by graph neural network has improved its classification accuracy in some graph-based tasks. we compare differences between concatenation methods on connecting embeddings between features and show that the simplest is the best. we generalize on the synthetic geometric graphs and certify the results on prediction difficulty between structural features."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ,10.1007/978-3-030-93736-2_19                                            ,2021-06-24 ,2021-09-09 ,"['jiaqing xie', 'rex ying']"
2106.15419 ,convergent and efficient deep q network algorithm                                                                                                                                       ,cs.lg cs.ai                                              ,"despite the empirical success of the deep q network (dqn) reinforcement learning algorithm and its variants, dqn is still not well understood and it does not guarantee convergence. in this work, we show that dqn can indeed diverge and cease to operate in realistic settings. although there exist gradient-based convergent methods, we show that they actually have inherent problems in learning dynamics which cause them to fail even in simple tasks. to overcome these problems, we propose a convergent dqn algorithm (c-dqn) that is guaranteed to converge and can work with large discount factors (0.9998). it learns robustly in difficult settings and can learn several difficult games in the atari 2600 benchmark that dqn fails to solve. our codes have been publicly released and can be used to reproduce our results."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,                                                                        ,2021-06-29 ,2022-05-02 ,"['zhikang t. wang', 'masahito ueda']"
2107.00296 ,explainable diabetic retinopathy detection and retinal image generation                                                                                                                 ,eess.iv cs.cv cs.lg                                      ,"though deep learning has shown successful performance in classifying the label and severity stage of certain diseases, most of them give few explanations on how to make predictions. inspired by koch's postulates, the foundation in evidence-based medicine (ebm) to identify the pathogen, we propose to exploit the interpretability of deep learning application in medical diagnosis. by determining and isolating the neuron activation patterns on which diabetic retinopathy (dr) detector relies to make decisions, we demonstrate the direct relation between the isolated neuron activation and lesions for a pathological explanation. to be specific, we first define novel pathological descriptors using activated neurons of the dr detector to encode both spatial and appearance information of lesions. then, to visualize the symptom encoded in the descriptor, we propose patho-gan, a new network to synthesize medically plausible retinal images. by manipulating these descriptors, we could even arbitrarily control the position, quantity, and categories of generated lesions. we also show that our synthesized images carry the symptoms directly related to diabetic retinopathy diagnosis. our generated images are both qualitatively and quantitatively superior to the ones by previous methods. besides, compared to existing methods that take hours to generate an image, our second level speed endows the potential to be an effective solution for data augmentation."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,10.1109/jbhi.2021.3110593                                               ,2021-07-01 ,           ,"['yuhao niu', 'lin gu', 'yitian zhao', 'feng lu']"
2107.00471 ,singan-seg: synthetic training data generation for medical image   segmentation                                                                                                         ,eess.iv cs.cv cs.lg                                      ,"analyzing medical data to find abnormalities is a time-consuming and costly task, particularly for rare abnormalities, requiring tremendous efforts from medical experts. artificial intelligence has become a popular tool for the automatic processing of medical data, acting as a supportive tool for doctors. however, the machine learning models used to build these tools are highly dependent on the data used to train them. large amounts of data can be difficult to obtain in medicine due to privacy, expensive and time-consuming annotations, and a general lack of data samples for infrequent lesions. here, we present a novel synthetic data generation pipeline, called singan-seg, to produce synthetic medical images with corresponding masks using a single training image. our method is different from the traditional gans because our model needs only a single image and the corresponding ground truth to train. our method produces alternative artificial segmentation datasets with ground truth masks when real datasets are not allowed to share. the pipeline is evaluated using qualitative and quantitative comparisons between real and synthetic data to show that the style transfer technique used in our pipeline significantly improves the quality of the generated data and our method is better than other state-of-the-art gans to prepare synthetic images when the size of training datasets are limited. by training unet++ using both real and the synthetic data generated from the singan-seg pipeline, we show that models trained with synthetic data have very close performances to those trained on real data when the datasets have a considerable amount of data. in contrast, synthetic data generated from the singan-seg pipeline can improve the performance of segmentation models when training datasets do not have a considerable amount of data. the code is available on github."                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,10.1371/journal.pone.0267976                                            ,2021-06-29 ,2022-04-25 ,"['vajira thambawita', 'pegah salehi', 'sajad amouei sheshkal', 'steven a. hicks', 'hugo l. hammer', 'sravanthi parasa', 'thomas de lange', 'pål halvorsen', 'michael a. riegler']"
2107.00656 ,shared data and algorithms for deep learning in fundamental physics                                                                                                                     ,cs.lg astro-ph.im hep-ph nucl-th physics.data-an stat.ml ,"we introduce a python package that provides simply and unified access to a collection of datasets from fundamental physics research - including particle physics, astroparticle physics, and hadron- and nuclear physics - for supervised machine learning studies. the datasets contain hadronic top quarks, cosmic-ray induced air showers, phase transitions in hadronic matter, and generator-level histories. while public datasets from multiple fundamental physics disciplines already exist, the common interface and provided reference models simplify future work on cross-disciplinary machine learning and transfer learning in fundamental physics. we discuss the design and structure and line out how additional datasets can be submitted for inclusion.   as showcase application, we present a simple yet flexible graph-based neural network architecture that can easily be applied to a wide range of supervised learning tasks. we show that our approach reaches performance close to dedicated methods on all datasets. to simplify adaptation for various problems, we provide easy-to-follow instructions on how graph-based representations of data structures, relevant for fundamental physics, can be constructed and provide code implementations for several of them. implementations are also provided for our proposed method and all reference algorithms."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,10.1007/s41781-022-00082-6                                              ,2021-07-01 ,2022-03-24 ,"['lisa benato', 'erik buhmann', 'martin erdmann', 'peter fackeldey', 'jonas glombitza', 'nikolai hartmann', 'gregor kasieczka', 'william korcari', 'thomas kuhr', 'jan steinheimer', 'horst stöcker', 'tilman plehn', 'kai zhou']"
2107.01461 ,a lottery ticket hypothesis framework for low-complexity device-robust   neural acoustic scene classification                                                                           ,cs.sd cs.lg cs.mm eess.as                                ,"we propose a novel neural model compression strategy combining data augmentation, knowledge transfer, pruning, and quantization for device-robust acoustic scene classification (asc). specifically, we tackle the asc task in a low-resource environment leveraging a recently proposed advanced neural network pruning mechanism, namely lottery ticket hypothesis (lth), to find a sub-network neural model associated with a small amount non-zero model parameters. the effectiveness of lth for low-complexity acoustic modeling is assessed by investigating various data augmentation and compression schemes, and we report an efficient joint framework for low-complexity multi-device asc, called \emph{acoustic lottery}. acoustic lottery could compress an asc model up to $1/10^{4}$ and attain a superior performance (validation accuracy of 79.4% and log loss of 0.64) compared to its not compressed seed model. all results reported in this work are based on a joint effort of four groups, namely gt-ustc-uke-tencent, aiming to address the ""low-complexity acoustic scene classification (asc) with multiple devices"" in the dcase 2021 challenge task 1a."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,                                                                        ,2021-07-03 ,2022-05-01 ,"['hao yen', 'chao-han huck yang', 'hu hu', 'sabato marco siniscalchi', 'qing wang', 'yuyang wang', 'xianjun xia', 'yuanjun zhao', 'yuzhong wu', 'yannan wang', 'jun du', 'chin-hui lee']"
2107.02791 ,depth-supervised nerf: fewer views and faster training for free                                                                                                                         ,cs.cv cs.gr cs.lg                                        ,"a commonly observed failure mode of neural radiance field (nerf) is fitting incorrect geometries when given an insufficient number of input views. one potential reason is that standard volumetric rendering does not enforce the constraint that most of a scene's geometry consist of empty space and opaque surfaces. we formalize the above assumption through ds-nerf (depth-supervised neural radiance fields), a loss for learning radiance fields that takes advantage of readily-available depth supervision. we leverage the fact that current nerf pipelines require images with known camera poses that are typically estimated by running structure-from-motion (sfm). crucially, sfm also produces sparse 3d points that can be used as ""free"" depth supervision during training: we add a loss to encourage the distribution of a ray's terminating depth matches a given 3d keypoint, incorporating depth uncertainty. ds-nerf can render better images given fewer training views while training 2-3x faster. further, we show that our loss is compatible with other recently proposed nerf methods, demonstrating that depth is a cheap and easily digestible supervisory signal. and finally, we find that ds-nerf can support other types of depth supervision such as scanned depth sensors and rgb-d reconstruction outputs."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ,                                                                        ,2021-07-06 ,2022-04-29 ,"['kangle deng', 'andrew liu', 'jun-yan zhu', 'deva ramanan']"
2107.06126 ,dicova-net: diagnosing covid-19 using acoustics based on deep residual   network for the dicova challenge 2021                                                                          ,cs.sd cs.ai cs.lg eess.as                                ,"in this paper, we propose a deep residual network-based method, namely the dicova-net, to identify covid-19 infected patients based on the acoustic recording of their coughs. since there are far more healthy people than infected patients, this classification problem faces the challenge of imbalanced data. to improve the model's ability to recognize minority class (the infected patients), we introduce data augmentation and cost-sensitive methods into our model. besides, considering the particularity of this task, we deploy some fine-tuning techniques to adjust the pre-training resnet50. furthermore, to improve the model's generalizability, we use ensemble learning to integrate prediction results from multiple base classifiers generated using different random seeds. to evaluate the proposed dicova-net's performance, we conducted experiments with the dicova challenge dataset. the results show that our method has achieved 85.43\% in auc, among the top of all competing teams."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ,                                                                        ,2021-07-11 ,2022-05-04 ,"['jiangeng chang', 'shaoze cui', 'mengling feng']"
2107.06943 ,fetalnet: multi-task deep learning framework for fetal ultrasound   biometric measurements                                                                                              ,eess.iv cs.ai cs.cv cs.lg                                ,"in this paper, we propose an end-to-end multi-task neural network called fetalnet with an attention mechanism and stacked module for spatio-temporal fetal ultrasound scan video analysis. fetal biometric measurement is a standard examination during pregnancy used for the fetus growth monitoring and estimation of gestational age and fetal weight. the main goal in fetal ultrasound scan video analysis is to find proper standard planes to measure the fetal head, abdomen and femur. due to natural high speckle noise and shadows in ultrasound data, medical expertise and sonographic experience are required to find the appropriate acquisition plane and perform accurate measurements of the fetus. in addition, existing computer-aided methods for fetal us biometric measurement address only one single image frame without considering temporal features. to address these shortcomings, we propose an end-to-end multi-task neural network for spatio-temporal ultrasound scan video analysis to simultaneously localize, classify and measure the fetal body parts. we propose a new encoder-decoder segmentation architecture that incorporates a classification branch. additionally, we employ an attention mechanism with a stacked module to learn salient maps to suppress irrelevant us regions and efficient scan plane localization. we trained on the fetal ultrasound video comes from routine examinations of 700 different patients. our method called fetalnet outperforms existing state-of-the-art methods in both classification and segmentation in fetal ultrasound video recordings."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,                                                                        ,2021-07-14 ,2022-05-03 ,"['szymon płotka', 'tomasz włodarczyk', 'adam klasa', 'michał lipa', 'arkadiusz sitek', 'tomasz trzciński']"
2107.07312 ,fmnet: latent feature-wise mapping network for cleaning up noisy   micro-doppler spectrogram                                                                                            ,eess.sp cs.lg                                            ,"micro-doppler signatures contain considerable information about target dynamics. however, the radar sensing systems are easily affected by noisy surroundings, resulting in uninterpretable motion patterns on the micro-doppler spectrogram. meanwhile, radar returns often suffer from multipath, clutter and interference. these issues lead to difficulty in, for example motion feature extraction, activity classification using micro doppler signatures ($\mu$-ds), etc. in this paper, we propose a latent feature-wise mapping strategy, called feature mapping network (fmnet), to transform measured spectrograms so that they more closely resemble the output from a simulation under the same conditions. based on measured spectrogram and the matched simulated data, our framework contains three parts: an encoder which is used to extract latent representations/features, a decoder outputs reconstructed spectrogram according to the latent features, and a discriminator minimizes the distance of latent features of measured and simulated data. we demonstrate the fmnet with six activities data and two experimental scenarios, and final results show strong enhanced patterns and can keep actual motion information to the greatest extent. on the other hand, we also propose a novel idea which trains a classifier with only simulated data and predicts new measured samples after cleaning them up with the fmnet. from final classification results, we can see significant improvements."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,10.1109/tgrs.2021.3121211                                               ,2021-07-09 ,           ,"['chong tang', 'wenda li', 'shelly vishwakarma', 'fangzhan shi', 'simon julier', 'kevin chetty']"
2107.07677 ,ecg-adv-gan: detecting ecg adversarial examples with conditional   generative adversarial networks                                                                                      ,cs.lg                                                    ,"electrocardiogram (ecg) acquisition requires an automated system and analysis pipeline for understanding specific rhythm irregularities. deep neural networks have become a popular technique for tracing ecg signals, outperforming human experts. despite this, convolutional neural networks are susceptible to adversarial examples that can misclassify ecg signals and decrease the model's precision. moreover, they do not generalize well on the out-of-distribution dataset. the gan architecture has been employed in recent works to synthesize adversarial ecg signals to increase existing training data. however, they use a disjointed cnn-based classification architecture to detect arrhythmia. till now, no versatile architecture has been proposed that can detect adversarial examples and classify arrhythmia simultaneously. to alleviate this, we propose a novel conditional generative adversarial network to simultaneously generate ecg signals for different categories and detect cardiac abnormalities. moreover, the model is conditioned on class-specific ecg signals to synthesize realistic adversarial examples. consequently, we compare our architecture and show how it outperforms other classification models in normal/abnormal ecg signal detection by benchmarking real world and adversarial signals."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,10.1109/icmla52953.2021.00016                                           ,2021-07-15 ,2021-10-18 ,"['khondker fariha hossain', 'sharif amit kamran', 'alireza tavakkoli', 'lei pan', 'xingjun ma', 'sutharshan rajasegarar', 'chandan karmaker']"
2107.09729 ,what do you get when you cross beam search with nucleus sampling?                                                                                                                       ,cs.cl cs.ai cs.lg                                        ,"we combine beam search with the probabilistic pruning technique of nucleus sampling to create two deterministic nucleus search algorithms for natural language generation. the first algorithm, p-exact search, locally prunes the next-token distribution and performs an exact search over the remaining space. the second algorithm, dynamic beam search, shrinks and expands the beam size according to the entropy of the candidate's probability distribution. despite the probabilistic intuition behind nucleus search, experiments on machine translation and summarization benchmarks show that both algorithms reach the same performance levels as standard beam search."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,                                                                        ,2021-07-20 ,2022-05-02 ,"['uri shaham', 'omer levy']"
2107.10716 ,"project achoo: a practical model and application for covid-19 detection   from recordings of breath, voice, and cough"                                                                 ,eess.sp cs.lg cs.sd eess.as                              ,"the covid-19 pandemic created a significant interest and demand for infection detection and monitoring solutions. in this paper we propose a machine learning method to quickly triage covid-19 using recordings made on consumer devices. the approach combines signal processing methods with fine-tuned deep learning networks and provides methods for signal denoising, cough detection and classification. we have also developed and deployed a mobile application that uses symptoms checker together with voice, breath and cough signals to detect covid-19 infection. the application showed robust performance on both open sourced datasets and on the noisy data collected during beta testing by the end users."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,10.1109/jstsp.2022.3142514                                              ,2021-07-12 ,2022-01-10 ,"['alexander ponomarchuk', 'ilya burenko', 'elian malkin', 'ivan nazarov', 'vladimir kokh', 'manvel avetisian', 'leonid zhukov']"
2107.13735 ,learning the temporal evolution of multivariate densities via   normalizing flows                                                                                                       ,stat.ml cs.lg math.ds math.pr                            ,"in this work, we propose a method to learn multivariate probability distributions using sample path data from stochastic differential equations. specifically, we consider temporally evolving probability distributions (e.g., those produced by integrating local or nonlocal fokker-planck equations). we analyze this evolution through machine learning assisted construction of a time-dependent mapping that takes a reference distribution (say, a gaussian) to each and every instance of our evolving distribution. if the reference distribution is the initial condition of a fokker-planck equation, what we learn is the time-t map of the corresponding solution. specifically, the learned map is a multivariate normalizing flow that deforms the support of the reference density to the support of each and every density snapshot in time. we demonstrate that this approach can approximate probability density function evolutions in time from observed sampled data for systems driven by both brownian and l\'evy noise. we present examples with two- and three-dimensional, uni- and multimodal distributions to validate the method."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,10.1063/5.0065093                                                       ,2021-07-29 ,2022-05-03 ,"['yubin lu', 'romit maulik', 'ting gao', 'felix dietrich', 'ioannis g. kevrekidis', 'jinqiao duan']"
2108.02671 ,visual domain adaptation for monocular depth estimation on   resource-constrained hardware                                                                                              ,cs.cv cs.lg                                              ,"real-world perception systems in many cases build on hardware with limited resources to adhere to cost and power limitations of their carrying system. deploying deep neural networks on resource-constrained hardware became possible with model compression techniques, as well as efficient and hardware-aware architecture design. however, model adaptation is additionally required due to the diverse operation environments. in this work, we address the problem of training deep neural networks on resource-constrained hardware in the context of visual domain adaptation. we select the task of monocular depth estimation where our goal is to transform a pre-trained model to the target's domain data. while the source domain includes labels, we assume an unlabelled target domain, as it happens in real-world applications. then, we present an adversarial learning approach that is adapted for training on the device with limited resources. since visual domain adaptation, i.e. neural network training, has not been previously explored for resource-constrained hardware, we present the first feasibility study for image-based depth estimation. our experiments show that visual domain adaptation is relevant only for efficient network architectures and training sets at the order of a few hundred samples. models and code are publicly available."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,10.1109/iccvw54120.2021.00111                                           ,2021-08-05 ,2022-05-05 ,"['julia hornauer', 'lazaros nalpantidis', 'vasileios belagiannis']"
2108.06325 ,continual backprop: stochastic gradient descent with persistent   randomness                                                                                                            ,cs.lg                                                    ,"the backprop algorithm for learning in neural networks utilizes two mechanisms: first, stochastic gradient descent and second, initialization with small random weights, where the latter is essential to the effectiveness of the former. we show that in continual learning setups, backprop performs well initially, but over time its performance degrades. stochastic gradient descent alone is insufficient to learn continually; the initial randomness enables only initial learning but not continual learning. to the best of our knowledge, ours is the first result showing this degradation in backprop's ability to learn. to address this degradation in backprop's plasticity, we propose an algorithm that continually injects random features alongside gradient descent using a new generate-and-test process. we call this the \textit{continual backprop} algorithm. we show that, unlike backprop, continual backprop is able to continually adapt in both supervised and reinforcement learning (rl) problems. continual backprop has the same computational complexity as backprop and can be seen as a natural extension of backprop for continual learning."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,                                                                        ,2021-08-13 ,2022-05-05 ,"['shibhansh dohare', 'richard s. sutton', 'a. rupam mahmood']"
2108.08230 ,predicting basin stability of power grids using graph neural networks                                                                                                                   ,physics.soc-ph cs.lg cs.sy eess.sy                       ,"the prediction of dynamical stability of power grids becomes more important and challenging with increasing shares of renewable energy sources due to their decentralized structure, reduced inertia and volatility. we investigate the feasibility of applying graph neural networks (gnn) to predict dynamic stability of synchronisation in complex power grids using the single-node basin stability (snbs) as a measure. to do so, we generate two synthetic datasets for grids with 20 and 100 nodes respectively and estimate snbs using monte-carlo sampling. those datasets are used to train and evaluate the performance of eight different gnn-models. all models use the full graph without simplifications as input and predict snbs in a nodal-regression-setup. we show that snbs can be predicted in general and the performance significantly changes using different gnn-models. furthermore, we observe interesting transfer capabilities of our approach: gnn-models trained on smaller grids can directly be applied on larger grids without the need of retraining."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,10.1088/1367-2630/ac54c9                                                ,2021-08-18 ,2022-05-05 ,"['christian nauck', 'michael lindner', 'konstantin schürholt', 'haoming zhang', 'paul schultz', 'jürgen kurths', 'ingrid isenhardt', 'frank hellmann']"
2108.08890 ,local latin hypercube refinement for multi-objective design uncertainty   optimization                                                                                                  ,stat.ml cs.lg physics.app-ph                             ,"optimizing the reliability and the robustness of a design is important but often unaffordable due to high sample requirements. surrogate models based on statistical and machine learning methods are used to increase the sample efficiency. however, for higher dimensional or multi-modal systems, surrogate models may also require a large amount of samples to achieve good results. we propose a sequential sampling strategy for the surrogate based solution of multi-objective reliability based robust design optimization problems. proposed local latin hypercube refinement (lolhr) strategy is model-agnostic and can be combined with any surrogate model because there is no free lunch but possibly a budget one. the proposed method is compared to stationary sampling as well as other proposed strategies from the literature. gaussian process and support vector regression are both used as surrogate models. empirical evidence is presented, showing that lolhr achieves on average better results compared to other surrogate based strategies on the tested examples."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,10.1016/j.asoc.2021.107807                                              ,2021-08-19 ,2022-05-05 ,"['can bogoclu', 'dirk roos', 'tamara nestorović']"
2108.10242 ,pattern inversion as a pattern recognition method for machine learning                                                                                                                  ,cs.cv cs.lg cs.ne                                        ,"artificial neural networks use a lot of coefficients that take a great deal of computing power for their adjustment, especially if deep learning networks are employed. however, there exist coefficients-free extremely fast indexing-based technologies that work, for instance, in google search engines, in genome sequencing, etc. the paper discusses the use of indexing-based methods for pattern recognition. it is shown that for pattern recognition applications such indexing methods replace with inverse patterns the fully inverted files, which are typically employed in search engines. not only such inversion provide automatic feature extraction, which is a distinguishing mark of deep learning, but, unlike deep learning, pattern inversion supports almost instantaneous learning, which is a consequence of absence of coefficients. the paper discusses a pattern inversion formalism that makes use on a novel pattern transform and its application for unsupervised instant learning. examples demonstrate a view-angle independent recognition of three-dimensional objects, such as cars, against arbitrary background, prediction of remaining useful life of aircraft engines, and other applications. in conclusion, it is noted that, in neurophysiology, the function of the neocortical mini-column has been widely debated since 1957. this paper hypothesize that, mathematically, the cortical mini-column can be described as an inverse pattern, which physically serves as a connection multiplier expanding associations of inputs with relevant pattern classes."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,10.1088/1742-6596/2224/1/012002                                         ,2021-08-15 ,           ,"['alexei mikhailov', 'mikhail karavay']"
2108.12129 ,parallel machine learning for forecasting the dynamics of complex   networks                                                                                                            ,cs.lg nlin.cd                                            ,forecasting the dynamics of large complex networks from previous time-series data is important in a wide range of contexts. here we present a machine learning scheme for this task using a parallel architecture that mimics the topology of the network of interest. we demonstrate the utility and scalability of our method implemented using reservoir computing on a chaotic network of oscillators. two levels of prior knowledge are considered: (i) the network links are known; and (ii) the network links are unknown and inferred via a data-driven approach to approximately optimize prediction.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,10.1103/physrevlett.128.164101                                          ,2021-08-27 ,           ,"['keshav srinivasan', 'nolan coble', 'joy hamlin', 'thomas antonsen', 'edward ott', 'michelle girvan']"
2108.13320 ,neural hmms are all you need (for high-quality attention-free tts)                                                                                                                      ,eess.as cs.hc cs.lg cs.sd                                ,"neural sequence-to-sequence tts has achieved significantly better output quality than statistical speech synthesis using hmms. however, neural tts is generally not probabilistic and uses non-monotonic attention. attention failures increase training time and can make synthesis babble incoherently. this paper describes how the old and new paradigms can be combined to obtain the advantages of both worlds, by replacing attention in neural tts with an autoregressive left-right no-skip hidden markov model defined by a neural network. based on this proposal, we modify tacotron 2 to obtain an hmm-based neural tts model with monotonic alignment, trained to maximise the full sequence likelihood without approximation. we also describe how to combine ideas from classical and contemporary tts for best results. the resulting example system is smaller and simpler than tacotron 2, and learns to speak with fewer iterations and less data, whilst achieving comparable naturalness prior to the post-net. our approach also allows easy control over speaking rate."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ,10.1109/icassp43922.2022.9746686                                        ,2021-08-30 ,2022-02-16 ,"['shivam mehta', 'éva székely', 'jonas beskow', 'gustav eje henter']"
2108.13323 ,fedkd: communication efficient federated learning via knowledge   distillation                                                                                                          ,cs.lg cs.cl                                              ,"federated learning is widely used to learn intelligent models from decentralized data. in federated learning, clients need to communicate their local model updates in each iteration of model learning. however, model updates are large in size if the model contains numerous parameters, and there usually needs many rounds of communication until model converges. thus, the communication cost in federated learning can be quite heavy. in this paper, we propose a communication efficient federated learning method based on knowledge distillation. instead of directly communicating the large models between clients and server, we propose an adaptive mutual distillation framework to reciprocally learn a student and a teacher model on each client, where only the student model is shared by different clients and updated collaboratively to reduce the communication cost. both the teacher and student on each client are learned on its local data and the knowledge distilled from each other, where their distillation intensities are controlled by their prediction quality. to further reduce the communication cost, we propose a dynamic gradient approximation method based on singular value decomposition to approximate the exchanged gradients with dynamic precision. extensive experiments on benchmark datasets in different tasks show that our approach can effectively reduce the communication cost and achieve competitive results."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ,10.1038/s41467-022-29763-x                                              ,2021-08-30 ,2022-04-24 ,"['chuhan wu', 'fangzhao wu', 'lingjuan lyu', 'yongfeng huang', 'xing xie']"
2109.00520 ,the role of explainability in assuring safety of machine learning in   healthcare                                                                                                       ,cs.lg cs.ai                                              ,"established approaches to assuring safety-critical systems and software are difficult to apply to systems employing ml where there is no clear, pre-defined specification against which to assess validity. this problem is exacerbated by the ""opaque"" nature of ml where the learnt model is not amenable to human scrutiny. explainable ai (xai) methods have been proposed to tackle this issue by producing human-interpretable representations of ml models which can help users to gain confidence and build trust in the ml system. however, little work explicitly investigates the role of explainability for safety assurance in the context of ml development. this paper identifies ways in which xai methods can contribute to safety assurance of ml-based systems. it then uses a concrete ml-based clinical decision support system, concerning weaning of patients from mechanical ventilation, to demonstrate how xai methods can be employed to produce evidence to support safety assurance. the results are also represented in a safety argument to show where, and in what way, xai methods can contribute to a safety case. overall, we conclude that xai methods have a valuable role in safety assurance of ml-based systems in healthcare but that they are not sufficient in themselves to assure safety."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2021-09-01 ,2022-05-05 ,"['yan jia', 'john mcdermid', 'tom lawton', 'ibrahim habli']"
2109.03697 ,u-fno -- an enhanced fourier neural operator-based deep-learning model   for multiphase flow                                                                                            ,physics.geo-ph cs.lg                                     ,"numerical simulation of multiphase flow in porous media is essential for many geoscience applications. machine learning models trained with numerical simulation data can provide a faster alternative to traditional simulators. here we present u-fno, a novel neural network architecture for solving multiphase flow problems with superior accuracy, speed, and data efficiency. u-fno is designed based on the newly proposed fourier neural operator (fno), which has shown excellent performance in single-phase flows. we extend the fno-based architecture to a highly complex co2-water multiphase problem with wide ranges of permeability and porosity heterogeneity, anisotropy, reservoir conditions, injection configurations, flow rates, and multiphase flow properties. the u-fno architecture is more accurate in gas saturation and pressure buildup predictions than the original fno and a state-of-the-art convolutional neural network (cnn) benchmark. meanwhile, it has superior data utilization efficiency, requiring only a third of the training data to achieve the equivalent accuracy as cnn. u-fno provides superior performance in highly heterogeneous geological formations and critically important applications such as gas saturation and pressure buildup ""fronts"" determination. the trained model can serve as a general-purpose alternative to routine numerical simulations of 2d-radial co2 injection problems with significant speed-ups than traditional simulators."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,                                                                        ,2021-09-03 ,2022-05-04 ,"['gege wen', 'zongyi li', 'kamyar azizzadenesheli', 'anima anandkumar', 'sally m. benson']"
2109.04266 ,an objective function for order preserving hierarchical clustering                                                                                                                      ,cs.lg math.co                                            ,"we present an objective function for similarity based hierarchical clustering of partially ordered data that preserves the partial order. that is, if $x \le y$, and if $[x]$ and $[y]$ are the respective clusters of $x$ and $y$, then there is an order relation $\le'$ on the clusters for which $[x] \le' |y]$. the theory distinguishes itself from existing theories for clustering of ordered data in that the order relation and the similarity are combined into a bi-objective optimisation problem to obtain a hierarchical clustering seeking to satisfy both. in particular, the order relation is weighted in the range $[0,1]$, and if the similarity and the order relation are not aligned, then order preservation may have to yield in favor of clustering. finding an optimal solution is np-hard, so we provide a polynomial time approximation algorithm, with a relative performance guarantee of $o\!\left(\log^{3/2} \!\!\, n \right)$, based on successive applications of directed sparsest cut. we provide a demonstration on a benchmark dataset, showing that our method outperforms existing methods for order preserving hierarchical clustering with significant margin. the theory is an extension of the dasgupta cost function for divisive hierarchical clustering."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ,                                                                        ,2021-09-09 ,2022-05-01 ,['daniel bakkelund']
2109.04392 ,fair conformal predictors for applications in medical imaging                                                                                                                           ,eess.iv cs.cv cs.lg                                      ,"deep learning has the potential to automate many clinically useful tasks in medical imaging. however translation of deep learning into clinical practice has been hindered by issues such as lack of the transparency and interpretability in these ""black box"" algorithms compared to traditional statistical methods. specifically, many clinical deep learning models lack rigorous and robust techniques for conveying certainty (or lack thereof) in their predictions -- ultimately limiting their appeal for extensive use in medical decision-making. furthermore, numerous demonstrations of algorithmic bias have increased hesitancy towards deployment of deep learning for clinical applications. to this end, we explore how conformal predictions can complement existing deep learning approaches by providing an intuitive way of expressing uncertainty while facilitating greater transparency to clinical users. in this paper, we conduct field interviews with radiologists to assess possible use-cases for conformal predictors. using insights gathered from these interviews, we devise two clinical use-cases and empirically evaluate several methods of conformal predictions on a dermatology photography dataset for skin lesion classification. we show how to modify conformal predictions to be more adaptive to subgroup differences in patient skin tones through equalized coverage. finally, we compare conformal prediction against measures of epistemic uncertainty."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ,                                                                        ,2021-09-09 ,2022-05-03 ,"['charles lu', 'andreanne lemay', 'ken chang', 'katharina hoebel', 'jayashree kalpathy-cramer']"
2109.04720 ,6mapnet: representing soccer players from tracking data by a triplet   network                                                                                                          ,cs.lg cs.ai                                              ,"although the values of individual soccer players have become astronomical, subjective judgments still play a big part in the player analysis. recently, there have been new attempts to quantitatively grasp players' styles using video-based event stream data. however, they have some limitations in scalability due to high annotation costs and sparsity of event stream data. in this paper, we build a triplet network named 6mapnet that can effectively capture the movement styles of players using in-game gps data. without any annotation of soccer-specific actions, we use players' locations and velocities to generate two types of heatmaps. our subnetworks then map these heatmap pairs into feature vectors whose similarity corresponds to the actual similarity of playing styles. the experimental results show that players can be accurately identified with only a small number of matches by our method."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,10.1007/978-3-031-02044-5_1                                             ,2021-09-10 ,           ,"['hyunsung kim', 'jihun kim', 'dongwook chung', 'jonghyun lee', 'jinsung yoon', 'sang-ki ko']"
2109.06368 ,policy optimization using semi-parametric models for dynamic pricing                                                                                                                    ,cs.lg econ.em math.oc stat.me stat.ml                    ,"in this paper, we study the contextual dynamic pricing problem where the market value of a product is linear in its observed features plus some market noise. products are sold one at a time, and only a binary response indicating success or failure of a sale is observed. our model setting is similar to javanmard and nazerzadeh [2019] except that we expand the demand curve to a semiparametric model and need to learn dynamically both parametric and nonparametric components. we propose a dynamic statistical learning and decision-making policy that combines semiparametric estimation from a generalized linear model with an unknown link and online decision-making to minimize regret (maximize revenue). under mild conditions, we show that for a market noise c.d.f. $f(\cdot)$ with $m$-th order derivative ($m\geq 2$), our policy achieves a regret upper bound of $\tilde{o}_{d}(t^{\frac{2m+1}{4m-1}})$, where $t$ is time horizon and $\tilde{o}_{d}$ is the order that hides logarithmic terms and the dimensionality of feature $d$. the upper bound is further reduced to $\tilde{o}_{d}(\sqrt{t})$ if $f$ is super smooth whose fourier transform decays exponentially. in terms of dependence on the horizon $t$, these upper bounds are close to $\omega(\sqrt{t})$, the lower bound where $f$ belongs to a parametric class. we further generalize these results to the case with dynamically dependent product features under the strong mixing condition."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,                                                                        ,2021-09-13 ,2022-05-03 ,"['jianqing fan', 'yongyi guo', 'mengxin yu']"
2109.07049 ,self-training with differentiable teacher                                                                                                                                               ,cs.cl cs.lg                                              ,"self-training achieves enormous success in various semi-supervised and weakly-supervised learning tasks. the method can be interpreted as a teacher-student framework, where the teacher generates pseudo-labels, and the student makes predictions. the two models are updated alternatingly. however, such a straightforward alternating update rule leads to training instability. this is because a small change in the teacher may result in a significant change in the student. to address this issue, we propose drift, short for differentiable self-training, that treats teacher-student as a stackelberg game. in this game, a leader is always in a more advantageous position than a follower. in self-training, the student contributes to the prediction performance, and the teacher controls the training process by generating pseudo-labels. therefore, we treat the student as the leader and the teacher as the follower. the leader procures its advantage by acknowledging the follower's strategy, which involves differentiable pseudo-labels and differentiable sample weights. consequently, the leader-follower interaction can be effectively captured via stackelberg gradient, obtained by differentiating the follower's strategy. experimental results on semi- and weakly-supervised classification and named entity recognition tasks show that our model outperforms existing approaches by large margins."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ,                                                                        ,2021-09-14 ,2022-05-03 ,"['simiao zuo', 'yue yu', 'chen liang', 'haoming jiang', 'siawpeng er', 'chao zhang', 'tuo zhao', 'hongyuan zha']"
2109.07703 ,ros-x-habitat: bridging the ros ecosystem with embodied ai                                                                                                                              ,cs.ro cs.ai cs.cv cs.lg                                  ,"we introduce ros-x-habitat, a software interface that bridges the ai habitat platform for embodied learning-based agents with other robotics resources via ros. this interface not only offers standardized communication protocols between embodied agents and simulators, but also enables physically and photorealistic simulation that benefits the training and/or testing of vision-based embodied agents. with this interface, roboticists can evaluate their own habitat rl agents in another ros-based simulator or use habitat sim v2 as the test bed for their own robotic algorithms. through in silico experiments, we demonstrate that ros-x-habitat has minimal impact on the navigation performance and simulation speed of a habitat rgbd agent; that a standard set of ros mapping, planning and navigation tools can run in habitat sim v2; and that a habitat agent can run in the standard ros simulator gazebo."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,                                                                        ,2021-09-15 ,2022-04-29 ,"['guanxiong chen', 'haoyu yang', 'ian m. mitchell']"
2109.08735 ,analyzing the habitable zones of circumbinary planets using machine   learning                                                                                                          ,astro-ph.ep astro-ph.im cs.lg                            ,"exoplanet detection in the past decade by efforts including nasa's kepler and tess missions has discovered many worlds that differ substantially from planets in our own solar system, including more than 150 exoplanets orbiting binary or multi-star systems. this not only broadens our understanding of the diversity of exoplanets, but also promotes our study of exoplanets in the complex binary systems and provides motivation to explore their habitability. in this study, we investigate the habitable zones of circumbinary planets based on planetary trajectory and dynamically informed habitable zones. our results indicate that the mass ratio and orbital eccentricity of binary stars are important factors affecting the orbital stability and habitability of planetary systems. moreover, planetary trajectory and dynamically informed habitable zones divide planetary habitability into three categories: habitable, part-habitable and uninhabitable. therefore, we train a machine learning model to quickly and efficiently classify these planetary systems."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ,10.3847/1538-4357/ac5c5a                                                ,2021-09-17 ,           ,"['zhihui kong', 'jonathan h. jiang', 'remo burn', 'kristen a. fahy', 'zonghong zhu']"
2109.11323 ,federated feature selection for cyber-physical systems of systems                                                                                                                       ,cs.lg cs.ni                                              ,"autonomous vehicles (avs) generate a massive amount of multi-modal data that once collected and processed through machine learning algorithms, enable ai-based services at the edge. in fact, not all these data contain valuable, and informative content but only a subset of the relative attributes should be exploited at the edge. therefore, enabling avs to locally extract such a subset is of utmost importance to limit computation and communication workloads. achieving a consistent subset of data in a distributed manner imposes the avs to cooperate in finding an agreement on what attributes should be sent to the edge. in this work, we address such a problem by proposing a federated feature selection algorithm where all the avs collaborate to filter out, iteratively, the redundant or irrelevant attributes in a distributed manner, without any exchange of raw data. this solution builds on two components: a mutual-information-based feature selection algorithm run by the avs and a novel aggregation function based on the bayes theorem executed on the edge. our federated feature selection algorithm provably converges to a solution in a finite number of steps. such an algorithm has been tested on two reference datasets: mav with images and inertial measurements of a monitored vehicle, wesad with a collection of samples from biophysical sensors to monitor a relative passenger. the numerical results show that the fleet finds a consensus with both the datasets on the minimum achievable subset of features, i.e., 24 out of 2166 (99\%) in mav and 4 out of 8 (50\%) in wesad, preserving the informative content of data."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2021-09-23 ,2022-05-02 ,"['pietro cassarà', 'alberto gotta', 'lorenzo valerio']"
2109.11661 ,deep reinforcement learning-based long-range autonomous valet parking   for smart cities                                                                                                ,cs.lg cs.ai                                              ,"in this paper, to reduce the congestion rate at the city center and increase the quality of experience (qoe) of each user, the framework of long-range autonomous valet parking (lavp) is presented, where an autonomous vehicle (av) is deployed in the city, which can pick up, drop off users at their required spots, and then drive to the car park out of city center autonomously. in this framework, we aim to minimize the overall distance of the av, while guarantee all users are served, i.e., picking up, and dropping off users at their required spots through optimizing the path planning of the av and number of serving time slots. to this end, we first propose a learning based algorithm, which is named as double-layer ant colony optimization (dl-aco) algorithm to solve the above problem in an iterative way. then, to make the real-time decision, while consider the dynamic environment (i.e., the av may pick up and drop off users from different locations), we further present a deep reinforcement learning (drl) based algorithm, which is known as deep q network (dqn). the experimental results show that the dl-aco and dqn-based algorithms both achieve the considerable performance."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,                                                                        ,2021-09-23 ,2022-05-04 ,"['muhammad khalid', 'liang wang', 'kezhi wang', 'cunhua pan', 'nauman aslam', 'yue cao']"
2109.11769 ,non-euclidean self-organizing maps                                                                                                                                                      ,cs.lg cs.ne math.gt                                      ,"self-organizing maps (soms, kohonen networks) belong to neural network models of the unsupervised class. in this paper, we present the generalized setup for non-euclidean soms. most data analysts take it for granted to use some subregions of a flat space as their data model; however, by the assumption that the underlying geometry is non-euclidean we obtain a new degree of freedom for the techniques that translate the similarities into spatial neighborhood relationships. we improve the traditional som algorithm by introducing topology-related extensions. our proposition can be successfully applied to dimension reduction, clustering or finding similarities in big data (both hierarchical and non-hierarchical)."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,                                                                        ,2021-09-24 ,2022-05-02 ,['dorota celińska-kopczyńska eryk kopczyński']
2109.14176 ,linear asymptotic convergence of anderson acceleration: fixed-point   analysis                                                                                                          ,math.oc cs.lg cs.na math.na                              ,"we study the asymptotic convergence of aa($m$), i.e., anderson acceleration with window size $m$ for accelerating fixed-point methods $x_{k+1}=q(x_{k})$, $x_k \in r^n$. convergence acceleration by aa($m$) has been widely observed but is not well understood. we consider the case where the fixed-point iteration function $q(x)$ is differentiable and the convergence of the fixed-point method itself is root-linear. we identify numerically several conspicuous properties of aa($m$) convergence: first, aa($m$) sequences $\{x_k\}$ converge root-linearly but the root-linear convergence factor depends strongly on the initial condition. second, the aa($m$) acceleration coefficients $\beta^{(k)}$ do not converge but oscillate as $\{x_k\}$ converges to $x^*$. to shed light on these observations, we write the aa($m$) iteration as an augmented fixed-point iteration $z_{k+1} =\psi(z_k)$, $z_k \in r^{n(m+1)}$ and analyze the continuity and differentiability properties of $\psi(z)$ and $\beta(z)$. we find that the vector of acceleration coefficients $\beta(z)$ is not continuous at the fixed point $z^*$. however, we show that, despite the discontinuity of $\beta(z)$, the iteration function $\psi(z)$ is lipschitz continuous and directionally differentiable at $z^*$ for aa(1), and we generalize this to aa($m$) with $m>1$ for most cases. furthermore, we find that $\psi(z)$ is not differentiable at $z^*$. we then discuss how these theoretical findings relate to the observed convergence behaviour of aa($m$). the discontinuity of $\beta(z)$ at $z^*$ allows $\beta^{(k)}$ to oscillate as $\{x_k\}$ converges to $x^*$, and the non-differentiability of $\psi(z)$ allows aa($m$) sequences to converge with root-linear convergence factors that strongly depend on the initial condition. additional numerical results illustrate our findings."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2021-09-28 ,2022-05-02 ,"['hans de sterck', 'yunhui he']"
2110.00135 ,useridentifier: implicit user representations for simple and effective   personalized sentiment analysis                                                                                ,cs.lg cs.ai cs.cl                                        ,"global models are trained to be as generalizable as possible, with user invariance considered desirable since the models are shared across multitudes of users. as such, these models are often unable to produce personalized responses for individual users, based on their data. contrary to widely-used personalization techniques based on few-shot learning, we propose useridentifier, a novel scheme for training a single shared model for all users. our approach produces personalized responses by adding fixed, non-trainable user identifiers to the input data. we empirically demonstrate that this proposed method outperforms the prefix-tuning based state-of-the-art approach by up to 13%, on a suite of sentiment analysis datasets. we also show that, unlike prior work, this method needs neither any additional model parameters nor any extra rounds of few-shot fine-tuning."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2021-09-30 ,2022-05-03 ,"['fatemehsadat mireshghallah', 'vaishnavi shrivastava', 'milad shokouhi', 'taylor berg-kirkpatrick', 'robert sim', 'dimitrios dimitriadis']"
2110.01517 ,skill induction and planning with latent language                                                                                                                                       ,cs.lg cs.ai cs.cl cs.cv cs.ro                            ,"we present a framework for learning hierarchical policies from demonstrations, using sparse natural language annotations to guide the discovery of reusable skills for autonomous decision-making. we formulate a generative model of action sequences in which goals generate sequences of high-level subtask descriptions, and these descriptions generate sequences of low-level actions. we describe how to train this model using primarily unannotated demonstrations by parsing demonstrations into sequences of named high-level subtasks, using only a small number of seed annotations to ground language in action. in trained models, natural language commands index a combinatorial library of skills; agents can use these skills to plan by generating high-level instruction sequences tailored to novel goals. we evaluate this approach in the alfred household simulation environment, providing natural language annotations for only 10% of demonstrations. it achieves task completion rates comparable to state-of-the-art models (outperforming several recent methods with access to ground-truth plans during training and evaluation) while providing structured and human-readable high-level plans."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,                                                                        ,2021-10-04 ,2022-05-02 ,"['pratyusha sharma', 'antonio torralba', 'jacob andreas']"
2110.02068 ,spatial context awareness for unsupervised change detection in optical   satellite images                                                                                               ,cs.cv cs.lg                                              ,"detecting changes on the ground in multitemporal earth observation data is one of the key problems in remote sensing. in this paper, we introduce sibling regression for optical change detection (siroc), an unsupervised method for change detection in optical satellite images with medium and high resolution. siroc is a spatial context-based method that models a pixel as a linear combination of its distant neighbors. it uses this model to analyze differences in the pixel and its spatial context-based predictions in subsequent time periods for change detection. we combine this spatial context-based change detection with ensembling over mutually exclusive neighborhoods and transitioning from pixel to object-level changes with morphological operations. siroc achieves competitive performance for change detection with medium-resolution sentinel-2 and high-resolution planetscope imagery on four datasets. besides accurate predictions without the need for training, siroc also provides a well-calibrated uncertainty of its predictions. this makes the method especially useful in conjunction with deep-learning based methods for applications such as pseudo-labeling."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,10.1109/tgrs.2021.3130842                                               ,2021-10-05 ,           ,"['lukas kondmann', 'aysim toker', 'sudipan saha', 'bernhard schölkopf', 'laura leal-taixé', 'xiao xiang zhu']"
2110.04495 ,multi-agent mdp homomorphic networks                                                                                                                                                    ,cs.lg cs.ma                                              ,"this paper introduces multi-agent mdp homomorphic networks, a class of networks that allows distributed execution using only local information, yet is able to share experience between global symmetries in the joint state-action space of cooperative multi-agent systems. in cooperative multi-agent systems, complex symmetries arise between different configurations of the agents and their local observations. for example, consider a group of agents navigating: rotating the state globally results in a permutation of the optimal joint policy. existing work on symmetries in single agent reinforcement learning can only be generalized to the fully centralized setting, because such approaches rely on the global symmetry in the full state-action spaces, and these can result in correspondences across agents. to encode such symmetries while still allowing distributed execution we propose a factorization that decomposes global symmetries into local transformations. our proposed factorization allows for distributing the computation that enforces global symmetries over local agents and local interactions. we introduce a multi-agent equivariant policy network based on this factorization. we show empirically on symmetric multi-agent problems that globally symmetric distributable policies improve data efficiency compared to non-equivariant baselines."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2021-10-09 ,2022-04-29 ,"['elise van der pol', 'herke van hoof', 'frans a. oliehoek', 'max welling']"
2110.06177 ,tracking the risk of a deployed model and detecting harmful distribution   shifts                                                                                                       ,stat.ml cs.lg                                            ,"when deployed in the real world, machine learning models inevitably encounter changes in the data distribution, and certain -- but not all -- distribution shifts could result in significant performance degradation. in practice, it may make sense to ignore benign shifts, under which the performance of a deployed model does not degrade substantially, making interventions by a human expert (or model retraining) unnecessary. while several works have developed tests for distribution shifts, these typically either use non-sequential methods, or detect arbitrary shifts (benign or harmful), or both. we argue that a sensible method for firing off a warning has to both (a) detect harmful shifts while ignoring benign ones, and (b) allow continuous monitoring of model performance without increasing the false alarm rate. in this work, we design simple sequential tools for testing if the difference between source (training) and target (test) distributions leads to a significant increase in a risk function of interest, like accuracy or calibration. recent advances in constructing time-uniform confidence sequences allow efficient aggregation of statistical evidence accumulated during the tracking process. the designed framework is applicable in settings where (some) true labels are revealed after the prediction is performed, or when batches of labels become available in a delayed fashion. we demonstrate the efficacy of the proposed framework through an extensive empirical study on a collection of simulated and real datasets."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,                                                                        ,2021-10-12 ,2022-05-05 ,"['aleksandr podkopaev', 'aaditya ramdas']"
2110.06986 ,admm-dad net: a deep unfolding network for analysis compressed sensing                                                                                                                  ,cs.it cs.cv cs.ir cs.lg math.it                          ,"in this paper, we propose a new deep unfolding neural network based on the admm algorithm for analysis compressed sensing. the proposed network jointly learns a redundant analysis operator for sparsification and reconstructs the signal of interest. we compare our proposed network with a state-of-the-art unfolded ista decoder, that also learns an orthogonal sparsifier. moreover, we consider not only image, but also speech datasets as test examples. computational experiments demonstrate that our proposed network outperforms the state-of-the-art deep unfolding network, consistently for both real-world image and speech datasets."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,10.1109/icassp43922.2022.9747096                                        ,2021-10-13 ,2022-05-02 ,"['vasiliki kouni', 'georgios paraskevopoulos', 'holger rauhut', 'george c. alexandropoulos']"
2110.07392 ,provably efficient multi-agent reinforcement learning with fully   decentralized communication                                                                                          ,cs.lg cs.ma math.oc                                      ,"a challenge in reinforcement learning (rl) is minimizing the cost of sampling associated with exploration. distributed exploration reduces sampling complexity in multi-agent rl (marl). we investigate the benefits to performance in marl when exploration is fully decentralized. specifically, we consider a class of online, episodic, tabular $q$-learning problems under time-varying reward and transition dynamics, in which agents can communicate in a decentralized manner.we show that group performance, as measured by the bound on regret, can be significantly improved through communication when each agent uses a decentralized message-passing protocol, even when limited to sending information up to its $\gamma$-hop neighbors. we prove regret and sample complexity bounds that depend on the number of agents, communication network structure and $\gamma.$ we show that incorporating more agents and more information sharing into the group learning scheme speeds up convergence to the optimal policy. numerical simulations illustrate our results and validate our theoretical claims."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2021-10-14 ,2022-05-02 ,"['justin lidard', 'udari madhushani', 'naomi ehrich leonard']"
2110.07409 ,the geometry of memoryless stochastic policy optimization in   infinite-horizon pomdps                                                                                                  ,math.oc cs.lg math.ag                                    ,"we consider the problem of finding the best memoryless stochastic policy for an infinite-horizon partially observable markov decision process (pomdp) with finite state and action spaces with respect to either the discounted or mean reward criterion. we show that the (discounted) state-action frequencies and the expected cumulative reward are rational functions of the policy, whereby the degree is determined by the degree of partial observability. we then describe the optimization problem as a linear optimization problem in the space of feasible state-action frequencies subject to polynomial constraints that we characterize explicitly. this allows us to address the combinatorial and geometric complexity of the optimization problem using recent tools from polynomial optimization. in particular, we estimate the number of critical points and use the polynomial programming description of reward maximization to solve a navigation problem in a grid world."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,                                                                        ,2021-10-14 ,2022-04-29 ,"['johannes müller', 'guido montúfar']"
2110.07537 ,toward degradation-robust voice conversion                                                                                                                                              ,eess.as cs.lg cs.sd                                      ,"any-to-any voice conversion technologies convert the vocal timbre of an utterance to any speaker even unseen during training. although there have been several state-of-the-art any-to-any voice conversion models, they were all based on clean utterances to convert successfully. however, in real-world scenarios, it is difficult to collect clean utterances of a speaker, and they are usually degraded by noises or reverberations. it thus becomes highly desired to understand how these degradations affect voice conversion and build a degradation-robust model. we report in this paper the first comprehensive study on the degradation robustness of any-to-any voice conversion. we show that the performance of state-of-the-art models nowadays was severely hampered given degraded utterances. to this end, we then propose speech enhancement concatenation and denoising training to improve the robustness. in addition to common degradations, we also consider adversarial noises, which alter the model output significantly yet are human-imperceptible. it was shown that both concatenations with off-the-shelf speech enhancement models and denoising training on voice conversion models could improve the robustness, while each of them had pros and cons."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ,                                                                        ,2021-10-14 ,2022-04-29 ,"['chien-yu huang', 'kai-wei chang', 'hung-yi lee']"
2110.07731 ,ccqa: a new web-scale question answering dataset for model pre-training                                                                                                                 ,cs.cl cs.lg                                              ,"with the rise of large-scale pre-trained language models, open-domain question-answering (odqa) has become an important research topic in nlp. based on the popular pre-training fine-tuning approach, we posit that an additional in-domain pre-training stage using a large-scale, natural, and diverse question-answering (qa) dataset can be beneficial for odqa. consequently, we propose a novel qa dataset based on the common crawl project in this paper. using the readily available schema.org annotation, we extract around 130 million multilingual question-answer pairs, including about 60 million english data-points. with this previously unseen number of natural qa pairs, we pre-train popular language models to show the potential of large-scale in-domain pre-training for the task of question-answering. in our experiments, we find that pre-training question-answering models on our common crawl question answering dataset (ccqa) achieves promising results in zero-shot, low resource and fine-tuned settings across multiple tasks, models and benchmarks."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,                                                                        ,2021-10-14 ,2022-05-02 ,"['patrick huber', 'armen aghajanyan', 'barlas oğuz', 'dmytro okhonko', 'wen-tau yih', 'sonal gupta', 'xilun chen']"
2110.07732 ,the neural data router: adaptive control flow in transformers improves   systematic generalization                                                                                      ,cs.lg cs.ai cs.ne                                        ,"despite progress across a broad range of applications, transformers have limited success in systematic generalization. the situation is especially frustrating in the case of algorithmic tasks, where they often fail to find intuitive solutions that route relevant information to the right node/operation at the right time in the grid represented by transformer columns. to facilitate the learning of useful control flow, we propose two modifications to the transformer architecture, copy gate and geometric attention. our novel neural data router (ndr) achieves 100% length generalization accuracy on the classic compositional table lookup task, as well as near-perfect accuracy on the simple arithmetic task and a new variant of listops testing for generalization across computational depths. ndr's attention and gating patterns tend to be interpretable as an intuitive form of neural routing. our code is public."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,                                                                        ,2021-10-14 ,2022-05-05 ,"['róbert csordás', 'kazuki irie', 'jürgen schmidhuber']"
2110.11323 ,stylealign: analysis and applications of aligned stylegan models                                                                                                                        ,cs.cv cs.gr cs.lg                                        ,"in this paper, we perform an in-depth study of the properties and applications of aligned generative models. we refer to two models as aligned if they share the same architecture, and one of them (the child) is obtained from the other (the parent) via fine-tuning to another domain, a common practice in transfer learning. several works already utilize some basic properties of aligned stylegan models to perform image-to-image translation. here, we perform the first detailed exploration of model alignment, also focusing on stylegan. first, we empirically analyze aligned models and provide answers to important questions regarding their nature. in particular, we find that the child model's latent spaces are semantically aligned with those of the parent, inheriting incredibly rich semantics, even for distant data domains such as human faces and churches. second, equipped with this better understanding, we leverage aligned models to solve a diverse set of tasks. in addition to image translation, we demonstrate fully automatic cross-domain image morphing. we further show that zero-shot vision tasks may be performed in the child domain, while relying exclusively on supervision in the parent domain. we demonstrate qualitatively and quantitatively that our approach yields state-of-the-art results, while requiring only simple fine-tuning and inversion."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,                                                                        ,2021-10-21 ,2022-05-05 ,"['zongze wu', 'yotam nitzan', 'eli shechtman', 'dani lischinski']"
2110.11945 ,soft: softmax-free transformer with linear complexity                                                                                                                                   ,cs.cv cs.ai cs.lg                                        ,"vision transformers (vits) have pushed the state-of-the-art for various visual recognition tasks by patch-wise image tokenization followed by self-attention. however, the employment of self-attention modules results in a quadratic complexity in both computation and memory usage. various attempts on approximating the self-attention computation with linear complexity have been made in natural language processing. however, an in-depth analysis in this work shows that they are either theoretically flawed or empirically ineffective for visual recognition. we further identify that their limitations are rooted in keeping the softmax self-attention during approximations. specifically, conventional self-attention is computed by normalizing the scaled dot-product between token feature vectors. keeping this softmax operation challenges any subsequent linearization efforts. based on this insight, for the first time, a softmax-free transformer or soft is proposed. to remove softmax in self-attention, gaussian kernel function is used to replace the dot-product similarity without further normalization. this enables a full self-attention matrix to be approximated via a low-rank matrix decomposition. the robustness of the approximation is achieved by calculating its moore-penrose inverse using a newton-raphson method. extensive experiments on imagenet show that our soft significantly improves the computational efficiency of existing vit variants. crucially, with a linear complexity, much longer token sequences are permitted in soft, resulting in superior trade-off between accuracy and complexity."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ,                                                                        ,2021-10-22 ,2022-04-30 ,"['jiachen lu', 'jinghan yao', 'junge zhang', 'xiatian zhu', 'hang xu', 'weiguo gao', 'chunjing xu', 'tao xiang', 'li zhang']"
2110.14457 ,direct then diffuse: incremental unsupervised skill discovery for state   covering and goal reaching                                                                                    ,cs.lg                                                    ,"learning meaningful behaviors in the absence of reward is a difficult problem in reinforcement learning. a desirable and challenging unsupervised objective is to learn a set of diverse skills that provide a thorough coverage of the state space while being directed, i.e., reliably reaching distinct regions of the environment. in this paper, we build on the mutual information framework for skill discovery and introduce upside, which addresses the coverage-directedness trade-off in the following ways: 1) we design policies with a decoupled structure of a directed skill, trained to reach a specific region, followed by a diffusing part that induces a local coverage. 2) we optimize policies by maximizing their number under the constraint that each of them reaches distinct regions of the environment (i.e., they are sufficiently discriminable) and prove that this serves as a lower bound to the original mutual information objective. 3) finally, we compose the learned directed skills into a growing tree that adaptively covers the environment. we illustrate in several navigation and control environments how the skills learned by upside solve sparse-reward downstream tasks better than existing baselines."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,                                                                        ,2021-10-27 ,2022-04-30 ,"['pierre-alexandre kamienny', 'jean tarbouriech', 'sylvain lamprier', 'alessandro lazaric', 'ludovic denoyer']"
2110.14621 ,fairer lp-based online allocation via analytic center                                                                                                                                   ,cs.ds cs.cy cs.lg math.oc                                ,"in this paper, we consider an online resource allocation problem where a decision maker accepts or rejects incoming customer requests irrevocably in order to maximize expected reward given limited resources. at each time, a new order/customer/bid is revealed with a request of some resource(s) and a reward. we consider a stochastic setting where all the orders are i.i.d. sampled from an unknown distribution. such formulation arises from many classic applications such as the canonical (quantity-based) network revenue management problem and the adwords problem. while the literature on the topic mainly focuses on regret minimization, our paper considers the \textit{fairness} aspect of the problem. on a high level, we define the fairness in a way that a fair online algorithm should treat similar agents/customers similarly, and the decision made for similar agents/customers should be consistent over time. to achieve this goal, we define the fair offline solution as the analytic center of the offline optimal solution set, and introduce \textit{cumulative unfairness} as the cumulative deviation from the online solutions to the fair offline solution over time. we propose a fair algorithm based on an interior-point lp solver and a mechanism that dynamically detects unfair resource spending. our algorithm achieves cumulative unfairness on the scale of order $o(\log(t))$, while maintains the regret to be bounded without dependency on $t$. in addition, compared to the literature, our result is produced under less restrictive assumptions on the degeneracy of the underlying linear program."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,                                                                        ,2021-10-27 ,2022-05-02 ,"['guanting chen', 'xiaocheng li', 'yinyu ye']"
2110.14782 ,when is bert multilingual? isolating crucial ingredients for   cross-lingual transfer                                                                                                   ,cs.cl cs.lg                                              ,"while recent work on multilingual language models has demonstrated their capacity for cross-lingual zero-shot transfer on downstream tasks, there is a lack of consensus in the community as to what shared properties between languages enable such transfer. analyses involving pairs of natural languages are often inconclusive and contradictory since languages simultaneously differ in many linguistic aspects. in this paper, we perform a large-scale empirical study to isolate the effects of various linguistic properties by measuring zero-shot transfer between four diverse natural languages and their counterparts constructed by modifying aspects such as the script, word order, and syntax. among other things, our experiments show that the absence of sub-word overlap significantly affects zero-shot transfer when languages differ in their word order, and there is a strong correlation between transfer performance and word embedding alignment between languages (e.g., r=0.94 on the task of nli). our results call for focus in multilingual models on explicitly improving word embedding alignment between languages rather than relying on its implicit emergence."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ,                                                                        ,2021-10-27 ,2022-05-03 ,"['ameet deshpande', 'partha talukdar', 'karthik narasimhan']"
2110.14993 ,using time-series privileged information for provably efficient learning   of prediction models                                                                                         ,cs.lg stat.ml                                            ,"we study prediction of future outcomes with supervised models that use privileged information during learning. the privileged information comprises samples of time series observed between the baseline time of prediction and the future outcome; this information is only available at training time which differs from the traditional supervised learning. our question is when using this privileged data leads to more sample-efficient learning of models that use only baseline data for predictions at test time. we give an algorithm for this setting and prove that when the time series are drawn from a non-stationary gaussian-linear dynamical system of fixed horizon, learning with privileged information is more efficient than learning without it. on synthetic data, we test the limits of our algorithm and theory, both when our assumptions hold and when they are violated. on three diverse real-world datasets, we show that our approach is generally preferable to classical learning, particularly when data is scarce. finally, we relate our estimator to a distillation approach both theoretically and empirically."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2021-10-28 ,2022-05-05 ,"['rickard k. a. karlsson', 'martin willbo', 'zeshan hussain', 'rahul g. krishnan', 'david sontag', 'fredrik d. johansson']"
2110.15105 ,a game-theoretic approach for improving generalization ability of tsp   solvers                                                                                                         ,cs.lg                                                    ,"in this paper, we introduce a two-player zero-sum framework between a trainable \emph{solver} and a \emph{data generator} to improve the generalization ability of deep learning-based solvers for traveling salesman problem (tsp). grounded in \textsl{policy space response oracle} (psro) methods, our two-player framework outputs a population of best-responding solvers, over which we can mix and output a combined model that achieves the least exploitability against the generator, and thereby the most generalizable performance on different tsp tasks. we conduct experiments on a variety of tsp instances with different types and sizes. results suggest that our solvers achieve the state-of-the-art performance even on tasks the solver never meets, whilst the performance of other deep learning-based solvers drops sharply due to over-fitting. to demonstrate the principle of our framework, we study the learning outcome of the proposed two-player game and demonstrate that the exploitability of the solver population decreases during training, and it eventually approximates the nash equilibrium along with the generator."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,                                                                        ,2021-10-28 ,2022-05-04 ,"['chenguang wang', 'yaodong yang', 'oliver slumbers', 'congying han', 'tiande guo', 'haifeng zhang', 'jun wang']"
2111.01533 ,a comparison of mixed-variables bayesian optimization approaches                                                                                                                        ,math.oc cs.lg stat.ap stat.co stat.ml                    ,"most real optimization problems are defined over a mixed search space where the variables are both discrete and continuous. in engineering applications, the objective function is typically calculated with a numerically costly black-box simulation.general mixed and costly optimization problems are therefore of a great practical interest, yet their resolution remains in a large part an open scientific question. in this article, costly mixed problems are approached through gaussian processes where the discrete variables are relaxed into continuous latent variables. the continuous space is more easily harvested by classical bayesian optimization techniques than a mixed space would. discrete variables are recovered either subsequently to the continuous optimization, or simultaneously with an additional continuous-discrete compatibility constraint that is handled with augmented lagrangians. several possible implementations of such bayesian mixed optimizers are compared. in particular, the reformulation of the problem with continuous latent variables is put in competition with searches working directly in the mixed space. among the algorithms involving latent variables and an augmented lagrangian, a particular attention is devoted to the lagrange multipliers for which a local and a global estimation techniques are studied. the comparisons are based on the repeated optimization of three analytical functions and a beam design problem."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ,                                                                        ,2021-10-30 ,2022-05-03 ,"['jhouben cuesta-ramirez', 'rodolphe le riche', 'olivier roustant', 'guillaume perrin', 'cedric durantin', 'alain gliere']"
2111.02278 ,mean-field analysis of piecewise linear solutions for wide relu networks                                                                                                                ,cs.lg stat.ml                                            ,"understanding the properties of neural networks trained via stochastic gradient descent (sgd) is at the heart of the theory of deep learning. in this work, we take a mean-field view, and consider a two-layer relu network trained via sgd for a univariate regularized regression problem. our main result is that sgd is biased towards a simple solution: at convergence, the relu network implements a piecewise linear map of the inputs, and the number of ""knot"" points - i.e., points where the tangent of the relu network estimator changes - between two consecutive training inputs is at most three. in particular, as the number of neurons of the network grows, the sgd dynamics is captured by the solution of a gradient flow and, at convergence, the distribution of the weights approaches the unique minimizer of a related free energy, which has a gibbs form. our key technical contribution consists in the analysis of the estimator resulting from this minimizer: we show that its second derivative vanishes everywhere, except at some specific locations which represent the ""knot"" points. we also provide empirical evidence that knots at locations distinct from the data points might occur, as predicted by our theory."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ,                                                                        ,2021-11-03 ,2022-04-29 ,"['alexander shevchenko', 'vyacheslav kungurtsev', 'marco mondelli']"
2111.05826 ,palette: image-to-image diffusion models                                                                                                                                                ,cs.cv cs.lg                                              ,"this paper develops a unified framework for image-to-image translation based on conditional diffusion models and evaluates this framework on four challenging image-to-image translation tasks, namely colorization, inpainting, uncropping, and jpeg restoration. our simple implementation of image-to-image diffusion models outperforms strong gan and regression baselines on all tasks, without task-specific hyper-parameter tuning, architecture customization, or any auxiliary loss or sophisticated new techniques needed. we uncover the impact of an l2 vs. l1 loss in the denoising diffusion objective on sample diversity, and demonstrate the importance of self-attention in the neural architecture through empirical studies. importantly, we advocate a unified evaluation protocol based on imagenet, with human evaluation and sample quality scores (fid, inception score, classification accuracy of a pre-trained resnet-50, and perceptual distance against original images). we expect this standardized evaluation protocol to play a role in advancing image-to-image translation research. finally, we show that a generalist, multi-task diffusion model performs as well or better than task-specific specialist counterparts. check out https://diffusion-palette.github.io for an overview of the results."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ,                                                                        ,2021-11-10 ,2022-05-03 ,"['chitwan saharia', 'william chan', 'huiwen chang', 'chris a. lee', 'jonathan ho', 'tim salimans', 'david j. fleet', 'mohammad norouzi']"
2111.06592 ,implicit vs unfolded graph neural networks                                                                                                                                              ,cs.lg                                                    ,"it has been observed that graph neural networks (gnn) sometimes struggle to maintain a healthy balance between the efficient modeling long-range dependencies across nodes while avoiding unintended consequences such oversmoothed node representations or sensitivity to spurious edges. to address this issue (among other things), two separate strategies have recently been proposed, namely implicit and unfolded gnns. the former treats node representations as the fixed points of a deep equilibrium model that can efficiently facilitate arbitrary implicit propagation across the graph with a fixed memory footprint. in contrast, the latter involves treating graph propagation as unfolded descent iterations as applied to some graph-regularized energy function. while motivated differently, in this paper we carefully quantify explicit situations where the solutions they produce are equivalent and others where their properties sharply diverge. this includes the analysis of convergence, representational capacity, and interpretability. in support of this analysis, we also provide empirical head-to-head comparisons across multiple synthetic and public real-world node classification benchmarks. these results indicate that while ignn is substantially more memory-efficient, ugnn models support unique, integrated graph attention mechanisms and propagation rules that can achieve sota node classification accuracy across disparate regimes such as adversarially-perturbed graphs, graphs with heterophily, and graphs involving long-range dependencies."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,                                                                        ,2021-11-12 ,2022-05-02 ,"['yongyi yang', 'tang liu', 'yangkun wang', 'zengfeng huang', 'david wipf']"
2111.08693 ,inverting brain grey matter models with likelihood-free inference: a   tool for trustable cytoarchitecture measurements                                                                 ,q-bio.qm cs.lg                                           ,"effective characterisation of the brain grey matter cytoarchitecture with quantitative sensitivity to soma density and volume remains an unsolved challenge in diffusion mri (dmri). solving the problem of relating the dmri signal with cytoarchitectural characteristics calls for the definition of a mathematical model that describes brain tissue via a handful of physiologically-relevant parameters and an algorithm for inverting the model. to address this issue, we propose a new forward model, specifically a new system of equations, requiring a few relatively sparse b-shells. we then apply modern tools from bayesian analysis known as likelihood-free inference (lfi) to invert our proposed model. as opposed to other approaches from the literature, our algorithm yields not only an estimation of the parameter vector $\theta$ that best describes a given observed data point $x_0$, but also a full posterior distribution $p(\theta|x_0)$ over the parameter space. this enables a richer description of the model inversion, providing indicators such as credible intervals for the estimated parameters and a complete characterization of the parameter regions where the model may present indeterminacies. we approximate the posterior distribution using deep neural density estimators, known as normalizing flows, and fit them using a set of repeated simulations from the forward model. we validate our approach on simulations using dmipy and then apply the whole pipeline on two publicly available datasets."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,                                                                        ,2021-11-15 ,2022-05-04 ,"['maëliss jallais', 'pedro luiz coelho rodrigues', 'alexandre gramfort', 'demian wassermann']"
2111.11954 ,depth induces scale-averaging in overparameterized linear bayesian   neural networks                                                                                                    ,cs.lg stat.ml                                            ,"inference in deep bayesian neural networks is only fully understood in the infinite-width limit, where the posterior flexibility afforded by increased depth washes out and the posterior predictive collapses to a shallow gaussian process. here, we interpret finite deep linear bayesian neural networks as data-dependent scale mixtures of gaussian process predictors across output channels. we leverage this observation to study representation learning in these networks, allowing us to connect limiting results obtained in previous studies within a unified framework. in total, these results advance our analytical understanding of how depth affects inference in a simple class of bayesian neural networks."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,10.1109/ieeeconf53345.2021.9723137                                      ,2021-11-23 ,           ,"['jacob a. zavatone-veth', 'cengiz pehlevan']"
2111.13955 ,a recommender system-inspired cloud data filling scheme for   satellite-based coastal observation                                                                                       ,cs.lg eess.iv stat.ap                                    ,"filling missing data in cloud-covered areas of satellite imaging is an important task to improve data quantity and quality for enhanced earth observation. traditional cloud filling studies focused on continuous numerical data such as temperature and cyanobacterial concentration in the open ocean. cloud data filling issues in coastal imaging is far less studied because of the complex landscape. inspired by the success of data imputation methods in recommender systems that are designed for online shopping, the present study explored their application to satellite cloud data filling tasks. a numerical experiment was designed and conducted for a landsat dataset with a range of synthetic cloud covers to examine the performance of different data filling schemes. the recommender system-inspired matrix factorization algorithm called funk-svd showed superior performance in computational accuracy and efficiency for the task of recovering landscape types in a complex coastal area than the traditional data filling scheme of dineof (data interpolating empirical orthogonal functions) and the deep learning method of datawig. the new method achieved the best filling accuracy and reached a speed comparable to dineof and much faster than deep learning. a theoretical framework was created to analyze the error propagation in dineof and found the algorithm needs to be modified to converge to the ground truth. the present study showed that funk-svd has great potential to enhance cloud data filling performance and connects the fields of recommender systems and cloud filling to promote the improvement and sharing of useful algorithms."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ,10.1016/j.jag.2022.102770                                               ,2021-11-27 ,2021-12-09 ,['ruo-qian wang']
2111.14680 ,graph embedding via high dimensional model representation for   hyperspectral images                                                                                                    ,cs.cv cs.lg eess.iv                                      ,"learning the manifold structure of remote sensing images is of paramount relevance for modeling and understanding processes, as well as to encapsulate the high dimensionality in a reduced set of informative features for subsequent classification, regression, or unmixing. manifold learning methods have shown excellent performance to deal with hyperspectral image (hsi) analysis but, unless specifically designed, they cannot provide an explicit embedding map readily applicable to out-of-sample data. a common assumption to deal with the problem is that the transformation between the high-dimensional input space and the (typically low) latent space is linear. this is a particularly strong assumption, especially when dealing with hyperspectral images due to the well-known nonlinear nature of the data. to address this problem, a manifold learning method based on high dimensional model representation (hdmr) is proposed, which enables to present a nonlinear embedding function to project out-of-sample samples into the latent space. the proposed method is compared to manifold learning methods along with its linear counterparts and achieves promising performance in terms of classification accuracy of a representative set of hyperspectral images."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,10.1109/tgrs.2021.3133957                                               ,2021-11-29 ,           ,"['gulsen taskin', 'gustau camps-valls']"
2112.00133 ,pokebnn: a binary pursuit of lightweight accuracy                                                                                                                                       ,cs.lg cs.cv                                              ,"optimization of top-1 imagenet promotes enormous networks that may be impractical in inference settings. binary neural networks (bnns) have the potential to significantly lower the compute intensity but existing models suffer from low quality. to overcome this deficiency, we propose pokeconv, a binary convolution block which improves quality of bnns by techniques such as adding multiple residual paths, and tuning the activation function. we apply it to resnet-50 and optimize resnet's initial convolutional layer which is hard to binarize. we name the resulting network family pokebnn. these techniques are chosen to yield favorable improvements in both top-1 accuracy and the network's cost. in order to enable joint optimization of the cost together with accuracy, we define arithmetic computation effort (ace), a hardware- and energy-inspired cost metric for quantized and binarized networks. we also identify a need to optimize an under-explored hyper-parameter controlling the binarization gradient approximation.   we establish a new, strong state-of-the-art (sota) on top-1 accuracy together with commonly-used cpu64 cost, ace cost and network size metrics. reactnet-adam, the previous sota in bnns, achieved a 70.5% top-1 accuracy with 7.9 ace. a small variant of pokebnn achieves 70.5% top-1 with 2.6 ace, more than 3x reduction in cost; a larger pokebnn achieves 75.6% top-1 with 7.8 ace, more than 5% improvement in accuracy without increasing the cost. pokebnn implementation in jax/flax and reproduction instructions are available in aqt repository: https://github.com/google/aqt"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,                                                                        ,2021-11-30 ,2022-04-28 ,"['yichi zhang', 'zhiru zhang', 'lukasz lew']"
2112.00195 ,efficient online bayesian inference for neural bandits                                                                                                                                  ,cs.lg                                                    ,"in this paper we present a new algorithm for online (sequential) inference in bayesian neural networks, and show its suitability for tackling contextual bandit problems. the key idea is to combine the extended kalman filter (which locally linearizes the likelihood function at each time step) with a (learned or random) low-dimensional affine subspace for the parameters; the use of a subspace enables us to scale our algorithm to models with $\sim 1m$ parameters. while most other neural bandit methods need to store the entire past dataset in order to avoid the problem of ""catastrophic forgetting"", our approach uses constant memory. this is possible because we represent uncertainty about all the parameters in the model, not just the final linear layer. we show good results on the ""deep bayesian bandit showdown"" benchmark, as well as mnist and a recommender system."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,                                                                        ,2021-11-30 ,           ,"['gerardo duran-martin', 'aleyna kara', 'kevin murphy']"
2112.00398 ,effective and efficient structure learning with pruning and model   averaging strategies                                                                                                ,cs.lg cs.ai                                              ,"learning the structure of a bayesian network (bn) with score-based solutions involves exploring the search space of possible graphs and moving towards the graph that maximises a given objective function. some algorithms offer exact solutions that guarantee to return the graph with the highest objective score, while others offer approximate solutions in exchange for reduced computational complexity. this paper describes an approximate bn structure learning algorithm, which we call model averaging hill-climbing (mahc), that combines two novel strategies with hill-climbing search. the algorithm starts by pruning the search space of graphs, where the pruning strategy can be viewed as an aggressive version of the pruning strategies that are typically applied to combinatorial optimisation structure learning problems. it then performs model averaging in the hill-climbing search process and moves to the neighbouring graph that maximises the objective function, on average, for that neighbouring graph and over all its valid neighbouring graphs. comparisons with other algorithms spanning different classes of learning suggest that the combination of aggressive pruning with model averaging is both effective and efficient, particularly in the presence of data noise."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2021-12-01 ,2022-04-30 ,"['anthony c. constantinou', 'yang liu', 'neville k. kitson', 'kiattikun chobtham', 'zhigao guo']"
2112.01156 ,a unified framework for adversarial attack and defense in constrained   feature space                                                                                                   ,cs.ai cs.lg                                              ,"the generation of feasible adversarial examples is necessary for properly assessing models that work in constrained feature space. however, it remains a challenging task to enforce constraints into attacks that were designed for computer vision. we propose a unified framework to generate feasible adversarial examples that satisfy given domain constraints. our framework can handle both linear and non-linear constraints. we instantiate our framework into two algorithms: a gradient-based attack that introduces constraints in the loss function to maximize, and a multi-objective search algorithm that aims for misclassification, perturbation minimization, and constraint satisfaction. we show that our approach is effective in four different domains, with a success rate of up to 100%, where state-of-the-art attacks fail to generate a single feasible example. in addition to adversarial retraining, we propose to introduce engineered non-convex constraints to improve model adversarial robustness. we demonstrate that this new defense is as effective as adversarial retraining. our framework forms the starting point for research on constrained adversarial attacks and provides relevant baselines and datasets that future research can exploit."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,                                                                        ,2021-12-02 ,2022-05-03 ,"['thibault simonetto', 'salijona dyrmishi', 'salah ghamizi', 'maxime cordy', 'yves le traon']"
2112.01455 ,zero-shot text-guided object generation with dream fields                                                                                                                               ,cs.cv cs.ai cs.gr cs.lg                                  ,"we combine neural rendering with multi-modal image and text representations to synthesize diverse 3d objects solely from natural language descriptions. our method, dream fields, can generate the geometry and color of a wide range of objects without 3d supervision. due to the scarcity of diverse, captioned 3d data, prior methods only generate objects from a handful of categories, such as shapenet. instead, we guide generation with image-text models pre-trained on large datasets of captioned images from the web. our method optimizes a neural radiance field from many camera views so that rendered images score highly with a target caption according to a pre-trained clip model. to improve fidelity and visual quality, we introduce simple geometric priors, including sparsity-inducing transmittance regularization, scene bounds, and new mlp architectures. in experiments, dream fields produce realistic, multi-view consistent object geometry and color from a variety of natural language captions."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,                                                                        ,2021-12-02 ,2022-05-04 ,"['ajay jain', 'ben mildenhall', 'jonathan t. barron', 'pieter abbeel', 'ben poole']"
2112.01797 ,detection of large vessel occlusions using deep learning by deforming   vessel tree segmentations                                                                                       ,eess.iv cs.cv cs.lg                                      ,"computed tomography angiography is a key modality providing insights into the cerebrovascular vessel tree that are crucial for the diagnosis and treatment of ischemic strokes, in particular in cases of large vessel occlusions (lvo). thus, the clinical workflow greatly benefits from an automated detection of patients suffering from lvos. this work uses convolutional neural networks for case-level classification trained with elastic deformation of the vessel tree segmentation masks to artificially augment training data. using only masks as the input to our model uniquely allows us to apply such deformations much more aggressively than one could with conventional image volumes while retaining sample realism. the neural network classifies the presence of an lvo and the affected hemisphere. in a 5-fold cross validated ablation study, we demonstrate that the use of the suggested augmentation enables us to train robust models even from few data sets. training the efficientnetb1 architecture on 100 data sets, the proposed augmentation scheme was able to raise the roc auc to 0.85 from a baseline value of 0.56 using no augmentation. the best performance was achieved using a 3d-densenet yielding an auc of 0.87. the augmentation had positive impact in classification of the affected hemisphere as well, where the 3d-densenet reached an auc of 0.93 on both sides."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2021-12-03 ,2022-05-05 ,"['florian thamm', 'oliver taubmann', 'markus jürgens', 'hendrik ditt', 'andreas maier']"
2112.01806 ,music-to-dance generation with optimal transport                                                                                                                                        ,cs.sd cs.cv cs.lg eess.as                                ,"dance choreography for a piece of music is a challenging task, having to be creative in presenting distinctive stylistic dance elements while taking into account the musical theme and rhythm. it has been tackled by different approaches such as similarity retrieval, sequence-to-sequence modeling and generative adversarial networks, but their generated dance sequences are often short of motion realism, diversity and music consistency. in this paper, we propose a music-to-dance with optimal transport network (mdot-net) for learning to generate 3d dance choreographies from music. we introduce an optimal transport distance for evaluating the authenticity of the generated dance distribution and a gromov-wasserstein distance to measure the correspondence between the dance distribution and the input music. this gives a well defined and non-divergent training objective that mitigates the limitation of standard gan training which is frequently plagued with instability and divergent generator loss issues. extensive experiments demonstrate that our mdot-net can synthesize realistic and diverse dances which achieve an organic unity with the input music, reflecting the shared intentionality and matching the rhythmic articulation. sample results are found at https://www.youtube.com/watch?v=derfbkrluo8."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,                                                                        ,2021-12-03 ,2022-05-04 ,"['shuang wu', 'shijian lu', 'li cheng']"
2112.02612 ,training structured neural networks through manifold identification and   variance reduction                                                                                            ,cs.lg math.oc stat.ml                                    ,"this paper proposes an algorithm (rmda) for training neural networks (nns) with a regularization term for promoting desired structures. rmda does not incur computation additional to proximal sgd with momentum, and achieves variance reduction without requiring the objective function to be of the finite-sum form. through the tool of manifold identification from nonlinear optimization, we prove that after a finite number of iterations, all iterates of rmda possess a desired structure identical to that induced by the regularizer at the stationary point of asymptotic convergence, even in the presence of engineering tricks like data augmentation and dropout that complicate the training process. experiments on training nns with structured sparsity confirm that variance reduction is necessary for such an identification, and show that rmda thus significantly outperforms existing methods for this task. for unstructured sparsity, rmda also outperforms a state-of-the-art pruning method, validating the benefits of training structured nns through regularization."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2021-12-05 ,2022-03-18 ,"['zih-syuan huang', 'ching-pei lee']"
2112.02682 ,bertmap: a bert-based ontology alignment system                                                                                                                                         ,cs.ai cs.cl cs.lg                                        ,"ontology alignment (a.k.a ontology matching (om)) plays a critical role in knowledge integration. owing to the success of machine learning in many domains, it has been applied in om. however, the existing methods, which often adopt ad-hoc feature engineering or non-contextual word embeddings, have not yet outperformed rule-based systems especially in an unsupervised setting. in this paper, we propose a novel om system named bertmap which can support both unsupervised and semi-supervised settings. it first predicts mappings using a classifier based on fine-tuning the contextual embedding model bert on text semantics corpora extracted from ontologies, and then refines the mappings through extension and repair by utilizing the ontology structure and logic. our evaluation with three alignment tasks on biomedical ontologies demonstrates that bertmap can often perform better than the leading om systems logmap and aml."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ,                                                                        ,2021-12-05 ,2022-05-03 ,"['yuan he', 'jiaoyan chen', 'denvar antonyrajah', 'ian horrocks']"
2112.03204 ,quantifying adaptability in pre-trained language models with 500 tasks                                                                                                                  ,cs.cl cs.lg                                              ,"when a neural language model (lm) is adapted to perform a new task, what aspects of the task predict the eventual performance of the model? in nlp, systematic features of lm generalization to individual examples are well characterized, but systematic aspects of lm adaptability to new tasks are not nearly as well understood. we present a large-scale empirical study of the features and limits of lm adaptability using a new benchmark, taskbench500, built from 500 procedurally generated sequence modeling tasks. these tasks combine core aspects of language processing, including lexical semantics, sequence processing, memorization, logical reasoning, and world knowledge. using taskbench500, we evaluate three facets of adaptability, finding that: (1) adaptation procedures differ dramatically in their ability to memorize small datasets; (2) within a subset of task types, adaptation procedures exhibit compositional adaptability to complex tasks; and (3) failure to match training label distributions is explained by mismatches in the intrinsic difficulty of predicting individual labels. our experiments show that adaptability to new tasks, like generalization to new examples, can be systematically described and understood, and we conclude with a discussion of additional aspects of adaptability that could be studied using the new benchmark."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,                                                                        ,2021-12-06 ,2022-05-04 ,"['belinda z. li', 'jane yu', 'madian khabsa', 'luke zettlemoyer', 'alon halevy', 'jacob andreas']"
2112.03254 ,human parity on commonsenseqa: augmenting self-attention with external   attention                                                                                                      ,cs.cl cs.ai cs.lg                                        ,"most of today's ai systems focus on using self-attention mechanisms and transformer architectures on large amounts of diverse data to achieve impressive performance gains. in this paper, we propose to augment the transformer architecture with an external attention mechanism to bring external knowledge and context to bear. by integrating external information into the prediction process, we hope to reduce the need for ever-larger models and increase the democratization of ai systems. we find that the proposed external attention mechanism can significantly improve the performance of existing ai systems, allowing practitioners to easily customize foundation ai models to many diverse downstream applications. in particular, we focus on the task of commonsense reasoning, demonstrating that the proposed external attention mechanism can augment existing transformer models and significantly improve the model's reasoning capabilities. the proposed system, knowledgeable external attention for commonsense reasoning (kear), reaches human parity on the open commonsenseqa research benchmark with an accuracy of 89.4\% in comparison to the human accuracy of 88.9\%."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ,                                                                        ,2021-12-06 ,2022-05-04 ,"['yichong xu', 'chenguang zhu', 'shuohang wang', 'siqi sun', 'hao cheng', 'xiaodong liu', 'jianfeng gao', 'pengcheng he', 'michael zeng', 'xuedong huang']"
2112.05907 ,smooth-swap: a simple enhancement for face-swapping with smoothness                                                                                                                     ,cs.cv cs.lg                                              ,"face-swapping models have been drawing attention for their compelling generation quality, but their complex architectures and loss functions often require careful tuning for successful training. we propose a new face-swapping model called `smooth-swap', which excludes complex handcrafted designs and allows fast and stable training. the main idea of smooth-swap is to build smooth identity embedding that can provide stable gradients for identity change. unlike the one used in previous models trained for a purely discriminative task, the proposed embedding is trained with a supervised contrastive loss promoting a smoother space. with improved smoothness, smooth-swap suffices to be composed of a generic u-net-based generator and three basic loss functions, a far simpler design compared with the previous models. extensive experiments on face-swapping benchmarks (ffhq, faceforensics++) and face images in the wild show that our model is also quantitatively and qualitatively comparable or even superior to the existing methods."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2021-12-10 ,2022-05-05 ,"['jiseob kim', 'jihoon lee', 'byoung-tak zhang']"
2112.06796 ,depth uncertainty networks for active learning                                                                                                                                          ,cs.lg stat.ml                                            ,"in active learning, the size and complexity of the training dataset changes over time. simple models that are well specified by the amount of data available at the start of active learning might suffer from bias as more points are actively sampled. flexible models that might be well suited to the full dataset can suffer from overfitting towards the start of active learning. we tackle this problem using depth uncertainty networks (duns), a bnn variant in which the depth of the network, and thus its complexity, is inferred. we find that duns outperform other bnn variants on several active learning tasks. importantly, we show that on the tasks in which duns perform best they present notably less overfitting than baselines."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ,                                                                        ,2021-12-13 ,2022-05-04 ,"['chelsea murray', 'james u. allingham', 'javier antorán', 'josé miguel hernández-lobato']"
2112.07884 ,experimental quantum advantage with quantum coupon collector                                                                                                                            ,quant-ph cs.cc cs.lg                                     ,"an increasing number of communication and computational schemes with quantum advantages have recently been proposed, which implies that quantum technology has fertile application prospects. however, demonstrating these schemes experimentally continues to be a central challenge because of the difficulty in preparing high-dimensional states or highly entangled states. in this study, we introduce and analyse a quantum coupon collector protocol by employing coherent states and simple linear optical elements, which was successfully demonstrated using realistic experimental equipment. we showed that our protocol can significantly reduce the number of samples needed to learn a specific set compared with the classical limit of the coupon collector problem. we also discuss the potential values and expansions of the quantum coupon collector by constructing a quantum blind box game. the information transmitted by the proposed game also broke the classical limit. these results strongly prove the advantages of quantum mechanics in machine learning and communication complexity."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,10.34133/2022/9798679                                                   ,2021-12-14 ,2022-04-28 ,"['min-gang zhou', 'xiao-yu cao', 'yu-shuo lu', 'yang wang', 'yu bao', 'zhao-ying jia', 'yao fu', 'hua-lei yin', 'zeng-bing chen']"
2112.08352 ,textless speech-to-speech translation on real data                                                                                                                                      ,cs.cl cs.ai cs.lg eess.as                                ,"we present a textless speech-to-speech translation (s2st) system that can translate speech from one language into another language and can be built without the need of any text data. different from existing work in the literature, we tackle the challenge in modeling multi-speaker target speech and train the systems with real-world s2st data. the key to our approach is a self-supervised unit-based speech normalization technique, which finetunes a pre-trained speech encoder with paired audios from multiple speakers and a single reference speaker to reduce the variations due to accents, while preserving the lexical content. with only 10 minutes of paired data for speech normalization, we obtain on average 3.2 bleu gain when training the s2st model on the voxpopuli s2st dataset, compared to a baseline trained on un-normalized speech target. we also incorporate automatically mined s2st data and show an additional 2.0 bleu gain. to our knowledge, we are the first to establish a textless s2st technique that can be trained with real-world data and works for multiple language pairs. audio samples are available at https://facebookresearch.github.io/speech_translation/textless_s2st_real_data/index.html ."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,                                                                        ,2021-12-15 ,2022-05-04 ,"['ann lee', 'hongyu gong', 'paul-ambroise duquenne', 'holger schwenk', 'peng-jen chen', 'changhan wang', 'sravya popuri', 'yossi adi', 'juan pino', 'jiatao gu', 'wei-ning hsu']"
2112.09130 ,ensembling off-the-shelf models for gan training                                                                                                                                        ,cs.cv cs.gr cs.lg                                        ,"the advent of large-scale training has produced a cornucopia of powerful visual recognition models. however, generative models, such as gans, have traditionally been trained from scratch in an unsupervised manner. can the collective ""knowledge"" from a large bank of pretrained vision models be leveraged to improve gan training? if so, with so many models to choose from, which one(s) should be selected, and in what manner are they most effective? we find that pretrained computer vision models can significantly improve performance when used in an ensemble of discriminators. notably, the particular subset of selected models greatly affects performance. we propose an effective selection mechanism, by probing the linear separability between real and fake samples in pretrained model embeddings, choosing the most accurate model, and progressively adding it to the discriminator ensemble. interestingly, our method can improve gan training in both limited data and large-scale settings. given only 10k training samples, our fid on lsun cat matches the stylegan2 trained on 1.6m images. on the full dataset, our method improves fid by 1.5x to 2x on cat, church, and horse categories of lsun."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,                                                                        ,2021-12-16 ,2022-05-04 ,"['nupur kumari', 'richard zhang', 'eli shechtman', 'jun-yan zhu']"
2112.14843 ,a graph attention learning approach to antenna tilt optimization                                                                                                                        ,cs.lg cs.ai                                              ,"6g will move mobile networks towards increasing levels of complexity. to deal with this complexity, optimization of network parameters is key to ensure high performance and timely adaptivity to dynamic network environments. the optimization of the antenna tilt provides a practical and cost-efficient method to improve coverage and capacity in the network. previous methods based on reinforcement learning (rl) have shown great promise for tilt optimization by learning adaptive policies outperforming traditional tilt optimization methods. however, most existing rl methods are based on single-cell features representation, which fails to fully characterize the agent state, resulting in suboptimal performance. also, most of such methods lack scalability, due to state-action explosion, and generalization ability. in this paper, we propose a graph attention q-learning (gaq) algorithm for tilt optimization. gaq relies on a graph attention mechanism to select relevant neighbors information, improve the agent state representation, and update the tilt control policy based on a history of observations using a deep q-network (dqn). we show that gaq efficiently captures important network information and outperforms standard dqn with local information by a large margin. in addition, we demonstrate its ability to generalize to network deployments of different sizes and densities."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2021-12-27 ,2022-05-05 ,"['yifei jin', 'filippo vannella', 'maxime bouton', 'jaeseong jeong', 'ezeddin al hakim']"
2201.00008 ,a lightweight and accurate spatial-temporal transformer for traffic   forecasting                                                                                                       ,cs.lg cs.ai                                              ,"we study the forecasting problem for traffic with dynamic, possibly periodical, and joint spatial-temporal dependency between regions. given the aggregated inflow and outflow traffic of regions in a city from time slots 0 to t-1, we predict the traffic at time t at any region. prior arts in the area often consider the spatial and temporal dependencies in a decoupled manner or are rather computationally intensive in training with a large number of hyper-parameters to tune. we propose st-tis, a novel, lightweight, and accurate spatial-temporal transformer with information fusion and region sampling for traffic forecasting. st-tis extends the canonical transformer with information fusion and region sampling. the information fusion module captures the complex spatial-temporal dependency between regions. the region sampling module is to improve the efficiency and prediction accuracy, cutting the computation complexity for dependency learning from $o(n^2)$ to $o(n\sqrt{n})$, where n is the number of regions. with far fewer parameters than state-of-the-art models, the offline training of our model is significantly faster in terms of tuning and computation (with a reduction of up to $90\%$ on training time and network parameters). notwithstanding such training efficiency, extensive experiments show that st-tis is substantially more accurate in online prediction than state-of-the-art approaches (with an average improvement of up to $9.5\%$ on rmse, and $12.4\%$ on mape)."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,                                                                        ,2021-12-30 ,2022-05-03 ,"['guanyao li', 'shuhan zhong', 's. -h. gary chan', 'ruiyuan li', 'chih-chieh hung', 'wen-chih peng']"
2201.01441 ,balsa: learning a query optimizer without expert demonstrations                                                                                                                         ,cs.db cs.lg                                              ,"query optimizers are a performance-critical component in every database system. due to their complexity, optimizers take experts months to write and years to refine. in this work, we demonstrate for the first time that learning to optimize queries without learning from an expert optimizer is both possible and efficient. we present balsa, a query optimizer built by deep reinforcement learning. balsa first learns basic knowledge from a simple, environment-agnostic simulator, followed by safe learning in real execution. on the join order benchmark, balsa matches the performance of two expert query optimizers, both open-source and commercial, with two hours of learning, and outperforms them by up to 2.8$\times$ in workload runtime after a few more hours. balsa thus opens the possibility of automatically learning to optimize in future compute environments where expert-designed optimizers do not exist."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ,10.1145/3514221.3517885                                                 ,2022-01-04 ,2022-05-03 ,"['zongheng yang', 'wei-lin chiang', 'sifei luan', 'gautam mittal', 'michael luo', 'ion stoica']"
2201.01666 ,sample efficient deep reinforcement learning via uncertainty estimation                                                                                                                 ,cs.lg cs.ai cs.ro                                        ,"in model-free deep reinforcement learning (rl) algorithms, using noisy value estimates to supervise policy evaluation and optimization is detrimental to the sample efficiency. as this noise is heteroscedastic, its effects can be mitigated using uncertainty-based weights in the optimization process. previous methods rely on sampled ensembles, which do not capture all aspects of uncertainty. we provide a systematic analysis of the sources of uncertainty in the noisy supervision that occurs in rl, and introduce inverse-variance rl, a bayesian framework which combines probabilistic ensembles and batch inverse variance weighting. we propose a method whereby two complementary uncertainty estimation methods account for both the q-value and the environment stochasticity to better mitigate the negative impacts of noisy supervision. our results show significant improvement in terms of sample efficiency on discrete and continuous control tasks."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ,                                                                        ,2022-01-05 ,2022-05-03 ,"['vincent mai', 'kaustubh mani', 'liam paull']"
2201.02445 ,negative evidence matters in interpretable histology image   classification                                                                                                             ,eess.iv cs.cv cs.lg                                      ,"using only global image-class labels, weakly-supervised learning methods, such as class activation mapping, allow training cnns to jointly classify an image, and locate regions of interest associated with the predicted class. however, without any guidance at the pixel level, such methods may yield inaccurate regions. this problem is known to be more challenging with histology images than with natural ones, since objects are less salient, structures have more variations, and foreground and background regions have stronger similarities. therefore, computer vision methods for visual interpretation of cnns may not directly apply. in this paper, a simple yet efficient method based on a composite loss is proposed to learn information from the fully negative samples (i.e., samples without positive regions), and thereby reduce false positives/negatives. our new loss function contains two complementary terms: the first exploits positive evidence collected from the cnn classifier, while the second leverages the fully negative samples from training data. in particular, a pre-trained cnn is equipped with a decoder that allows refining the regions of interest. the cnn is exploited to collect both positive and negative evidence at the pixel level to train the decoder. our method called negev benefits from the fully negative samples that naturally occur in the data, without any additional supervision signals beyond image-class labels. extensive experiments show that our proposed method can substantial outperform related state-of-art methods on glas (public benchmark for colon cancer), and camelyon16 (patch-based benchmark for breast cancer using three different backbones). our results highlight the benefits of using both positive and negative evidence, the first obtained from a classifier, and the other naturally available in datasets."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,                                                                        ,2022-01-07 ,2022-05-05 ,"['soufiane belharbi', 'marco pedersoli', 'ismail ben ayed', 'luke mccaffrey', 'eric granger']"
2201.02863 ,pocketnn: integer-only training and inference of neural networks via   direct feedback alignment and pocket activations in pure c++                                                     ,cs.lg cs.ai                                              ,"standard deep learning algorithms are implemented using floating-point real numbers. this presents an obstacle for implementing them on low-end devices which may not have dedicated floating-point units (fpus). as a result, researchers in tinyml have considered machine learning algorithms that can train and run a deep neural network (dnn) on a low-end device using integer operations only. in this paper we propose pocketnn, a light and self-contained proof-of-concept framework in pure c++ for the training and inference of dnns using only integers. unlike other approaches, pocketnn directly operates on integers without requiring any explicit quantization algorithms or customized fixed-point formats. this was made possible by pocket activations, which are a family of activation functions devised for integer-only dnns, and an emerging dnn training algorithm called direct feedback alignment (dfa). unlike the standard backpropagation (bp), dfa trains each layer independently, thus avoiding integer overflow which is a key problem when using bp with integer-only operations. we used pocketnn to train some dnns on two well-known datasets, mnist and fashion-mnist. our experiments show that the dnns trained with our pocketnn achieved 96.98% and 87.7% accuracies on mnist and fashion-mnist datasets, respectively. the accuracies are very close to the equivalent dnns trained using bp with floating-point real number operations, such that accuracy degradations were just 1.02%p and 2.09%p, respectively. finally, our pocketnn has high compatibility and portability for low-end devices as it is open source and implemented in pure c++ without any dependencies."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,                                                                        ,2022-01-08 ,2022-05-03 ,"['jaewoo song', 'fangzhen lin']"
2201.04669 ,on neural network kernels and the storage capacity problem                                                                                                                              ,cond-mat.dis-nn cs.lg                                    ,"in this short note, we reify the connection between work on the storage capacity problem in wide two-layer treelike neural networks and the rapidly-growing body of literature on kernel limits of wide neural networks. concretely, we observe that the ""effective order parameter"" studied in the statistical mechanics literature is exactly equivalent to the infinite-width neural network gaussian process kernel. this correspondence connects the expressivity and trainability of wide two-layer neural networks."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,10.1162/neco_a_01494                                                    ,2022-01-12 ,           ,"['jacob a. zavatone-veth', 'cengiz pehlevan']"
2201.05279 ,manifoldron: direct space partition via manifold discovery                                                                                                                              ,cs.lg cs.cv                                              ,"a neural network with the widely-used relu activation has been shown to partition the sample space into many convex polytopes for prediction. however, the parameterized way a neural network and other machine learning models use to partition the space has imperfections, \textit{e}.\textit{g}., the compromised interpretability for complex models, the inflexibility in decision boundary construction due to the generic character of the model, and the risk of being trapped into shortcut solutions. in contrast, although the non-parameterized models can adorably avoid or downplay these issues, they are usually insufficiently powerful either due to over-simplification or the failure to accommodate the manifold structures of data. in this context, we first propose a new type of machine learning models referred to as manifoldron that directly derives decision boundaries from data and partitions the space via manifold structure discovery. then, we systematically analyze the key characteristics of the manifoldron such as manifold characterization capability and its link to neural networks. the experimental results on 4 synthetic examples, 20 public benchmark datasets, and 1 real-world application demonstrate that the proposed manifoldron performs competitively compared to the mainstream machine learning models. we have shared our code in \url{https://github.com/wdayang/manifoldron} for free download and evaluation."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,                                                                        ,2022-01-13 ,2022-05-02 ,"['dayang wang', 'feng-lei fan', 'bo-jian hou', 'hao zhang', 'zhen jia', 'boce zhou', 'rongjie lai', 'hengyong yu', 'fei wang']"
2201.05989 ,instant neural graphics primitives with a multiresolution hash encoding                                                                                                                 ,cs.cv cs.gr cs.lg                                        ,"neural graphics primitives, parameterized by fully connected neural networks, can be costly to train and evaluate. we reduce this cost with a versatile new input encoding that permits the use of a smaller network without sacrificing quality, thus significantly reducing the number of floating point and memory access operations: a small neural network is augmented by a multiresolution hash table of trainable feature vectors whose values are optimized through stochastic gradient descent. the multiresolution structure allows the network to disambiguate hash collisions, making for a simple architecture that is trivial to parallelize on modern gpus. we leverage this parallelism by implementing the whole system using fully-fused cuda kernels with a focus on minimizing wasted bandwidth and compute operations. we achieve a combined speedup of several orders of magnitude, enabling training of high-quality neural graphics primitives in a matter of seconds, and rendering in tens of milliseconds at a resolution of ${1920\!\times\!1080}$."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,10.1145/3528223.3530127                                                 ,2022-01-16 ,2022-05-04 ,"['thomas müller', 'alex evans', 'christoph schied', 'alexander keller']"
2201.06503 ,analytic-dpm: an analytic estimate of the optimal reverse variance in   diffusion probabilistic models                                                                                  ,cs.lg                                                    ,"diffusion probabilistic models (dpms) represent a class of powerful generative models. despite their success, the inference of dpms is expensive since it generally needs to iterate over thousands of timesteps. a key problem in the inference is to estimate the variance in each timestep of the reverse process. in this work, we present a surprising result that both the optimal reverse variance and the corresponding optimal kl divergence of a dpm have analytic forms w.r.t. its score function. building upon it, we propose analytic-dpm, a training-free inference framework that estimates the analytic forms of the variance and kl divergence using the monte carlo method and a pretrained score-based model. further, to correct the potential bias caused by the score-based model, we derive both lower and upper bounds of the optimal variance and clip the estimate for a better result. empirically, our analytic-dpm improves the log-likelihood of various dpms, produces high-quality samples, and meanwhile enjoys a 20x to 80x speed up."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2022-01-17 ,2022-05-03 ,"['fan bao', 'chongxuan li', 'jun zhu', 'bo zhang']"
2201.07912 ,communication-efficient device scheduling for federated learning using   stochastic optimization                                                                                        ,cs.lg cs.dc cs.it math.it stat.ml                        ,"federated learning (fl) is a useful tool in distributed machine learning that utilizes users' local datasets in a privacy-preserving manner. when deploying fl in a constrained wireless environment; however, training models in a time-efficient manner can be a challenging task due to intermittent connectivity of devices, heterogeneous connection quality, and non-i.i.d. data. in this paper, we provide a novel convergence analysis of non-convex loss functions using fl on both i.i.d. and non-i.i.d. datasets with arbitrary device selection probabilities for each round. then, using the derived convergence bound, we use stochastic optimization to develop a new client selection and power allocation algorithm that minimizes a function of the convergence bound and the average communication time under a transmit power constraint. we find an analytical solution to the minimization problem. one key feature of the algorithm is that knowledge of the channel statistics is not required and only the instantaneous channel state information needs to be known. using the femnist and cifar-10 datasets, we show through simulations that the communication time can be significantly decreased using our algorithm, compared to uniformly random participation."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ,                                                                        ,2022-01-19 ,2022-05-04 ,"['jake perazzone', 'shiqiang wang', 'mingyue ji', 'kevin chan']"
2201.08690 ,a deep learning energy method for hyperelasticity and viscoelasticity                                                                                                                   ,cs.lg cs.na math.na                                      ,"the potential energy formulation and deep learning are merged to solve partial differential equations governing the deformation in hyperelastic and viscoelastic materials. the presented deep energy method (dem) is self-contained and meshfree. it can accurately capture the three-dimensional (3d) mechanical response without requiring any time-consuming training data generation by classical numerical methods such as the finite element method. once the model is appropriately trained, the response can be attained almost instantly at any point in the physical domain, given its spatial coordinates. therefore, the deep energy method is potentially a promising standalone method for solving partial differential equations describing the mechanical deformation of materials or structural systems and other physical phenomena."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,10.1016/j.euromechsol.2022.104639                                       ,2022-01-15 ,           ,"['diab w. abueidda', 'seid koric', 'rashid abu al-rub', 'corey m. parrott', 'kai a. james', 'nahil a. sobh']"
2201.12126 ,leveraging class abstraction for commonsense reinforcement learning via   residual policy gradient methods                                                                              ,cs.ai cs.lg                                              ,"enabling reinforcement learning (rl) agents to leverage a knowledge base while learning from experience promises to advance rl in knowledge intensive domains. however, it has proven difficult to leverage knowledge that is not manually tailored to the environment. we propose to use the subclass relationships present in open-source knowledge graphs to abstract away from specific objects. we develop a residual policy gradient method that is able to integrate knowledge across different abstraction levels in the class hierarchy. our method results in improved sample efficiency and generalisation to unseen objects in commonsense games, but we also investigate failure modes, such as excessive noise in the extracted class knowledge or environments with little class structure."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2022-01-28 ,2022-05-01 ,"['niklas höpner', 'ilaria tiddi', 'herke van hoof']"
2201.12384 ,developing a machine-learning algorithm to diagnose age-related macular   degeneration                                                                                                  ,eess.iv cs.cv cs.lg                                      ,"today, more than 12 million people over the age of 40 suffer from ocular diseases. most commonly, older patients are susceptible to age related macular degeneration, an eye disease that causes blurring of the central vision due to the deterioration of the retina. the former can only be detected through complex and expensive imaging software, markedly a visual field test; this leaves a significant population with untreated eye disease and holds them at risk for complete vision loss. the use of machine learning algorithms has been proposed for treating eye disease. however, the development of these models is limited by a lack of understanding regarding appropriate model and training parameters to maximize model performance. in our study, we address these points by generating 6 models, each with a learning rate of 1 * 10^n where n is 0, -1, -2, ... -6, and calculated a f1 score for each of the models. our analysis shows that sample imbalance is a key challenge in training of machine learning models and can result in deceptive improvements in training cost which does not translate to true improvements in model predictive performance. considering the wide ranging impact of the disease and its adverse effects, we developed a machine learning algorithm to treat the same. we trained our model on varying eye disease datasets consisting of over 5000 patients, and the pictures of their infected eyes. in the future, we hope this model is used extensively, especially in areas that are under-resourced, to better diagnose eye disease and improve well being for humanity."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ,                                                                        ,2022-01-28 ,           ,"['ananya dua', 'pham hung minh', 'sajid fahmid', 'shikhar gupta', 'sophia zheng', 'vanessa moyo', 'yanran elisa xue']"
2201.13178 ,few-shot backdoor attacks on visual object tracking                                                                                                                                     ,cs.cv cs.ai cs.cr cs.lg                                  ,"visual object tracking (vot) has been widely adopted in mission-critical applications, such as autonomous driving and intelligent surveillance systems. in current practice, third-party resources such as datasets, backbone networks, and training platforms are frequently used to train high-performance vot models. whilst these resources bring certain convenience, they also introduce new security threats into vot models. in this paper, we reveal such a threat where an adversary can easily implant hidden backdoors into vot models by tempering with the training process. specifically, we propose a simple yet effective few-shot backdoor attack (fsba) that optimizes two losses alternately: 1) a \emph{feature loss} defined in the hidden feature space, and 2) the standard \emph{tracking loss}. we show that, once the backdoor is embedded into the target model by our fsba, it can trick the model to lose track of specific objects even when the \emph{trigger} only appears in one or a few frames. we examine our attack in both digital and physical-world settings and show that it can significantly degrade the performance of state-of-the-art vot trackers. we also show that our attack is resistant to potential defenses, highlighting the vulnerability of vot models to potential backdoor attacks."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ,                                                                        ,2022-01-31 ,2022-05-04 ,"['yiming li', 'haoxiang zhong', 'xingjun ma', 'yong jiang', 'shu-tao xia']"
2202.00273 ,stylegan-xl: scaling stylegan to large diverse datasets                                                                                                                                 ,cs.lg cs.cv                                              ,"computer graphics has experienced a recent surge of data-centric approaches for photorealistic and controllable content creation. stylegan in particular sets new standards for generative modeling regarding image quality and controllability. however, stylegan's performance severely degrades on large unstructured datasets such as imagenet. stylegan was designed for controllability; hence, prior works suspect its restrictive design to be unsuitable for diverse datasets. in contrast, we find the main limiting factor to be the current training strategy. following the recently introduced projected gan paradigm, we leverage powerful neural network priors and a progressive growing strategy to successfully train the latest stylegan3 generator on imagenet. our final model, stylegan-xl, sets a new state-of-the-art on large-scale image synthesis and is the first to generate images at a resolution of $1024^2$ at such a dataset scale. we demonstrate that this model can invert and edit images beyond the narrow domain of portraits or specific object classes."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,                                                                        ,2022-02-01 ,2022-05-05 ,"['axel sauer', 'katja schwarz', 'andreas geiger']"
2202.00339 ,quantifying relevance in learning and inference                                                                                                                                         ,cs.lg cond-mat.dis-nn physics.data-an stat.ml            ,"learning is a distinctive feature of intelligent behaviour. high-throughput experimental data and big data promise to open new windows on complex systems such as cells, the brain or our societies. yet, the puzzling success of artificial intelligence and machine learning shows that we still have a poor conceptual understanding of learning. these applications push statistical inference into uncharted territories where data is high-dimensional and scarce, and prior information on ""true"" models is scant if not totally absent. here we review recent progress on understanding learning, based on the notion of ""relevance"". the relevance, as we define it here, quantifies the amount of information that a dataset or the internal representation of a learning machine contains on the generative model of the data. this allows us to define maximally informative samples, on one hand, and optimal learning machines on the other. these are ideal limits of samples and of machines, that contain the maximal amount of information about the unknown generative process, at a given resolution (or level of compression). both ideal limits exhibit critical features in the statistical sense: maximally informative samples are characterised by a power-law frequency distribution (statistical criticality) and optimal learning machines by an anomalously large susceptibility. the trade-off between resolution (i.e. compression) and relevance distinguishes the regime of noisy representations from that of lossy compression. these are separated by a special point characterised by zipf's law statistics. this identifies samples obeying zipf's law as the most compressed loss-less representations that are optimal in the sense of maximal relevance. criticality in optimal learning machines manifests in an exponential degeneracy of energy levels, that leads to unusual thermodynamic properties."                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,10.1016/j.physrep.2022.03.001                                           ,2022-02-01 ,           ,"['matteo marsili', 'yasser roudi']"
2202.00568 ,stochastic 2d signal generative model with wavelet packets basis   regarded as a random variable and bayes optimal processing                                                           ,eess.sp cs.lg                                            ,"this study deals with two-dimensional (2d) signal processing using the wavelet packet transform. when the basis is unknown the candidate of basis increases in exponential order with respect to the signal size. previous studies do not consider the basis as a random vaiables. therefore, the cost function needs to be used to select a basis. however, this method is often a heuristic and a greedy search because it is impossible to search all the candidates for a huge number of bases. therefore, it is difficult to evaluate the entire signal processing under a criterion and also it does not always gurantee the optimality of the entire signal processing. in this study, we propose a stochastic generative model in which the basis is regarded as a random variable. this makes it possible to evaluate entire signal processing under a unified criterion i.e. bayes criterion. moreover we can derive an optimal signal processing scheme that achieves the theoretical limit. this derived scheme shows that all the bases should be combined according to the posterior in stead of selecting a single basis. although exponential order calculations is required for this scheme, we have derived a recursive algorithm for this scheme, which successfully reduces the computational complexity from the exponential order to the polynomial order."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,                                                                        ,2022-01-26 ,2022-05-01 ,"['ryohei oka', 'yuta nakahara', 'toshiyasu matsushima']"
2202.01575 ,cost: contrastive learning of disentangled seasonal-trend   representations for time series forecasting                                                                                 ,cs.lg                                                    ,"deep learning has been actively studied for time series forecasting, and the mainstream paradigm is based on the end-to-end training of neural network architectures, ranging from classical lstm/rnns to more recent tcns and transformers. motivated by the recent success of representation learning in computer vision and natural language processing, we argue that a more promising paradigm for time series forecasting, is to first learn disentangled feature representations, followed by a simple regression fine-tuning step -- we justify such a paradigm from a causal perspective. following this principle, we propose a new time series representation learning framework for time series forecasting named cost, which applies contrastive learning methods to learn disentangled seasonal-trend representations. cost comprises both time domain and frequency domain contrastive losses to learn discriminative trend and seasonal representations, respectively. extensive experiments on real-world datasets show that cost consistently outperforms the state-of-the-art methods by a considerable margin, achieving a 21.3% improvement in mse on multivariate benchmarks. it is also robust to various choices of backbone encoders, as well as downstream regressors. code is available at https://github.com/salesforce/cost."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ,                                                                        ,2022-02-03 ,2022-05-05 ,"['gerald woo', 'chenghao liu', 'doyen sahoo', 'akshat kumar', 'steven hoi']"
2202.01909 ,ad-datasets: a meta-collection of data sets for autonomous driving                                                                                                                      ,cs.lg                                                    ,"autonomous driving is among the largest domains in which deep learning has been fundamental for progress within the last years. the rise of datasets went hand in hand with this development. all the more striking is the fact that researchers do not have a tool available that provides a quick, comprehensive and up-to-date overview of data sets and their features in the domain of autonomous driving. in this paper, we present ad-datasets, an online tool that provides such an overview for more than 150 data sets. the tool enables users to sort and filter the data sets according to currently 16 different categories. ad-datasets is an open-source project with community contributions. it is in constant development, ensuring that the content stays up-to-date."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,10.5220/0011001900003191                                                ,2022-02-03 ,2022-05-03 ,"['daniel bogdoll', 'felix schreyer', 'j. marius zöllner']"
2202.02098 ,supervised contrastive learning for product matching                                                                                                                                    ,cs.lg                                                    ,"contrastive learning has moved the state of the art for many tasks in computer vision and information retrieval in recent years. this poster is the first work that applies supervised contrastive learning to the task of product matching in e-commerce using product offers from different e-shops. more specifically, we employ a supervised contrastive learning technique to pre-train a transformer encoder which is afterward fine-tuned for the matching task using pair-wise training data. we further propose a source-aware sampling strategy that enables contrastive learning to be applied for use cases in which the training data does not contain product identifiers. we show that applying supervised contrastive pre-training in combination with source-aware sampling significantly improves the state-of-the-art performance on several widely used benchmarks: for abt-buy, we reach an f1-score of 94.29 (+3.24 compared to the previous state-of-the-art), for amazon-google 79.28 (+ 3.7). for wdc computers datasets, we reach improvements between +0.8 and +8.84 in f1-score depending on the training set size. further experiments with data augmentation and self-supervised contrastive pre-training show that the former can be helpful for smaller training sets while the latter leads to a significant decline in performance due to inherent label noise. we thus conclude that contrastive pre-training has a high potential for product matching use cases in which explicit supervision is available."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,10.1145/3487553.3524254                                                 ,2022-02-04 ,2022-05-02 ,"['ralph peeters', 'christian bizer']"
2202.02440 ,zero experience required: plug & play modular transfer learning for   semantic visual navigation                                                                                        ,cs.cv cs.ai cs.lg                                        ,"in reinforcement learning for visual navigation, it is common to develop a model for each new task, and train that model from scratch with task-specific interactions in 3d environments. however, this process is expensive; massive amounts of interactions are needed for the model to generalize well. moreover, this process is repeated whenever there is a change in the task type or the goal modality. we present a unified approach to visual navigation using a novel modular transfer learning model. our model can effectively leverage its experience from one source task and apply it to multiple target tasks (e.g., objectnav, roomnav, viewnav) with various goal modalities (e.g., image, sketch, audio, label). furthermore, our model enables zero-shot experience learning, whereby it can solve the target tasks without receiving any task-specific interactive training. our experiments on multiple photorealistic datasets and challenging tasks show that our approach learns faster, generalizes better, and outperforms sota models by a significant margin."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,                                                                        ,2022-02-04 ,2022-04-28 ,"['ziad al-halah', 'santhosh k. ramakrishnan', 'kristen grauman']"
2202.02470 ,markovgnn: graph neural networks on markov diffusion                                                                                                                                    ,cs.lg cs.ai                                              ,"most real-world networks contain well-defined community structures where nodes are densely connected internally within communities. to learn from these networks, we develop markovgnn that captures the formation and evolution of communities directly in different convolutional layers. unlike most graph neural networks (gnns) that consider a static graph at every layer, markovgnn generates different stochastic matrices using a markov process and then uses these community-capturing matrices in different layers. markovgnn is a general approach that could be used with most existing gnns. we experimentally show that markovgnn outperforms other gnns for clustering, node classification, and visualization tasks. the source code of markovgnn is publicly available at \url{https://github.com/hipgraph/markovgnn}."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2022-02-04 ,2022-04-29 ,"['md. khaledur rahman', 'abhigya agrawal', 'ariful azad']"
2202.03281 ,personalized public policy analysis in social sciences using   causal-graphical normalizing flows                                                                                       ,cs.lg cs.ai stat.ml                                      ,"structural equation/causal models (sems/scms) are widely used in epidemiology and social sciences to identify and analyze the average causal effect (ace) and conditional ace (cace). traditional causal effect estimation methods such as inverse probability weighting (ipw) and more recently regression-with-residuals (rwr) are widely used - as they avoid the challenging task of identifying the scm parameters - to estimate ace and cace. however, much work remains before traditional estimation methods can be used for counterfactual inference, and for the benefit of personalized public policy analysis (p$^3$a) in the social sciences. while doctors rely on personalized medicine to tailor treatments to patients in laboratory settings (relatively closed systems), p$^3$a draws inspiration from such tailoring but adapts it for open social systems. in this article, we develop a method for counterfactual inference that we name causal-graphical normalizing flow (c-gnf), facilitating p$^3$a. first, we show how c-gnf captures the underlying scm without making any assumption about functional forms. second, we propose a novel dequantization trick to deal with discrete variables, which is a limitation of normalizing flows in general. third, we demonstrate in experiments that c-gnf performs on-par with ipw and rwr in terms of bias and variance for estimating the ate, when the true functional forms are known, and better when they are unknown. fourth and most importantly, we conduct counterfactual inference with c-gnfs, demonstrating promising empirical performance. because ipw and rwr, like other traditional methods, lack the capability of counterfactual inference, c-gnfs will likely play a major role in tailoring personalized treatment, facilitating p$^3$a, optimizing social interventions - in contrast to the current `one-size-fits-all' approach of existing methods."                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,                                                                        ,2022-02-07 ,2022-04-30 ,"['sourabh balgi', 'jose m. pena', 'adel daoud']"
2202.04052 ,decision boundaries and convex hulls in the feature space that deep   learning functions learn from images                                                                              ,cs.cv cs.ai cs.lg math.oc                                ,"the success of deep neural networks in image classification and learning can be partly attributed to the features they extract from images. it is often speculated about the properties of a low-dimensional manifold that models extract and learn from images. however, there is not sufficient understanding about this low-dimensional space based on theory or empirical evidence. for image classification models, their last hidden layer is the one where images of each class is separated from other classes and it also has the least number of features. here, we develop methods and formulations to study that feature space for any model. we study the partitioning of the domain in feature space, identify regions guaranteed to have certain classifications, and investigate its implications for the pixel space. we observe that geometric arrangements of decision boundaries in feature space is significantly different compared to pixel space, providing insights about adversarial vulnerabilities, image morphing, extrapolation, ambiguity in classification, and the mathematical understanding of image classification models."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,                                                                        ,2022-02-05 ,2022-05-03 ,['roozbeh yousefzadeh']
2202.04169 ,swiftagg: communication-efficient and dropout-resistant secure   aggregation for federated learning with worst-case security guarantees                                                 ,cs.it cs.dc cs.lg math.it                                ,"we propose swiftagg, a novel secure aggregation protocol for federated learning systems, where a central server aggregates local models of $n$ distributed users, each of size $l$, trained on their local data, in a privacy-preserving manner. compared with state-of-the-art secure aggregation protocols, swiftagg significantly reduces the communication overheads without any compromise on security. specifically, in presence of at most $d$ dropout users, swiftagg achieves a users-to-server communication load of $(t+1)l$ and a users-to-users communication load of up to $(n-1)(t+d+1)l$, with a worst-case information-theoretic security guarantee, against any subset of up to $t$ semi-honest users who may also collude with the curious server. the key idea of swiftagg is to partition the users into groups of size $d+t+1$, then in the first phase, secret sharing and aggregation of the individual models are performed within each group, and then in the second phase, model aggregation is performed on $d+t+1$ sequences of users across the groups. if a user in a sequence drops out in the second phase, the rest of the sequence remain silent. this design allows only a subset of users to communicate with each other, and only the users in a single group to directly communicate with the server, eliminating the requirements of 1) all-to-all communication network across users; and 2) all users communicating with the server, for other secure aggregation protocols. this helps to substantially slash the communication costs of the system."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ,                                                                        ,2022-02-08 ,2022-04-29 ,"['tayyebeh jahani-nezhad', 'mohammad ali maddah-ali', 'songze li', 'giuseppe caire']"
2202.04964 ,forecasting large-scale circulation regimes using deformable   convolutional neural networks and global spatiotemporal climate data                                                     ,cs.lg                                                    ,"classifying the state of the atmosphere into a finite number of large-scale circulation regimes is a popular way of investigating teleconnections, the predictability of severe weather events, and climate change. here, we investigate a supervised machine learning approach based on deformable convolutional neural networks (decnns) and transfer learning to forecast the north atlantic-european weather regimes during extended boreal winter for 1 to 15 days into the future. we apply state-of-the-art interpretation techniques from the machine learning literature to attribute particular regions of interest or potential teleconnections relevant for any given weather cluster prediction or regime transition. we demonstrate superior forecasting performance relative to several classical meteorological benchmarks, as well as logistic regression and random forests. due to its wider field of view, we also observe decnn achieving considerably better performance than regular convolutional neural networks at lead times beyond 5-6 days. finally, we find transfer learning to be of paramount importance, similar to previous data-driven atmospheric forecasting studies."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,                                                                        ,2022-02-10 ,2022-04-29 ,"['andreas holm nielsen', 'alexandros iosifidis', 'henrik karstoft']"
2202.05735 ,sleepppg-net: a deep learning algorithm for robust sleep staging from   continuous photoplethysmography                                                                                 ,cs.lg eess.sp                                            ,"introduction: sleep staging is an essential component in the diagnosis of sleep disorders and management of sleep health. it is traditionally measured in a clinical setting and requires a labor-intensive labeling process. we hypothesize that it is possible to perform robust 4-class sleep staging using the raw photoplethysmography (ppg) time series and modern advances in deep learning (dl). methods: we used two publicly available sleep databases that included raw ppg recordings, totalling 2,374 patients and 23,055 hours. we developed sleepppg-net, a dl model for 4-class sleep staging from the raw ppg time series. sleepppg-net was trained end-to-end and consists of a residual convolutional network for automatic feature extraction and a temporal convolutional network to capture long-range contextual information. we benchmarked the performance of sleepppg-net against models based on the best-reported state-of-the-art (sota) algorithms. results: when benchmarked on a held-out test set, sleepppg-net obtained a median cohen's kappa ($\kappa$) score of 0.75 against 0.69 for the best sota approach. sleepppg-net showed good generalization performance to an external database, obtaining a $\kappa$ score of 0.74 after transfer learning. perspective: overall, sleepppg-net provides new sota performance. in addition, performance is high enough to open the path to the development of wearables that meet the requirements for usage in clinical applications such as the diagnosis and monitoring of obstructive sleep apnea."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,                                                                        ,2022-02-11 ,2022-04-29 ,"['kevin kotzen', 'peter h. charlton', 'sharon salabi', 'lea amar', 'amir landesberg', 'joachim a. behar']"
2202.05839 ,abstraction for deep reinforcement learning                                                                                                                                             ,cs.lg cs.ai                                              ,"we characterise the problem of abstraction in the context of deep reinforcement learning. various well established approaches to analogical reasoning and associative memory might be brought to bear on this issue, but they present difficulties because of the need for end-to-end differentiability. we review developments in ai and machine learning that could facilitate their adoption."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,                                                                        ,2022-02-10 ,2022-04-29 ,"['murray shanahan', 'melanie mitchell']"
2202.08906 ,st-moe: designing stable and transferable sparse expert models                                                                                                                          ,cs.cl cs.lg                                              ,"scale has opened new frontiers in natural language processing -- but at a high cost. in response, mixture-of-experts (moe) and switch transformers have been proposed as an energy efficient path to even larger and more capable language models. but advancing the state-of-the-art across a broad set of natural language tasks has been hindered by training instabilities and uncertain quality during fine-tuning. our work focuses on these issues and acts as a design guide. we conclude by scaling a sparse model to 269b parameters, with a computational cost comparable to a 32b dense encoder-decoder transformer (stable and transferable mixture-of-experts or st-moe-32b). for the first time, a sparse model achieves state-of-the-art performance in transfer learning, across a diverse set of tasks including reasoning (superglue, arc easy, arc challenge), summarization (xsum, cnn-dm), closed book question answering (webqa, natural questions), and adversarially constructed tasks (winogrande, anli r3)."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ,                                                                        ,2022-02-17 ,2022-04-29 ,"['barret zoph', 'irwan bello', 'sameer kumar', 'nan du', 'yanping huang', 'jeff dean', 'noam shazeer', 'william fedus']"
2202.10573 ,deep iterative phase retrieval for ptychography                                                                                                                                         ,eess.iv cs.lg eess.as eess.sp                            ,"one of the most prominent challenges in the field of diffractive imaging is the phase retrieval (pr) problem: in order to reconstruct an object from its diffraction pattern, the inverse fourier transform must be computed. this is only possible given the full complex-valued diffraction data, i.e. magnitude and phase. however, in diffractive imaging, generally only magnitudes can be directly measured while the phase needs to be estimated. in this work we specifically consider ptychography, a sub-field of diffractive imaging, where objects are reconstructed from multiple overlapping diffraction images. we propose an augmentation of existing iterative phase retrieval algorithms with a neural network designed for refining the result of each iteration. for this purpose we adapt and extend a recently proposed architecture from the speech processing field. evaluation results show the proposed approach delivers improved convergence rates in terms of both iteration count and algorithm runtime."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ,10.1109/icassp43922.2022.9746811                                        ,2022-02-17 ,           ,"['simon welker', 'tal peer', 'henry n. chapman', 'timo gerkmann']"
2202.10973 ,wavebender gan: an architecture for phonetically meaningful speech   manipulation                                                                                                       ,eess.as cs.hc cs.lg cs.sd                                ,"deep learning has revolutionised synthetic speech quality. however, it has thus far delivered little value to the speech science community. the new methods do not meet the controllability demands that practitioners in this area require e.g.: in listening tests with manipulated speech stimuli. instead, control of different speech properties in such stimuli is achieved by using legacy signal-processing methods. this limits the range, accuracy, and speech quality of the manipulations. also, audible artefacts have a negative impact on the methodological validity of results in speech perception studies.   this work introduces a system capable of manipulating speech properties through learning rather than design. the architecture learns to control arbitrary speech properties and leverages progress in neural vocoders to obtain realistic output. experiments with copy synthesis and manipulation of a small set of core speech features (pitch, formants, and voice quality measures) illustrate the promise of the approach for producing speech stimuli that have accurate control and high perceptual quality."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ,10.1109/icassp43922.2022.9747442                                        ,2022-02-22 ,           ,"['gustavo teodoro döhler beck', 'ulme wennberg', 'zofia malisz', 'gustav eje henter']"
2202.11783 ,"adversarially-regularized mixed effects deep learning (armed) models for   improved interpretability, performance, and generalization on clustered data"                               ,cs.lg stat.ml                                            ,"natural science datasets frequently violate assumptions of independence. samples may be clustered (e.g. by study site, subject, or experimental batch), leading to spurious associations, poor model fitting, and confounded analyses. while largely unaddressed in deep learning, this problem has been handled in the statistics community through mixed effects models, which separate cluster-invariant fixed effects from cluster-specific random effects. we propose a general-purpose framework for adversarially-regularized mixed effects deep learning (armed) models through non-intrusive additions to existing neural networks: 1) an adversarial classifier constraining the original model to learn only cluster-invariant features, 2) a random effects subnetwork capturing cluster-specific features, and 3) an approach to apply random effects to clusters unseen during training. we apply armed to dense, convolutional, and autoencoder neural networks on 4 applications including simulated nonlinear data, dementia prognosis and diagnosis, and live-cell image analysis. compared to prior techniques, armed models better distinguish confounded from true associations in simulations and learn more biologically plausible features in clinical applications. they can also quantify inter-cluster variance and visualize cluster effects in data. finally, armed improves accuracy on data from clusters seen during training (up to 28% vs. conventional models) and generalization to unseen clusters (up to 9% vs. conventional models)."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,                                                                        ,2022-02-23 ,2022-04-28 ,"['kevin p. nguyen', 'albert montillo']"
2202.12163 ,attentive temporal pooling for conformer-based streaming language   identification in long-form speech                                                                                  ,eess.as cs.cl cs.lg stat.ml                              ,"in this paper, we introduce a novel language identification system based on conformer layers. we propose an attentive temporal pooling mechanism to allow the model to carry information in long-form audio via a recurrent form, such that the inference can be performed in a streaming fashion. additionally, we investigate two domain adaptation approaches to allow adapting an existing language identification model without retraining the model parameters for a new domain. we perform a comparative study of different model topologies under different constraints of model size, and find that conformer-based models significantly outperform lstm and transformer based models. our experiments also show that attentive temporal pooling and domain adaptation improve model accuracy."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,                                                                        ,2022-02-24 ,2022-05-01 ,"['quan wang', 'yang yu', 'jason pelecanos', 'yiling huang', 'ignacio lopez moreno']"
2202.13683 ,estimating model performance on external samples from their limited   statistical characteristics                                                                                       ,stat.ml cs.lg stat.ap stat.me                            ,"methods that address data shifts usually assume full access to multiple datasets. in the healthcare domain, however, privacy-preserving regulations as well as commercial interests limit data availability and, as a result, researchers can typically study only a small number of datasets. in contrast, limited statistical characteristics of specific patient samples are much easier to share and may be available from previously published literature or focused collaborative efforts.   here, we propose a method that estimates model performance in external samples from their limited statistical characteristics. we search for weights that induce internal statistics that are similar to the external ones; and that are closest to uniform. we then use model performance on the weighted internal sample as an estimation for the external counterpart.   we evaluate the proposed algorithm on simulated data as well as electronic medical record data for two risk models, predicting complications in ulcerative colitis patients and stroke in women diagnosed with atrial fibrillation. in the vast majority of cases, the estimated external performance is much closer to the actual one than the internal performance. our proposed method may be an important building block in training robust models and detecting potential model failures in external environments."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ,                                                                        ,2022-02-28 ,           ,"['tal el-hay', 'chen yanover']"
2203.00101 ,apachejit: a large dataset for just-in-time defect prediction                                                                                                                           ,cs.se cs.ai cs.lg cs.pl                                  ,"in this paper, we present apachejit, a large dataset for just-in-time defect prediction. apachejit consists of clean and bug-inducing software changes in popular apache projects. apachejit has a total of 106,674 commits (28,239 bug-inducing and 78,435 clean commits). having a large number of commits makes apachejit a suitable dataset for machine learning models, especially deep learning models that require large training sets to effectively generalize the patterns present in the historical data to future data."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ,                                                                        ,2022-02-28 ,2022-04-29 ,"['hossein keshavarz', 'meiyappan nagappan']"
2203.00439 ,active learning with binary models for real time data labelling                                                                                                                         ,cs.cv cs.lg eess.iv                                      ,"machine learning (ml) and deep learning (dl) tasks primarily depend on data. most of the ml and dl applications involve supervised learning which requires labelled data. in the initial phases of ml realm lack of data used to be a problem, now we are in a new era of big data. the supervised ml algorithms require data to be labelled and of good quality. labelling task requires a large amount of money and time investment. data labelling require a skilled person who will charge high for this task, consider the case of the medical field or the data is in bulk that requires a lot of people assigned to label it. the amount of data that is well enough for training needs to be known, money and time can not be wasted to label the whole data. this paper mainly aims to propose a strategy that helps in labelling the data along with oracle in real-time. with balancing on model contribution for labelling is 89 and 81.1 for furniture type and intel scene image data sets respectively. further with balancing being kept off model contribution is found to be 83.47 and 78.71 for furniture type and flower data sets respectively."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,                                                                        ,2022-02-28 ,2022-05-03 ,"['ankush deshmukh', 'bhargava b c', 'a v narasimhadhan']"
2203.00829 ,personalized federated learning with graph                                                                                                                                              ,cs.lg                                                    ,"knowledge sharing and model personalization are two key components in the conceptual framework of personalized federated learning (pfl). existing pfl methods focus on proposing new model personalization mechanisms while simply implementing knowledge sharing by aggregating models from all clients, regardless of their relation graph. this paper aims to enhance the knowledge-sharing process in pfl by leveraging the graph-based structural information among clients. we propose a novel structured federated learning (sfl) framework to learn both the global and personalized models simultaneously using client-wise relation graphs and clients' private data. we cast sfl with graph into a novel optimization problem that can model the client-wise complex relations and graph-based structural topology by a unified framework. moreover, in addition to using an existing relation graph, sfl could be expanded to learn the hidden relations among clients. experiments on traffic and image benchmark datasets can demonstrate the effectiveness of the proposed method. all implementation codes are available on github"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,                                                                        ,2022-03-01 ,2022-04-30 ,"['fengwen chen', 'guodong long', 'zonghan wu', 'tianyi zhou', 'jing jiang']"
2203.01441 ,3d common corruptions and data augmentation                                                                                                                                             ,cs.cv cs.lg                                              ,"we introduce a set of image transformations that can be used as corruptions to evaluate the robustness of models as well as data augmentation mechanisms for training neural networks. the primary distinction of the proposed transformations is that, unlike existing approaches such as common corruptions, the geometry of the scene is incorporated in the transformations -- thus leading to corruptions that are more likely to occur in the real world. we also introduce a set of semantic corruptions (e.g. natural object occlusions). we show these transformations are `efficient' (can be computed on-the-fly), `extendable' (can be applied on most image datasets), expose vulnerability of existing models, and can effectively make models more robust when employed as `3d data augmentation' mechanisms. the evaluations on several tasks and datasets suggest incorporating 3d information into benchmarking and training opens up a promising direction for robustness research."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ,                                                                        ,2022-03-02 ,2022-04-29 ,"['oğuzhan fatih kar', 'teresa yeo', 'andrei atanov', 'amir zamir']"
2203.02288 ,integrating statistical uncertainty into neural network-based speech   enhancement                                                                                                      ,eess.as cs.lg cs.sd                                      ,"speech enhancement in the time-frequency domain is often performed by estimating a multiplicative mask to extract clean speech. however, most neural network-based methods perform point estimation, i.e., their output consists of a single mask. in this paper, we study the benefits of modeling uncertainty in neural network-based speech enhancement. for this, our neural network is trained to map a noisy spectrogram to the wiener filter and its associated variance, which quantifies uncertainty, based on the maximum a posteriori (map) inference of spectral coefficients. by estimating the distribution instead of the point estimate, one can model the uncertainty associated with each estimate. we further propose to use the estimated wiener filter and its uncertainty to build an approximate map (a-map) estimator of spectral magnitudes, which in turn is combined with the map inference of spectral coefficients to form a hybrid loss function to jointly reinforce the estimation. experimental results on different datasets show that the proposed method can not only capture the uncertainty associated with the estimated filters, but also yield a higher enhancement performance over comparable models that do not take uncertainty into account."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,10.1109/icassp43922.2022.9747642                                        ,2022-03-04 ,           ,"['huajian fang', 'tal peer', 'stefan wermter', 'timo gerkmann']"
2203.02628 ,target network and truncation overcome the deadly triad in $q$-learning                                                                                                                 ,cs.lg math.oc stat.ml                                    ,"$q$-learning with function approximation is one of the most empirically successful while theoretically mysterious reinforcement learning (rl) algorithms, and was identified in sutton (1999) as one of the most important theoretical open problems in the rl community. even in the basic linear function approximation setting, there are well-known divergent examples. in this work, we show that \textit{target network} and \textit{truncation} together are enough to provably stabilize $q$-learning with linear function approximation, and we establish the finite-sample guarantees. the result implies an $o(\epsilon^{-2})$ sample complexity up to a function approximation error. moreover, our results do not require strong assumptions or modifying the problem parameters as in existing literature."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2022-03-04 ,2022-05-03 ,"['zaiwei chen', 'john paul clarke', 'siva theja maguluri']"
2203.04950 ,renyi fair information bottleneck for image classification                                                                                                                              ,cs.lg cs.it math.it                                      ,"we develop a novel method for ensuring fairness in machine learning which we term as the renyi fair information bottleneck (rfib). we consider two different fairness constraints - demographic parity and equalized odds - for learning fair representations and derive a loss function via a variational approach that uses renyi's divergence with its tunable parameter $\alpha$ and that takes into account the triple constraints of utility, fairness, and compactness of representation. we then evaluate the performance of our method for image classification using the eyepacs medical imaging dataset, showing it outperforms competing state of the art techniques with performance measured using a variety of compound utility/fairness metrics, including accuracy gap and rawls' minimal accuracy."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,                                                                        ,2022-03-09 ,2022-05-02 ,"['adam gronowski', 'william paul', 'fady alajaji', 'bahman gharesifard', 'philippe burlina']"
2203.05325 ,aifb-webscience at semeval-2022 task 12: relation extraction first --   using relation extraction to identify entities                                                                  ,cs.cl cs.ai cs.lg                                        ,"in this paper, we present an end-to-end joint entity and relation extraction approach based on transformer-based language models. we apply the model to the task of linking mathematical symbols to their descriptions in latex documents. in contrast to existing approaches, which perform entity and relation extraction in sequence, our system incorporates information from relation extraction into entity extraction. this means that the system can be trained even on data sets where only a subset of all valid entity spans is annotated. we provide an extensive evaluation of the proposed system and its strengths and weaknesses. our approach, which can be scaled dynamically in computational complexity at inference time, produces predictions with high precision and reaches 3rd place in the leaderboard of semeval-2022 task 12. for inputs in the domain of physics and math, it achieves high relation extraction macro f1 scores of 95.43% and 79.17%, respectively. the code used for training and evaluating our models is available at: https://github.com/nicpopovic/re1st"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2022-03-10 ,2022-05-04 ,"['nicholas popovic', 'walter laurito', 'michael färber']"
2203.06855 ,dias: a domain-independent alife-based problem-solving system                                                                                                                           ,cs.ne cs.ai cs.lg cs.ma                                  ,"a domain-independent problem-solving system based on principles of artificial life is introduced. in this system, dias, the input and output dimensions of the domain are laid out in a spatial medium. a population of actors, each seeing only part of this medium, solves problems collectively in it. the process is independent of the domain and can be implemented through different kinds of actors. through a set of experiments on various problem domains, dias is shown able to solve problems with different dimensionality and complexity, to require no hyperparameter tuning for new problems, and to exhibit lifelong learning, i.e. adapt rapidly to run-time changes in the problem domain, and do it better than a standard non-collective approach. dias therefore demonstrates a role for alife in building scalable, general, and adaptive problem-solving systems."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2022-03-14 ,2022-05-03 ,"['babak hodjat', 'hormoz shahrzad', 'risto miikkulainen']"
2203.08021 ,interpretable machine learning in physics                                                                                                                                               ,hep-ph cs.lg                                             ,adding interpretability to multivariate methods creates a powerful synergy for exploring complex physical systems with higher order correlations while bringing about a degree of clarity in the underlying dynamics of the system.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,10.1038/s42254-022-00456-0                                              ,2022-03-11 ,2022-05-02 ,"['christophe grojean', 'ayan paul', 'zhuoni qian', 'inga strümke']"
2203.08189 ,fiber bundle morphisms as a framework for modeling many-to-many maps                                                                                                                    ,cs.lg                                                    ,"while it is not generally reflected in the `nice' datasets used for benchmarking machine learning algorithms, the real-world is full of processes that would be best described as many-to-many. that is, a single input can potentially yield many different outputs (whether due to noise, imperfect measurement, or intrinsic stochasticity in the process) and many different inputs can yield the same output (that is, the map is not injective). for example, imagine a sentiment analysis task where, due to linguistic ambiguity, a single statement can have a range of different sentiment interpretations while at the same time many distinct statements can represent the same sentiment. when modeling such a multivalued function $f: x \rightarrow y$, it is frequently useful to be able to model the distribution on $f(x)$ for specific input $x$ as well as the distribution on fiber $f^{-1}(y)$ for specific output $y$. such an analysis helps the user (i) better understand the variance intrinsic to the process they are studying and (ii) understand the range of specific input $x$ that can be used to achieve output $y$. following existing work which used a fiber bundle framework to better model many-to-one processes, we describe how morphisms of fiber bundles provide a template for building models which naturally capture the structure of many-to-many processes."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,                                                                        ,2022-03-15 ,2022-04-29 ,"['elizabeth coda', 'nico courts', 'colby wight', 'loc truong', 'woongjo choi', 'charles godfrey', 'tegan emerson', 'keerti kappagantula', 'henry kvinge']"
2203.08958 ,on the usefulness of the fit-on-the-test view on evaluating calibration   of classifiers                                                                                                ,cs.lg cs.ai                                              ,"every uncalibrated classifier has a corresponding true calibration map that calibrates its confidence. deviations of this idealistic map from the identity map reveal miscalibration. such calibration errors can be reduced with many post-hoc calibration methods which fit some family of calibration maps on a validation dataset. in contrast, evaluation of calibration with the expected calibration error (ece) on the test set does not explicitly involve fitting. however, as we demonstrate, ece can still be viewed as if fitting a family of functions on the test data. this motivates the fit-on-the-test view on evaluation: first, approximate a calibration map on the test data, and second, quantify its distance from the identity. exploiting this view allows us to unlock missed opportunities: (1) use the plethora of post-hoc calibration methods for evaluating calibration; (2) tune the number of bins in ece with cross-validation. furthermore, we introduce: (3) benchmarking on pseudo-real data where the true calibration map can be estimated very precisely; and (4) novel calibration and evaluation methods using new calibration map families pl and pl3."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ,                                                                        ,2022-03-16 ,2022-05-03 ,"['markus kängsepp', 'kaspar valk', 'meelis kull']"
2203.09678 ,self-ensemble adversarial training for improved robustness                                                                                                                              ,cs.lg cs.cr                                              ,"due to numerous breakthroughs in real-world applications brought by machine intelligence, deep neural networks (dnns) are widely employed in critical applications. however, predictions of dnns are easily manipulated with imperceptible adversarial perturbations, which impedes the further deployment of dnns and may result in profound security and privacy implications. by incorporating adversarial samples into the training data pool, adversarial training is the strongest principled strategy against various adversarial attacks among all sorts of defense methods. recent works mainly focus on developing new loss functions or regularizers, attempting to find the unique optimal point in the weight space. but none of them taps the potentials of classifiers obtained from standard adversarial training, especially states on the searching trajectory of training. in this work, we are dedicated to the weight states of models through the training process and devise a simple but powerful \emph{self-ensemble adversarial training} (seat) method for yielding a robust classifier by averaging weights of history models. this considerably improves the robustness of the target model against several well known adversarial attacks, even merely utilizing the naive cross-entropy loss to supervise. we also discuss the relationship between the ensemble of predictions from different adversarially trained models and the prediction of weight-ensembled models, as well as provide theoretical and empirical evidence that the proposed self-ensemble method provides a smoother loss landscape and better robustness than both individual models and the ensemble of predictions from different classifiers. we further analyze a subtle but fatal issue in the general settings for the self-ensemble model, which causes the deterioration of the weight-ensembled method in the late phases."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2022-03-17 ,2022-05-03 ,"['hongjun wang', 'yisen wang']"
2203.09783 ,isde : independence structure density estimation                                                                                                                                        ,cs.lg                                                    ,"in this paper, we propose isde (independence structure density estimation), an algorithm designed to estimate a multivariate density under kullback-leibler loss and the independence structure (is) model. is tackles the curse of dimensionality by separating features into independent groups. we explain the construction of isde and present some experiments to show its performance on synthetic and real-world data. performance is measured quantitatively by comparing empirical $\log$-likelihood with other density estimation methods and qualitatively by analyzing outputted partitions of variables. we also provide information about complexity and running time."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,                                                                        ,2022-03-18 ,2022-05-05 ,['louis pujol']
2203.10528 ,stochastic video prediction with structure and motion                                                                                                                                   ,cs.cv cs.lg                                              ,"while stochastic video prediction models enable future prediction under uncertainty, they mostly fail to model the complex dynamics of real-world scenes. for example, they cannot provide reliable predictions for scenes with a moving camera and independently moving foreground objects in driving scenarios. the existing methods fail to fully capture the dynamics of the structured world by only focusing on changes in pixels. in this paper, we assume that there is an underlying process creating observations in a video and propose to factorize it into static and dynamic components. we model the static part based on the scene structure and the ego-motion of the vehicle, and the dynamic part based on the remaining motion of the dynamic objects. by learning separate distributions of changes in foreground and background, we can decompose the scene into static and dynamic parts and separately model the change in each. our experiments demonstrate that disentangling structure and motion helps stochastic video prediction, leading to better future predictions in complex driving scenarios on two real-world driving datasets, kitti and cityscapes."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,                                                                        ,2022-03-20 ,2022-04-29 ,"['adil kaan akan', 'sadra safadoust', 'fatma güney']"
2203.11410 ,dazzle: using optimized generative adversarial networks to address   security data class imbalance issue                                                                                ,cs.cr cs.lg cs.se                                        ,"background: machine learning techniques have been widely used and demonstrate promising performance in many software security tasks such as software vulnerability prediction. however, the class ratio within software vulnerability datasets is often highly imbalanced (since the percentage of observed vulnerability is usually very low). goal: to help security practitioners address software security data class imbalanced issues and further help build better prediction models with resampled datasets. method: we introduce an approach called dazzle which is an optimized version of conditional wasserstein generative adversarial networks with gradient penalty (cwgan-gp). dazzle explores the architecture hyperparameters of cwgan-gp with a novel optimizer called bayesian optimization. we use dazzle to generate minority class samples to resample the original imbalanced training dataset. results: we evaluate dazzle with three software security datasets, i.e., moodle vulnerable files, ambari bug reports, and javascript function code. we show that dazzle is practical to use and demonstrates promising improvement over existing state-of-the-art oversampling techniques such as smote (e.g., with an average of about 60% improvement rate over smote in recall among all datasets). conclusion: based on this study, we would suggest the use of optimized gans as an alternative method for security vulnerability data class imbalanced issues."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,                                                                        ,2022-03-21 ,2022-05-02 ,"['rui shu', 'tianpei xia', 'laurie williams', 'tim menzies']"
2203.13167 ,"towards exemplar-free continual learning in vision transformers: an   account of attention, functional and weight regularization"                                                      ,cs.cv cs.lg                                              ,"in this paper, we investigate the continual learning of vision transformers (vit) for the challenging exemplar-free scenario, with special focus on how to efficiently distill the knowledge of its crucial self-attention mechanism (sam). our work takes an initial step towards a surgical investigation of sam for designing coherent continual learning methods in vits. we first carry out an evaluation of established continual learning regularization techniques. we then examine the effect of regularization when applied to two key enablers of sam: (a) the contextualized embedding layers, for their ability to capture well-scaled representations with respect to the values, and (b) the prescaled attention maps, for carrying value-independent global contextual information. we depict the perks of each distilling strategy on two image recognition benchmarks (cifar100 and imagenet-32) -- while (a) leads to a better overall accuracy, (b) helps enhance the rigidity by maintaining competitive performances. furthermore, we identify the limitation imposed by the symmetric nature of regularization losses. to alleviate this, we propose an asymmetric variant and apply it to the pooled output distillation (pod) loss adapted for vits. our experiments confirm that introducing asymmetry to pod boosts its plasticity while retaining stability across (a) and (b). moreover, we acknowledge low forgetting measures for all the compared methods, indicating that vits might be naturally inclined continual learner"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ,                                                                        ,2022-03-24 ,2022-05-05 ,"['francesco pelosin', 'saurav jha', 'andrea torsello', 'bogdan raducanu', 'joost van de weijer']"
2203.13551 ,feature extraction using spectral clustering for gene function   prediction using hierarchical multi-label classification                                                               ,cs.lg                                                    ,"gene annotation addresses the problem of predicting unknown associations between gene and functions (e.g., biological processes) of a specific organism. despite recent advances, the cost and time demanded by annotation procedures that rely largely on in vivo biological experiments remain prohibitively high. this paper presents a novel in silico approach for to the annotation problem that combines cluster analysis and hierarchical multi-label classification (hmc). the approach uses spectral clustering to extract new features from the gene co-expression network (gcn) and enrich the prediction task. hmc is used to build multiple estimators that consider the hierarchical structure of gene functions. the proposed approach is applied to a case study on zea mays, one of the most dominant and productive crops in the world. the results illustrate how in silico approaches are key to reduce the time and costs of gene annotation. more specifically, they highlight the importance of: (i) building new features that represent the structure of gene relationships in gcns to annotate genes; and (ii) taking into account the structure of biological processes to obtain consistent predictions."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,                                                                        ,2022-03-25 ,2022-04-28 ,"['miguel romero', 'oscar ramírez', 'jorge finke', 'camilo rocha']"
2203.15228 ,shop: a deep learning based pipeline for near real-time detection of   small handheld objects present in blurry video                                                                   ,cs.cv cs.lg                                              ,"while prior works have investigated and developed computational models capable of object detection, models still struggle to reliably interpret images with motion blur and small objects. moreover, none of these models are specifically designed for handheld object detection. in this work, we present shop (small handheld object pipeline), a pipeline that reliably and efficiently interprets blurry images containing handheld objects. the specific models used in each stage of the pipeline are flexible and can be changed based on performance requirements. first, images are deblurred and then run through a pose detection system where areas-of-interest are proposed around the hands of any people present. next, object detection is performed on the images by a single-stage object detector. finally, the proposed areas-of-interest are used to filter out low confidence detections. testing on a handheld subset of microsoft common objects in context (ms coco) demonstrates that this 3 stage process results in a 70 percent decrease in false positives while only reducing true positives by 17 percent in its strongest configuration. we also present a subset of ms coco consisting solely of handheld objects that can be used to continue the development of handheld object detection methods. https://github.com/spider-sense/shop"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,10.1109/southeastcon48659.2022.9763890                                  ,2022-03-29 ,           ,"['abhinav ganguly', 'amar c gandhi', 'sylvia e', 'jeffrey d chang', 'ian m hudson']"
2204.00408 ,structured pruning learns compact and accurate models                                                                                                                                   ,cs.cl cs.lg                                              ,"the growing size of neural language models has led to increased attention in model compression. the two predominant approaches are pruning, which gradually removes weights from a pre-trained model, and distillation, which trains a smaller compact model to match a larger one. pruning methods can significantly reduce the model size but hardly achieve large speedups as distillation. however, distillation methods require large amounts of unlabeled data and are expensive to train. in this work, we propose a task-specific structured pruning method cofi (coarse- and fine-grained pruning), which delivers highly parallelizable subnetworks and matches the distillation methods in both accuracy and latency, without resorting to any unlabeled data. our key insight is to jointly prune coarse-grained (e.g., layers) and fine-grained (e.g., heads and hidden units) modules, which controls the pruning decision of each parameter with masks of different granularity. we also devise a layerwise distillation strategy to transfer knowledge from unpruned to pruned models during optimization. our experiments on glue and squad datasets show that cofi yields models with over 10x speedups with a small accuracy drop, showing its effectiveness and efficiency compared to previous pruning and distillation approaches."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2022-04-01 ,2022-05-02 ,"['mengzhou xia', 'zexuan zhong', 'danqi chen']"
2204.02246 ,continuously discovering novel strategies via reward-switching policy   optimization                                                                                                    ,cs.lg cs.ai                                              ,"we present reward-switching policy optimization (rspo), a paradigm to discover diverse strategies in complex rl environments by iteratively finding novel policies that are both locally optimal and sufficiently different from existing ones. to encourage the learning policy to consistently converge towards a previously undiscovered local optimum, rspo switches between extrinsic and intrinsic rewards via a trajectory-based novelty measurement during the optimization process. when a sampled trajectory is sufficiently distinct, rspo performs standard policy optimization with extrinsic rewards. for trajectories with high likelihood under existing policies, rspo utilizes an intrinsic diversity reward to promote exploration. experiments show that rspo is able to discover a wide spectrum of strategies in a variety of domains, ranging from single-agent particle-world tasks and mujoco continuous control to multi-agent stag-hunt games and starcraftii challenges."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,                                                                        ,2022-04-04 ,2022-05-03 ,"['zihan zhou', 'wei fu', 'bingliang zhang', 'yi wu']"
2204.02694 ,customizable end-to-end optimization of online neural network-supported   dereverberation for hearing devices                                                                           ,eess.as cs.lg cs.sd                                      ,"this work focuses on online dereverberation for hearing devices using the weighted prediction error (wpe) algorithm. wpe filtering requires an estimate of the target speech power spectral density (psd). recently deep neural networks (dnns) have been used for this task. however, these approaches optimize the psd estimate which only indirectly affects the wpe output, thus potentially resulting in limited dereverberation. in this paper, we propose an end-to-end approach specialized for online processing, that directly optimizes the dereverberated output signal. in addition, we propose to adapt it to the needs of different types of hearing-device users by modifying the optimization target as well as the wpe algorithm characteristics used in training. we show that the proposed end-to-end approach outperforms the traditional and conventional dnn-supported wpes on a noise-free version of the whamr! dataset."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,10.1109/icassp43922.2022.9746235                                        ,2022-04-06 ,           ,"['jean-marie lemercier', 'joachim thiemann', 'raphael koning', 'timo gerkmann']"
2204.04168 ,ranking with submodular functions on a budget                                                                                                                                           ,cs.ds cs.lg                                              ,"submodular maximization has been the backbone of many important machine-learning problems, and has applications to viral marketing, diversification, sensor placement, and more. however, the study of maximizing submodular functions has mainly been restricted in the context of selecting a set of items. on the other hand, many real-world applications require a solution that is a ranking over a set of items. the problem of ranking in the context of submodular function maximization has been considered before, but to a much lesser extent than item-selection formulations. in this paper, we explore a novel formulation for ranking items with submodular valuations and budget constraints. we refer to this problem as max-submodular ranking (msr). in more detail, given a set of items and a set of non-decreasing submodular functions, where each function is associated with a budget, we aim to find a ranking of the set of items that maximizes the sum of values achieved by all functions under the budget constraints. for the msr problem with cardinality- and knapsack-type budget constraints we propose practical algorithms with approximation guarantees. in addition, we perform an empirical evaluation, which demonstrates the superior performance of the proposed algorithms against strong baselines."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,10.1007/s10618-022-00833-4                                              ,2022-04-08 ,           ,"['guangyi zhang', 'nikolaj tatti', 'aristides gionis']"
2204.04256 ,interpretable ai for policy-making in pandemics                                                                                                                                         ,cs.lg cs.ai cs.cy                                        ,"since the first wave of the covid-19 pandemic, governments have applied restrictions in order to slow down its spreading. however, creating such policies is hard, especially because the government needs to trade-off the spreading of the pandemic with the economic losses. for this reason, several works have applied machine learning techniques, often with the help of special-purpose simulators, to generate policies that were more effective than the ones obtained by governments. while the performance of such approaches are promising, they suffer from a fundamental issue: since such approaches are based on black-box machine learning, their real-world applicability is limited, because these policies cannot be analyzed, nor tested, and thus they are not trustable. in this work, we employ a recently developed hybrid approach, which combines reinforcement learning with evolutionary computation, for the generation of interpretable policies for containing the pandemic. these policies, trained on an existing simulator, aim to reduce the spreading of the pandemic while minimizing the economic losses. our results show that our approach is able to find solutions that are extremely simple, yet very powerful. in fact, our approach has significantly better performance (in simulated scenarios) than both previous work and government policies."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,10.1145/3520304.3533959                                                 ,2022-04-08 ,2022-04-30 ,"['leonardo lucio custode', 'giovanni iacca']"
2204.04487 ,informativeness and invariance: two perspectives on spurious   correlations in natural language                                                                                         ,cs.cl cs.lg                                              ,"spurious correlations are a threat to the trustworthiness of natural language processing systems, motivating research into methods for identifying and eliminating them. however, addressing the problem of spurious correlations requires more clarity on what they are and how they arise in language data. gardner et al (2021) argue that the compositional nature of language implies that \emph{all} correlations between labels and individual ""input features"" are spurious. this paper analyzes this proposal in the context of a toy example, demonstrating three distinct conditions that can give rise to feature-label correlations in a simple pcfg. linking the toy example to a structured causal model shows that (1) feature-label correlations can arise even when the label is invariant to interventions on the feature, and (2) feature-label correlations may be absent even when the label is sensitive to interventions on the feature. because input features will be individually correlated with labels in all but very rare circumstances, domain knowledge must be applied to identify spurious correlations that pose genuine robustness threats."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,                                                                        ,2022-04-09 ,2022-05-03 ,['jacob eisenstein']
2204.04796 ,sos! self-supervised learning over sets of handled objects in egocentric   action recognition                                                                                           ,cs.cv cs.ai cs.lg                                        ,"learning an egocentric action recognition model from video data is challenging due to distractors (e.g., irrelevant objects) in the background. further integrating object information into an action model is hence beneficial. existing methods often leverage a generic object detector to identify and represent the objects in the scene. however, several important issues remain. object class annotations of good quality for the target domain (dataset) are still required for learning good object representation. besides, previous methods deeply couple the existing action models and need to retrain them jointly with object representation, leading to costly and inflexible integration. to overcome both limitations, we introduce self-supervised learning over sets (sos), an approach to pre-train a generic objects in contact (oic) representation model from video object regions detected by an off-the-shelf hand-object contact detector. instead of augmenting object regions individually as in conventional self-supervised learning, we view the action process as a means of natural data transformations with unique spatio-temporal continuity and exploit the inherent relationships among per-video object sets. extensive experiments on two datasets, epic-kitchens-100 and egtea, show that our oic significantly boosts the performance of multiple state-of-the-art video classification models."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,                                                                        ,2022-04-10 ,2022-05-02 ,"['victor escorcia', 'ricardo guerrero', 'xiatian zhu', 'brais martinez']"
2204.05231 ,towards generalizable semantic product search by text similarity   pre-training on search click logs                                                                                    ,cs.ir cs.ai cs.cl cs.lg                                  ,"recently, semantic search has been successfully applied to e-commerce product search and the learned semantic space(s) for query and product encoding are expected to generalize to unseen queries or products. yet, whether generalization can conveniently emerge has not been thoroughly studied in the domain thus far. in this paper, we examine several general-domain and domain-specific pre-trained roberta variants and discover that general-domain fine-tuning does not help generalization, which aligns with the discovery of prior art. proper domain-specific fine-tuning with clickstream data can lead to better model generalization, based on a bucketed analysis of a publicly available manual annotated query-product pair da"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,                                                                        ,2022-04-11 ,2022-04-28 ,"['zheng liu', 'wei zhang', 'yan chen', 'weiyi sun', 'tianchuan du', 'benjamin schroeder']"
2204.06885 ,shedding new light on the language of the dark web                                                                                                                                      ,cs.cl cs.ir cs.lg                                        ,"the hidden nature and the limited accessibility of the dark web, combined with the lack of public datasets in this domain, make it difficult to study its inherent characteristics such as linguistic properties. previous works on text classification of dark web domain have suggested that the use of deep neural models may be ineffective, potentially due to the linguistic differences between the dark and surface webs. however, not much work has been done to uncover the linguistic characteristics of the dark web. this paper introduces coda, a publicly available dark web dataset consisting of 10000 web documents tailored towards text-based dark web analysis. by leveraging coda, we conduct a thorough linguistic analysis of the dark web and examine the textual differences between the dark web and the surface web. we also assess the performance of various methods of dark web page classification. finally, we compare coda with an existing public dark web dataset and evaluate their suitability for various use cases."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,                                                                        ,2022-04-14 ,2022-05-04 ,"['youngjin jin', 'eugene jang', 'yongjae lee', 'seungwon shin', 'jin-woo chung']"
2204.06963 ,finding mnemon: reviving memories of node embeddings                                                                                                                                    ,cs.lg cs.cr stat.ml                                      ,"previous security research efforts orbiting around graphs have been exclusively focusing on either (de-)anonymizing the graphs or understanding the security and privacy issues of graph neural networks. little attention has been paid to understand the privacy risks of integrating the output from graph embedding models (e.g., node embeddings) with complex downstream machine learning pipelines. in this paper, we fill this gap and propose a novel model-agnostic graph recovery attack that exploits the implicit graph structural information preserved in the embeddings of graph nodes. we show that an adversary can recover edges with decent accuracy by only gaining access to the node embedding matrix of the original graph without interactions with the node embedding models. we demonstrate the effectiveness and applicability of our graph recovery attack through extensive experiments."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ,                                                                        ,2022-04-14 ,2022-04-29 ,"['yun shen', 'yufei han', 'zhikun zhang', 'min chen', 'ting yu', 'michael backes', 'yang zhang', 'gianluca stringhini']"
2204.07316 ,xdbert: distilling visual information to bert from cross-modal systems   to improve language understanding                                                                              ,cs.cl cs.ai cs.lg                                        ,"transformer-based models are widely used in natural language understanding (nlu) tasks, and multimodal transformers have been effective in visual-language tasks. this study explores distilling visual information from pretrained multimodal transformers to pretrained language encoders. our framework is inspired by cross-modal encoders' success in visual-language tasks while we alter the learning objective to cater to the language-heavy characteristics of nlu. after training with a small number of extra adapting steps and finetuned, the proposed xdbert (cross-modal distilled bert) outperforms pretrained-bert in general language understanding evaluation (glue), situations with adversarial generations (swag) benchmarks, and readability benchmarks. we analyze the performance of xdbert on glue to show that the improvement is likely visually grounded."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,                                                                        ,2022-04-14 ,2022-05-02 ,"['chan-jan hsu', 'hung-yi lee', 'yu tsao']"
2204.09105 ,an improved central limit theorem and fast convergence rates for   entropic transportation costs                                                                                        ,math.st cs.lg math.pr stat.th                            ,"we prove a central limit theorem for the entropic transportation cost between subgaussian probability measures, centered at the population cost. this is the first result which allows for asymptotically valid inference for entropic optimal transport between measures which are not necessarily discrete. in the compactly supported case, we complement these results with new, faster, convergence rates for the expected entropic transportation cost between empirical measures. our proof is based on strengthening convergence results for dual solutions to the entropic optimal transport problem."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,                                                                        ,2022-04-19 ,2022-05-04 ,"['eustasio del barrio', 'alberto gonzalez-sanz', 'jean-michel loubes', 'jonathan niles-weed']"
2204.09183 ,robustness testing of data and knowledge driven anomaly detection in   cyber-physical systems                                                                                           ,cs.lg cs.ai                                              ,"the growing complexity of cyber-physical systems (cps) and challenges in ensuring safety and security have led to the increasing use of deep learning methods for accurate and scalable anomaly detection. however, machine learning (ml) models often suffer from low performance in predicting unexpected data and are vulnerable to accidental or malicious perturbations. although robustness testing of deep learning models has been extensively explored in applications such as image classification and speech recognition, less attention has been paid to ml-driven safety monitoring in cps. this paper presents the preliminary results on evaluating the robustness of ml-based anomaly detection methods in safety-critical cps against two types of accidental and malicious input perturbations, generated using a gaussian-based noise model and the fast gradient sign method (fgsm). we test the hypothesis of whether integrating the domain knowledge (e.g., on unsafe system behavior) with the ml models can improve the robustness of anomaly detection without sacrificing accuracy and transparency. experimental results with two case studies of artificial pancreas systems (aps) for diabetes management show that ml-based safety monitors trained with domain knowledge can reduce on average up to 54.2% of robustness error and keep the average f1 scores high while improving transparency."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,                                                                        ,2022-04-19 ,2022-05-03 ,"['xugui zhou', 'maxfield kouzel', 'homa alemzadeh']"
2204.09560 ,understanding and preventing capacity loss in reinforcement learning                                                                                                                    ,cs.lg                                                    ,"the reinforcement learning (rl) problem is rife with sources of non-stationarity, making it a notoriously difficult problem domain for the application of neural networks. we identify a mechanism by which non-stationary prediction targets can prevent learning progress in deep rl agents: \textit{capacity loss}, whereby networks trained on a sequence of target values lose their ability to quickly update their predictions over time. we demonstrate that capacity loss occurs in a range of rl agents and environments, and is particularly damaging to performance in sparse-reward tasks. we then present a simple regularizer, initial feature regularization (infer), that mitigates this phenomenon by regressing a subspace of features towards its value at initialization, leading to significant performance improvements in sparse-reward environments such as montezuma's revenge. we conclude that preventing capacity loss is crucial to enable agents to maximally benefit from the learning signals they obtain throughout the entire training trajectory."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,                                                                        ,2022-04-20 ,2022-05-04 ,"['clare lyle', 'mark rowland', 'will dabney']"
2204.10685 ,tasac: a twin-actor reinforcement learning framework with stochastic   policy for batch process control                                                                                 ,cs.lg cs.sy eess.sy                                      ,"due to their complex nonlinear dynamics and batch-to-batch variability, batch processes pose a challenge for process control. due to the absence of accurate models and resulting plant-model mismatch, these problems become harder to address for advanced model-based control strategies. reinforcement learning (rl), wherein an agent learns the policy by directly interacting with the environment, offers a potential alternative in this context. rl frameworks with actor-critic architecture have recently become popular for controlling systems where state and action spaces are continuous. it has been shown that an ensemble of actor and critic networks further helps the agent learn better policies due to the enhanced exploration due to simultaneous policy learning. to this end, the current study proposes a stochastic actor-critic rl algorithm, termed twin actor soft actor-critic (tasac), by incorporating an ensemble of actors for learning, in a maximum entropy framework, for batch process control."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2022-04-22 ,2022-05-02 ,"['tanuja joshi', 'hariprasad kodamana', 'harikumar kandath', 'niket kaisare']"
2204.11640 ,hybrid ista: unfolding ista with convergence guarantees using free-form   deep neural networks                                                                                          ,cs.cv cs.lg eess.iv                                      ,"it is promising to solve linear inverse problems by unfolding iterative algorithms (e.g., iterative shrinkage thresholding algorithm (ista)) as deep neural networks (dnns) with learnable parameters. however, existing ista-based unfolded algorithms restrict the network architectures for iterative updates with the partial weight coupling structure to guarantee convergence. in this paper, we propose hybrid ista to unfold ista with both pre-computed and learned parameters by incorporating free-form dnns (i.e., dnns with arbitrary feasible and reasonable network architectures), while ensuring theoretical convergence. we first develop hcista to improve the efficiency and flexibility of classical ista (with pre-computed parameters) without compromising the convergence rate in theory. furthermore, the dnn-based hybrid algorithm is generalized to popular variants of learned ista, dubbed hlista, to enable a free architecture of learned parameters with a guarantee of linear convergence. to our best knowledge, this paper is the first to provide a convergence-provable framework that enables free-form dnns in ista-based unfolded algorithms. this framework is general to endow arbitrary dnns for solving linear inverse problems with convergence guarantees. extensive experiments demonstrate that hybrid ista can reduce the reconstruction error with an improved convergence rate in the tasks of sparse recovery and compressive sensing."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ,10.1109/tpami.2022.3172214                                              ,2022-04-25 ,2022-05-05 ,"['ziyang zheng', 'wenrui dai', 'duoduo xue', 'chenglin li', 'junni zou', 'hongkai xiong']"
2204.11736 ,knowaugnet: multi-source medical knowledge augmented medication   prediction network with multi-level graph contrastive learning                                                        ,cs.ai cs.lg                                              ,"predicting medications is a crucial task in many intelligent healthcare systems. it can assist doctors in making informed medication decisions for patients according to electronic medical records (emrs). however, medication prediction is a challenging data mining task due to the complex relations between medical codes. most existing studies focus on utilizing inherent relations between homogeneous codes of medical ontology graph to enhance their representations using supervised methods, and few studies pay attention to the valuable relations between heterogeneous or homogeneous medical codes from history emrs, which further limits the prediction performance and application scenarios. therefore, to address these limitations, this paper proposes knowaugnet, a multi-sourced medical knowledge augmented medication prediction network which can fully capture the diverse relations between medical codes via multi-level graph contrastive learning framework. specifically, knowaugnet first leverages the graph contrastive learning using graph attention network as the encoder to capture the implicit relations between homogeneous medical codes from the medical ontology graph and obtains the knowledge augmented medical codes embedding vectors. then, it utilizes the graph contrastive learning using a weighted graph convolutional network as the encoder to capture the correlative relations between homogeneous or heterogeneous medical codes from the constructed medical prior relation graph and obtains the relation augmented medical codes embedding vectors. finally, the augmented medical codes embedding vectors and the supervised medical codes embedding vectors are retrieved and input to the sequential learning network to capture the temporal relations of medical codes and predict medications for patients."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2022-04-25 ,2022-04-28 ,"['yang an', 'bo jin', 'xiaopeng wei']"
2204.11790 ,can rationalization improve robustness?                                                                                                                                                 ,cs.cl cs.cr cs.lg                                        ,"a growing line of work has investigated the development of neural nlp models that can produce rationales--subsets of input that can explain their model predictions. in this paper, we ask whether such rationale models can also provide robustness to adversarial attacks in addition to their interpretable nature. since these models need to first generate rationales (""rationalizer"") before making predictions (""predictor""), they have the potential to ignore noise or adversarially added text by simply masking it out of the generated rationale. to this end, we systematically generate various types of 'addtext' attacks for both token and sentence-level rationalization tasks, and perform an extensive empirical evaluation of state-of-the-art rationale models across five different tasks. our experiments reveal that the rationale models show the promise to improve robustness, while they struggle in certain scenarios--when the rationalizer is sensitive to positional bias or lexical choices of attack text. further, leveraging human rationale as supervision does not always translate to better performance. our study is a first step towards exploring the interplay between interpretability and robustness in the rationalize-then-predict framework."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ,                                                                        ,2022-04-25 ,2022-05-03 ,"['howard chen', 'jacqueline he', 'karthik narasimhan', 'danqi chen']"
2204.11822 ,zero-shot logit adjustment                                                                                                                                                              ,cs.cv cs.lg                                              ,"semantic-descriptor-based generalized zero-shot learning (gzsl) poses challenges in recognizing novel classes in the test phase. the development of generative models enables current gzsl techniques to probe further into the semantic-visual link, culminating in a two-stage form that includes a generator and a classifier. however, existing generation-based methods focus on enhancing the generator's effect while neglecting the improvement of the classifier. in this paper, we first analyze of two properties of the generated pseudo unseen samples: bias and homogeneity. then, we perform variational bayesian inference to back-derive the evaluation metrics, which reflects the balance of the seen and unseen classes. as a consequence of our derivation, the aforementioned two properties are incorporated into the classifier training as seen-unseen priors via logit adjustment. the zero-shot logit adjustment further puts semantic-based classifiers into effect in generation-based gzsl. our experiments demonstrate that the proposed technique achieves state-of-the-art when combined with the basic generator, and it can improve various generative zero-shot learning frameworks. our codes are available on https://github.com/cdb342/ijcai-2022-zla."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ,                                                                        ,2022-04-25 ,2022-05-05 ,"['dubing chen', 'yuming shen', 'haofeng zhang', 'philip h. s. torr']"
2204.11849 ,heterogeneous information network based default analysis on banking   micro and small enterprise users                                                                                  ,q-fin.rm cs.ai cs.lg cs.si                               ,"risk assessment is a substantial problem for financial institutions that has been extensively studied both for its methodological richness and its various practical applications. with the expansion of inclusive finance, recent attentions are paid to micro and small-sized enterprises (mses). compared with large companies, mses present a higher exposure rate to default owing to their insecure financial stability. conventional efforts learn classifiers from historical data with elaborate feature engineering. however, the main obstacle for mses involves severe deficiency in credit-related information, which may degrade the performance of prediction. besides, financial activities have diverse explicit and implicit relations, which have not been fully exploited for risk judgement in commercial banks. in particular, the observations on real data show that various relationships between company users have additional power in financial risk analysis. in this paper, we consider a graph of banking data, and propose a novel hidam model for the purpose. specifically, we attempt to incorporate heterogeneous information network with rich attributes on multi-typed nodes and links for modeling the scenario of business banking service. to enhance feature representation of mses, we extract interactive information through meta-paths and fully exploit path information. furthermore, we devise a hierarchical attention mechanism respectively to learn the importance of contents inside each meta-path and the importance of different metapahs. experimental results verify that hidam outperforms state-of-the-art competitors on real-world banking data."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,                                                                        ,2022-04-24 ,2022-05-02 ,"['zheng zhang', 'yingsheng ji', 'jiachen shen', 'xi zhang', 'guangwen yang']"
2204.11992 ,offline vehicle routing problem with online bookings: a novel problem   formulation with applications to paratransit                                                                    ,cs.ai cs.lg                                              ,"vehicle routing problems (vrps) can be divided into two major categories: offline vrps, which consider a given set of trip requests to be served, and online vrps, which consider requests as they arrive in real-time. based on discussions with public transit agencies, we identify a real-world problem that is not addressed by existing formulations: booking trips with flexible pickup windows (e.g., 3 hours) in advance (e.g., the day before) and confirming tight pickup windows (e.g., 30 minutes) at the time of booking. such a service model is often required in paratransit service settings, where passengers typically book trips for the next day over the phone. to address this gap between offline and online problems, we introduce a novel formulation, the offline vehicle routing problem with online bookings. this problem is very challenging computationally since it faces the complexity of considering large sets of requests -- similar to offline vrps -- but must abide by strict constraints on running time -- similar to online vrps. to solve this problem, we propose a novel computational approach, which combines an anytime algorithm with a learning-based policy for real-time decisions. based on a paratransit dataset obtained from the public transit agency of chattanooga, tn, we demonstrate that our novel formulation and computational approach lead to significantly better outcomes in this setting than existing algorithms."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2022-04-25 ,2022-05-05 ,"['amutheezan sivagnanam', 'salah uddin kadir', 'ayan mukhopadhyay', 'philip pugliese', 'abhishek dubey', 'samitha samaranayake', 'aron laszka']"
2204.12010 ,theoretical understanding of the information flow on continual learning   performance                                                                                                   ,cs.lg                                                    ,"continual learning (cl) is a setting in which an agent has to learn from an incoming stream of data sequentially. cl performance evaluates the model's ability to continually learn and solve new problems with incremental available information over time while retaining previous knowledge. despite the numerous previous solutions to bypass the catastrophic forgetting (cf) of previously seen tasks during the learning process, most of them still suffer significant forgetting, expensive memory cost, or lack of theoretical understanding of neural networks' conduct while learning new tasks. while the issue that cl performance degrades under different training regimes has been extensively studied empirically, insufficient attention has been paid from a theoretical angle. in this paper, we establish a probabilistic framework to analyze information flow through layers in networks for task sequences and its impact on learning performance. our objective is to optimize the information preservation between layers while learning new tasks to manage task-specific knowledge passing throughout the layers while maintaining model performance on previous tasks. in particular, we study cl performance's relationship with information flow in the network to answer the question ""how can knowledge of information flow between layers be used to alleviate cf?"". our analysis provides novel insights of information adaptation within the layers during the incremental task learning process. through our experiments, we provide empirical evidence and practically highlight the performance improvement across multiple tasks."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,                                                                        ,2022-04-25 ,2022-05-02 ,"['josh andle', 'salimeh yasaei sekeh']"
2204.12048 ,thompson sampling for bandit learning in matching markets                                                                                                                               ,cs.lg cs.gt                                              ,"the problem of two-sided matching markets has a wide range of real-world applications and has been extensively studied in the literature. a line of recent works have focused on the problem setting where the preferences of one-side market participants are unknown \emph{a priori} and are learned by iteratively interacting with the other side of participants. all these works are based on explore-then-commit (etc) and upper confidence bound (ucb) algorithms, two common strategies in multi-armed bandits (mab). thompson sampling (ts) is another popular approach, which attracts lots of attention due to its easier implementation and better empirical performances. in many problems, even when ucb and etc-type algorithms have already been analyzed, researchers are still trying to study ts for its benefits. however, the convergence analysis of ts is much more challenging and remains open in many problem settings. in this paper, we provide the first regret analysis for ts in the new setting of iterative matching markets. extensive experiments demonstrate the practical advantages of the ts-type algorithm over the etc and ucb-type baselines."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2022-04-25 ,2022-05-02 ,"['fang kong', 'junming yin', 'shuai li']"
2204.12263 ,science checker: extractive-boolean question answering for scientific   fact checking                                                                                                   ,cs.cl cs.ai cs.ir cs.lg                                  ,"with the explosive growth of scientific publications, making the synthesis of scientific knowledge and fact checking becomes an increasingly complex task. in this paper, we propose a multi-task approach for verifying the scientific questions based on a joint reasoning from facts and evidence in research articles. we propose an intelligent combination of (1) an automatic information summarization and (2) a boolean question answering which allows to generate an answer to a scientific question from only extracts obtained after summarization. thus on a given topic, our proposed approach conducts structured content modeling based on paper abstracts to answer a scientific question while highlighting texts from paper that discuss the topic. we based our final system on an end-to-end extractive question answering (eqa) combined with a three outputs classification model to perform in-depth semantic understanding of a question to illustrate the aggregation of multiple responses. with our light and fast proposed architecture, we achieved an average error rate of 4% and a f1-score of 95.6%. our results are supported via experiments with two qa models (bert, roberta) over 3 million open access (oa) articles in the medical and health domains on europe pmc."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,10.1145/3512732.3533580                                                 ,2022-04-26 ,2022-04-29 ,"['loïc rakotoson', 'charles letaillieur', 'sylvain massip', 'fréjus laleye']"
2204.12426 ,time-triggered federated learning over wireless networks                                                                                                                                ,cs.lg cs.sy eess.sy                                      ,"the newly emerging federated learning (fl) framework offers a new way to train machine learning models in a privacy-preserving manner. however, traditional fl algorithms are based on an event-triggered aggregation, which suffers from stragglers and communication overhead issues. to address these issues, in this paper, we present a time-triggered fl algorithm (tt-fed) over wireless networks, which is a generalized form of classic synchronous and asynchronous fl. taking the constrained resource and unreliable nature of wireless communication into account, we jointly study the user selection and bandwidth optimization problem to minimize the fl training loss. to solve this joint optimization problem, we provide a thorough convergence analysis for tt-fed. based on the obtained analytical convergence upper bound, the optimization problem is decomposed into tractable sub-problems with respect to each global aggregation round, and finally solved by our proposed online search algorithm. simulation results show that compared to asynchronous fl (fedasync) and fl with asynchronous user tiers (fedat) benchmarks, our proposed tt-fed algorithm improves the converged test accuracy by up to 12.5% and 5%, respectively, under highly imbalanced and non-iid data, while substantially reducing the communication overhead."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2022-04-26 ,2022-05-02 ,"['xiaokang zhou', 'yansha deng', 'huiyun xia', 'shaochuan wu', 'mehdi bennis']"
2204.12443 ,a review of federated learning in intrusion detection systems for iot                                                                                                                   ,cs.cr cs.lg                                              ,"intrusion detection systems are evolving into intelligent systems that perform data analysis searching for anomalies in their environment. the development of deep learning technologies opened the door to build more complex and effective threat detection models. however, training those models may be computationally infeasible in most internet of things devices. current approaches rely on powerful centralized servers that receive data from all their parties -- violating basic privacy constraints and substantially affecting response times and operational costs due to the huge communication overheads. to mitigate these issues, federated learning emerged as a promising approach where different agents collaboratively train a shared model, neither exposing training data to others nor requiring a compute-intensive centralized infrastructure. this paper focuses on the application of federated learning approaches in the field of intrusion detection. both technologies are described in detail and current scientific progress is reviewed and categorized. finally, the paper highlights the limitations present in recent works and presents some future directions for this technology."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ,                                                                        ,2022-04-26 ,2022-04-29 ,"['aitor belenguer', 'javier navaridas', 'jose a. pascual']"
2204.12466 ,meta-free few-shot learning via representation learning with weight   averaging                                                                                                         ,cs.lg cs.cv                                              ,"recent studies on few-shot classification using transfer learning pose challenges to the effectiveness and efficiency of episodic meta-learning algorithms. transfer learning approaches are a natural alternative, but they are restricted to few-shot classification. moreover, little attention has been on the development of probabilistic models with well-calibrated uncertainty from few-shot samples, except for some bayesian episodic learning algorithms. to tackle the aforementioned issues, we propose a new transfer learning method to obtain accurate and reliable models for few-shot regression and classification. the resulting method does not require episodic meta-learning and is called meta-free representation learning (mfrl). mfrl first finds low-rank representation generalizing well on meta-test tasks. given the learned representation, probabilistic linear models are fine-tuned with few-shot samples to obtain models with well-calibrated uncertainty. the proposed method not only achieves the highest accuracy on a wide range of few-shot learning benchmark datasets but also correctly quantifies the prediction uncertainty. in addition, weight averaging and temperature scaling are effective in improving the accuracy and reliability of few-shot learning in existing meta-learning algorithms with a wide range of learning paradigms and model architectures."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,                                                                        ,2022-04-26 ,2022-04-30 ,"['kuilin chen', 'chi-guhn lee']"
2204.12471 ,coarse-to-fine q-attention with tree expansion                                                                                                                                          ,cs.ro cs.ai cs.cv cs.lg                                  ,"coarse-to-fine q-attention enables sample-efficient robot manipulation by discretizing the translation space in a coarse-to-fine manner, where the resolution gradually increases at each layer in the hierarchy. although effective, q-attention suffers from ""coarse ambiguity"" - when voxelization is significantly coarse, it is not feasible to distinguish similar-looking objects without first inspecting at a finer resolution. to combat this, we propose to envision q-attention as a tree that can be expanded and used to accumulate value estimates across the top-k voxels at each q-attention depth. when our extension, q-attention with tree expansion (qte), replaces standard q-attention in the attention-driven robot manipulation (arm) system, we are able to accomplish a larger set of tasks; especially on those that suffer from ""coarse ambiguity"". in addition to evaluating our approach across 12 rlbench tasks, we also show that the improved performance is visible in a real-world task involving small objects."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2022-04-26 ,2022-05-02 ,"['stephen james', 'pieter abbeel']"
2204.12527 ,application of wgan-gp in recommendation and questioning the relevance   of gan-based approaches                                                                                        ,cs.ir cs.lg                                              ,"many neural-based recommender systems were proposed in recent years and part of them used generative adversarial networks (gan) to model user-item interactions. however, the exploration of wasserstein gan with gradient penalty (wgan-gp) on recommendation has received relatively less scrutiny. in this paper, we focus on two questions: 1- can we successfully apply wgan-gp on recommendation and does this approach give an advantage compared to the best gan models? 2- are gan-based recommender systems relevant? to answer the first question, we propose a recommender system based on wgan-gp called cfwgan-gp which is founded on a previous model (cfgan). we successfully applied our method on real-world datasets on the top-k recommendation task and the empirical results show that it is competitive with state-of-the-art gan approaches, but we found no evidence of significant advantage of using wgan-gp instead of the original gan, at least from the accuracy point of view. as for the second question, we conduct a simple experiment in which we show that a well-tuned conceptually simpler method outperforms gan-based models by a considerable margin, questioning the use of such models."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ,                                                                        ,2022-04-26 ,2022-04-28 ,"['hichem ammar khodja', 'oussama boudjeniba']"
2204.12589 ,self-scalable tanh (stan): faster convergence and better generalization   in physics-informed neural networks                                                                           ,cs.lg cs.ne                                              ,"physics-informed neural networks (pinns) are gaining attention in the engineering and scientific literature for solving a range of differential equations with applications in weather modeling, healthcare, manufacturing, etc. poor scalability is one of the barriers to utilizing pinns for many real-world problems. to address this, a self-scalable tanh (stan) activation function is proposed for the pinns. the proposed stan function is smooth, non-saturating, and has a trainable parameter. during training, it can allow easy flow of gradients to compute the required derivatives and also enable systematic scaling of the input-output mapping. it is shown theoretically that the pinns with the proposed stan function have no spurious stationary points when using gradient descent algorithms. the proposed stan is tested on a number of numerical studies involving general regression problems. it is subsequently used for solving multiple forward problems, which involve second-order derivatives and multiple dimensions, and an inverse problem where the thermal diffusivity of a rod is predicted with heat conduction data. these case studies establish empirically that the stan activation function can achieve better training and more accurate predictions than the existing activation functions in the literature."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ,                                                                        ,2022-04-26 ,2022-04-29 ,"['raghav gnanasambandam', 'bo shen', 'jihoon chung', 'xubo yue', 'n/a zhenyu', 'n/a kong']"
2204.12868 ,performance and interpretability comparisons of supervised machine   learning algorithms: an empirical study                                                                            ,stat.ml cs.lg                                            ,"this paper compares the performances of three supervised machine learning algorithms in terms of predictive ability and model interpretation on structured or tabular data. the algorithms considered were scikit-learn implementations of extreme gradient boosting machines (xgb) and random forests (rfs), and feedforward neural networks (ffnns) from tensorflow. the paper is organized in a findings-based manner, with each section providing general conclusions supported by empirical results from simulation studies that cover a wide range of model complexity and correlation structures among predictors. we considered both continuous and binary responses of different sample sizes.   overall, xgb and ffnns were competitive, with ffnns showing better performance in smooth models and tree-based boosting algorithms performing better in non-smooth models. this conclusion held generally for predictive performance, identification of important variables, and determining correct input-output relationships as measured by partial dependence plots (pdps). ffnns generally had less over-fitting, as measured by the difference in performance between training and testing datasets. however, the difference with xgb was often small. rfs did not perform well in general, confirming the findings in the literature. all models exhibited different degrees of bias seen in pdps, but the bias was especially problematic for rfs. the extent of the biases varied with correlation among predictors, response type, and data set sample size. in general, tree-based models tended to over-regularize the fitted model in the tails of predictor distributions. finally, as to be expected, performances were better for continuous responses compared to binary data and with larger samples."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,                                                                        ,2022-04-27 ,2022-05-05 ,"['alice j. liu', 'arpita mukherjee', 'linwei hu', 'jie chen', 'vijayan n. nair']"
2204.13021 ,"nlu++: a multi-label, slot-rich, generalisable dataset for natural   language understanding in task-oriented dialogue"                                                                 ,cs.cl cs.lg                                              ,"we present nlu++, a novel dataset for natural language understanding (nlu) in task-oriented dialogue (tod) systems, with the aim to provide a much more challenging evaluation environment for dialogue nlu models, up to date with the current application and industry requirements. nlu++ is divided into two domains (banking and hotels) and brings several crucial improvements over current commonly used nlu datasets. 1) nlu++ provides fine-grained domain ontologies with a large set of challenging multi-intent sentences, introducing and validating the idea of intent modules that can be combined into complex intents that convey complex user goals, combined with finer-grained and thus more challenging slot sets. 2) the ontology is divided into domain-specific and generic (i.e., domain-universal) intent modules that overlap across domains, promoting cross-domain reusability of annotated examples. 3) the dataset design has been inspired by the problems observed in industrial tod systems, and 4) it has been collected, filtered and carefully annotated by dialogue nlu experts, yielding high-quality annotated data. finally, we benchmark a series of current state-of-the-art nlu models on nlu++; the results demonstrate the challenging nature of the dataset, especially in low-data regimes, the validity of `intent modularisation', and call for further research on tod nlu."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ,                                                                        ,2022-04-27 ,2022-05-05 ,"['iñigo casanueva', 'ivan vulić', 'georgios p. spithourakis', 'paweł budzianowski']"
2204.13335 ,anomaly detection by leveraging incomplete anomalous knowledge with   anomaly-aware bidirectional gans                                                                                  ,cs.lg                                                    ,"the goal of anomaly detection is to identify anomalous samples from normal ones. in this paper, a small number of anomalies are assumed to be available at the training stage, but they are assumed to be collected only from several anomaly types, leaving the majority of anomaly types not represented in the collected anomaly dataset at all. to effectively leverage this kind of incomplete anomalous knowledge represented by the collected anomalies, we propose to learn a probability distribution that can not only model the normal samples, but also guarantee to assign low density values for the collected anomalies. to this end, an anomaly-aware generative adversarial network (gan) is developed, which, in addition to modeling the normal samples as most gans do, is able to explicitly avoid assigning probabilities for collected anomalous samples. moreover, to facilitate the computation of anomaly detection criteria like reconstruction error, the proposed anomaly-aware gan is designed to be bidirectional, attaching an encoder for the generator. extensive experimental results demonstrate that our proposed method is able to effectively make use of the incomplete anomalous information, leading to significant performance gains compared to existing methods."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ,                                                                        ,2022-04-28 ,2022-05-01 ,"['bowen tian', 'qinliang su', 'jian yin']"
2204.13409 ,weanf: weak supervision with normalizing flows                                                                                                                                          ,cs.cl cs.lg                                              ,"a popular approach to decrease the need for costly manual annotation of large data sets is weak supervision, which introduces problems of noisy labels, coverage and bias. methods for overcoming these problems have either relied on discriminative models, trained with cost functions specific to weak supervision, and more recently, generative models, trying to model the output of the automatic annotation process. in this work, we explore a novel direction of generative modeling for weak supervision: instead of modeling the output of the annotation process (the labeling function matches), we generatively model the input-side data distributions (the feature space) covered by labeling functions. specifically, we estimate a density for each weak labeling source, or labeling function, by using normalizing flows. an integral part of our method is the flow-based modeling of multiple simultaneously matching labeling functions, and therefore phenomena such as labeling function overlap and correlations are captured. we analyze the effectiveness and modeling capabilities on various commonly used weak supervision data sets, and show that weakly supervised normalizing flows compare favorably to standard weak supervision baselines."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,                                                                        ,2022-04-28 ,2022-05-02 ,"['andreas stephan', 'benjamin roth']"
2204.13574 ,an explainable regression framework for predicting remaining useful life   of machines                                                                                                  ,cs.lg cs.ai                                              ,"prediction of a machine's remaining useful life (rul) is one of the key tasks in predictive maintenance. the task is treated as a regression problem where machine learning (ml) algorithms are used to predict the rul of machine components. these ml algorithms are generally used as a black box with a total focus on the performance without identifying the potential causes behind the algorithms' decisions and their working mechanism. we believe, the performance (in terms of mean squared error (mse), etc.,) alone is not enough to build the trust of the stakeholders in ml prediction rather more insights on the causes behind the predictions are needed. to this aim, in this paper, we explore the potential of explainable ai (xai) techniques by proposing an explainable regression framework for the prediction of machines' rul. we also evaluate several ml algorithms including classical and neural networks (nns) based solutions for the task. for the explanations, we rely on two model agnostic xai methods namely local interpretable model-agnostic explanations (lime) and shapley additive explanations (shap). we believe, this work will provide a baseline for future research in the domain."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,                                                                        ,2022-04-28 ,2022-04-30 ,"['talhat khan', 'kashif ahmad', 'jebran khan', 'imran khan', 'nasir ahmad']"
2204.13697 ,federated learning: balancing the thin line between data intelligence   and privacy                                                                                                     ,cs.lg cs.ai cs.cv eess.iv                                ,"federated learning holds great promise in learning from fragmented sensitive data and has revolutionized how machine learning models are trained. this article provides a systematic overview and detailed taxonomy of federated learning. we investigate the existing security challenges in federated learning and provide a comprehensive overview of established defense techniques for data poisoning, inference attacks, and model poisoning attacks. the work also presents an overview of current training challenges for federated learning, focusing on handling non-i.i.d. data, high dimensionality issues, and heterogeneous architecture, and discusses several solutions for the associated challenges. finally, we discuss the remaining challenges in managing federated learning training and suggest focused research directions to address the open questions. potential candidate areas for federated learning, including iot ecosystem, healthcare applications, are discussed with a particular focus on banking and financial domains."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,                                                                        ,2022-04-22 ,           ,"['sherin mary mathews', 'samuel a. assefa']"
2204.13700 ,identifying critical lms features for predicting at-risk students                                                                                                                       ,cs.cy cs.lg                                              ,"learning management systems (lmss) have become essential in higher education and play an important role in helping educational institutions to promote student success. traditionally, lmss have been used by postsecondary institutions in administration, reporting, and delivery of educational content. in this paper, we present an additional use of lms by using its data logs to perform data-analytics and identify academically at-risk students. the data-driven insights would allow educational institutions and educators to develop and implement pedagogical interventions targeting academically at-risk students. we used anonymized data logs created by brightspace lms during fall 2019, spring 2020, and fall 2020 semesters at our college. supervised machine learning algorithms were used to predict the final course performance of students, and several algorithms were found to perform well with accuracy above 90%. shap value method was used to assess the relative importance of features used in the predictive models. unsupervised learning was also used to group students into different clusters based on the similarities in their interaction/involvement with lms. in both of supervised and unsupervised learning, we identified two most-important features (number_of_assignment_submissions and content_completed). more importantly, our study lays a foundation and provides a framework for developing a real-time data analytics metric that may be incorporated into a lms."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,                                                                        ,2022-04-27 ,           ,"['ying guo', 'cengiz gunay', 'sairam tangirala', 'david kerven', 'wei jin', 'jamye curry savage', 'seungjin lee']"
2204.13702 ,neighbor-based optimized logistic regression machine learning model for   electric vehicle occupancy detection                                                                          ,cs.lg                                                    ,"this paper presents an optimized logistic regression machine learning model that predicts the occupancy of an electric vehicle (ev) charging station given the occupancy of neighboring stations. the model was optimized for the time of day. trained on data from 57 ev charging stations around the university of california san diego campus, the model achieved an 88.43% average accuracy and 92.23% maximum accuracy in predicting occupancy, outperforming a persistence model benchmark."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,                                                                        ,2022-04-27 ,           ,"['sayan shaw', 'keaton chia', 'jan kleissl']"
2204.13707 ,tag-assisted multimodal sentiment analysis under uncertain missing   modalities                                                                                                         ,cs.lg cs.ai                                              ,"multimodal sentiment analysis has been studied under the assumption that all modalities are available. however, such a strong assumption does not always hold in practice, and most of multimodal fusion models may fail when partial modalities are missing. several works have addressed the missing modality problem; but most of them only considered the single modality missing case, and ignored the practically more general cases of multiple modalities missing. to this end, in this paper, we propose a tag-assisted transformer encoder (tate) network to handle the problem of missing uncertain modalities. specifically, we design a tag encoding module to cover both the single modality and multiple modalities missing cases, so as to guide the network's attention to those missing modalities. besides, we adopt a new space projection pattern to align common vectors. then, a transformer encoder-decoder network is utilized to learn the missing modality features. at last, the outputs of the transformer encoder are used for the final sentiment classification. extensive experiments are conducted on cmu-mosi and iemocap datasets, showing that our method can achieve significant improvements compared with several baselines."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,                                                                        ,2022-04-28 ,           ,"['jiandian zeng', 'tianyi liu', 'jiantao zhou']"
2204.13744 ,gcn-ffnn: a two-stream deep model for learning solution to partial   differential equations                                                                                             ,cs.lg cs.na math.na physics.comp-ph                      ,"this paper introduces a novel two-stream deep model based on graph convolutional network (gcn) architecture and feed-forward neural networks (ffnn) for learning the solution of nonlinear partial differential equations (pdes). the model aims at incorporating both graph and grid input representations using two streams corresponding to gcn and ffnn models, respectively. each stream layer receives and processes its own input representation. as opposed to ffnn which receives a grid-like structure, the gcn stream layer operates on graph input data where the neighborhood information is incorporated through the adjacency matrix of the graph. in this way, the proposed gcn-ffnn model learns from two types of input representations, i.e. grid and graph data, obtained via the discretization of the pde domain. the gcn-ffnn model is trained in two phases. in the first phase, the model parameters of each stream are trained separately. both streams employ the same error function to adjust their parameters by enforcing the models to satisfy the given pde as well as its initial and boundary conditions on grid or graph collocation (training) data. in the second phase, the learned parameters of two-stream layers are frozen and their learned representation solutions are fed to fully connected layers whose parameters are learned using the previously used error function. the learned gcn-ffnn model is tested on test data located both inside and outside the pde domain. the obtained numerical results demonstrate the applicability and efficiency of the proposed gcn-ffnn model over individual gcn and ffnn models on 1d-burgers, 1d-schr\""odinger, 2d-burgers and 2d-schr\""odinger equations."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2022-04-28 ,           ,"['onur bilgin', 'thomas vergutz', 'siamak mehrkanoon']"
2204.13751 ,beinit: avoiding barren plateaus in variational quantum algorithms                                                                                                                      ,quant-ph cs.lg                                           ,"barren plateaus are a notorious problem in the optimization of variational quantum algorithms and pose a critical obstacle in the quest for more efficient quantum machine learning algorithms. many potential reasons for barren plateaus have been identified but few solutions have been proposed to avoid them in practice. existing solutions are mainly focused on the initialization of unitary gate parameters without taking into account the changes induced by input data. in this paper, we propose an alternative strategy which initializes the parameters of a unitary gate by drawing from a beta distribution. the hyperparameters of the beta distribution are estimated from the data. to further prevent barren plateau during training we add a novel perturbation at every gradient descent step. taking these ideas together, we empirically show that our proposed framework significantly reduces the possibility of a complex quantum neural network getting stuck in a barren plateau."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,                                                                        ,2022-04-28 ,           ,"['ankit kulshrestha', 'ilya safro']"
2204.13765 ,probabilistic permutation graph search: black-box optimization for   fairness in ranking                                                                                                ,cs.lg cs.ir                                              ,"there are several measures for fairness in ranking, based on different underlying assumptions and perspectives. pl optimization with the reinforce algorithm can be used for optimizing black-box objective functions over permutations. in particular, it can be used for optimizing fairness measures. however, though effective for queries with a moderate number of repeating sessions, pl optimization has room for improvement for queries with a small number of repeating sessions.   in this paper, we present a novel way of representing permutation distributions, based on the notion of permutation graphs. similar to pl, our distribution representation, called ppg, can be used for black-box optimization of fairness. different from pl, where pointwise logits are used as the distribution parameters, in ppg pairwise inversion probabilities together with a reference permutation construct the distribution. as such, the reference permutation can be set to the best sampled permutation regarding the objective function, making ppg suitable for both deterministic and stochastic rankings. our experiments show that ppg, while comparable to pl for larger session repetitions (i.e., stochastic ranking), improves over pl for optimizing fairness metrics for queries with one session (i.e., deterministic ranking). additionally, when accurate utility estimations are available, e.g., in tabular models, the performance of ppg in fairness optimization is significantly boosted compared to lower quality utility estimations from a learning to rank model, leading to a large performance gap with pl. finally, the pairwise probabilities make it possible to impose pairwise constraints such as ""item $d_1$ should always be ranked higher than item $d_2$."" such constraints can be used to simultaneously optimize the fairness metric and control another objective such as ranking performance."                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,10.1145/3477495.3532045                                                 ,2022-04-28 ,           ,"['ali vardasbi', 'fatemeh sarvi', 'maarten de rijke']"
2204.13767 ,"triformer: triangular, variable-specific attentions for long sequence   multivariate time series forecasting--full version"                                                            ,cs.lg                                                    ,"a variety of real-world applications rely on far future information to make decisions, thus calling for efficient and accurate long sequence multivariate time series forecasting. while recent attention-based forecasting models show strong abilities in capturing long-term dependencies, they still suffer from two key limitations. first, canonical self attention has a quadratic complexity w.r.t. the input time series length, thus falling short in efficiency. second, different variables' time series often have distinct temporal dynamics, which existing studies fail to capture, as they use the same model parameter space, e.g., projection matrices, for all variables' time series, thus falling short in accuracy. to ensure high efficiency and accuracy, we propose triformer, a triangular, variable-specific attention. (i) linear complexity: we introduce a novel patch attention with linear complexity. when stacking multiple layers of the patch attentions, a triangular structure is proposed such that the layer sizes shrink exponentially, thus maintaining linear complexity. (ii) variable-specific parameters: we propose a light-weight method to enable distinct sets of model parameters for different variables' time series to enhance accuracy without compromising efficiency and memory usage. strong empirical evidence on four datasets from multiple domains justifies our design choices, and it demonstrates that triformer outperforms state-of-the-art methods w.r.t. both accuracy and efficiency. this is an extended version of ""triformer: triangular, variable-specific attentions for long sequence multivariate time series forecasting"", to appear in ijcai 2022 [cirstea et al., 2022a], including additional experimental results."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,                                                                        ,2022-04-28 ,           ,"['razvan-gabriel cirstea', 'chenjuan guo', 'bin yang', 'tung kieu', 'xuanyi dong', 'shirui pan']"
2204.13808 ,analysing the influence of attack configurations on the reconstruction   of medical images in federated learning                                                                        ,eess.iv cs.cr cs.cv cs.lg                                ,"the idea of federated learning is to train deep neural network models collaboratively and share them with multiple participants without exposing their private training data to each other. this is highly attractive in the medical domain due to patients' privacy records. however, a recently proposed method called deep leakage from gradients enables attackers to reconstruct data from shared gradients. this study shows how easy it is to reconstruct images for different data initialization schemes and distance measures. we show how data and model architecture influence the optimal choice of initialization scheme and distance measure configurations when working with single images. we demonstrate that the choice of initialization scheme and distance measure can significantly increase convergence speed and quality. furthermore, we find that the optimal attack configuration depends largely on the nature of the target image distribution and the complexity of the model architecture."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2022-04-25 ,           ,"['mads emil dahlgaard', 'morten wehlast jørgensen', 'niels asp fuglsang', 'hiba nassar']"
2204.13812 ,visualization and optimization techniques for high dimensional parameter   spaces                                                                                                       ,cs.hc cs.ai cs.gr cs.lg                                  ,"high dimensional parameter space optimization is crucial in many applications. the parameters affecting this performance can be both numerical and categorical in their type. the existing techniques of black-box optimization and visual analytics are good in dealing with numerical parameters but analyzing categorical variables in context of the numerical variables are not well studied. hence, we propose a novel approach, to create an auto-tuning framework for storage systems optimization combining both direct optimization techniques and visual analytics research. while the optimization algorithm will be the core of the system, visual analytics will provide a guideline with the help of an external agent (expert) to provide crucial hints to narrow down the large search space for the optimization engine. as part of the initial step towards creating an auto-tuning engine for storage systems optimization, we created an interactive configuration explorer \textit{ice}, which directly addresses the need of analysts to learn how the dependent numerical variable is affected by the parameter settings given multiple optimization objectives. no information is lost as ice shows the complete distribution and statistics of the dependent variable in context with each categorical variable. analysts can interactively filter the variables to optimize for certain goals such as achieving a system with maximum performance, low variance, etc. our system was developed in tight collaboration with a group of systems performance researchers and its final effectiveness was evaluated with expert interviews, a comparative user study, and two case studies. we also discuss our research plan for creating an efficient auto-tuning framework combining black-box optimization and visual analytics for storage systems performance optimization."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2022-04-28 ,           ,['anjul tyagi']
2204.13814 ,an online ensemble learning model for detecting attacks in wireless   sensor networks                                                                                                   ,cs.ni cs.cr cs.lg                                        ,"in today's modern world, the usage of technology is unavoidable and the rapid advances in the internet and communication fields have resulted to expand the wireless sensor network (wsn) technology. a huge number of sensing devices collect and/or generate numerous sensory data throughout time for a wide range of fields and applications. however, wsn has been proven to be vulnerable to security breaches, the harsh and unattended deployment of these networks, combined with their constrained resources and the volume of data generated introduce a major security concern. wsn applications are extremely critical, it is essential to build reliable solutions that involve fast and continuous mechanisms for online data stream analysis enabling the detection of attacks and intrusions. in this context, our aim is to develop an intelligent, efficient, and updatable intrusion detection system by applying an important machine learning concept known as ensemble learning in order to improve detection performance. although ensemble models have been proven to be useful in offline learning, they have received less attention in streaming applications. in this paper, we examine the application of different homogeneous and heterogeneous online ensembles in sensory data analysis, on a specialized wireless sensor network-detection system (wsn-ds) dataset in order to classify four types of attacks: blackhole attack, grayhole, flooding, and scheduling among normal network traffic. among the proposed novel online ensembles, both the heterogeneous ensemble consisting of an adaptive random forest (arf) combined with the hoeffding adaptive tree (hat) algorithm and the homogeneous ensemble hat made up of 10 models achieved higher detection rates of 96.84% and 97.2%, respectively. the above models are efficient and effective in dealing with concept drift, while taking into account the resource constraints of wsns."                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2022-04-28 ,           ,"['hiba tabbaa', 'samir ifzarne', 'imad hafidi']"
2204.13819 ,automatic machine learning for multi-receiver cnn technology classifiers                                                                                                                ,cs.lg cs.ni eess.sp                                      ,"convolutional neural networks (cnns) are one of the most studied family of deep learning models for signal classification, including modulation, technology, detection, and identification. in this work, we focus on technology classification based on raw i/q samples collected from multiple synchronized receivers. as an example use case, we study protocol identification of wi-fi, lte-laa, and 5g nr-u technologies that coexist over the 5 ghz unlicensed national information infrastructure (u-nii) bands. designing and training accurate cnn classifiers involve significant time and effort that goes into fine-tuning a model's architectural settings and determining the appropriate hyperparameter configurations, such as learning rate and batch size. we tackle the former by defining architectural settings themselves as hyperparameters. we attempt to automatically optimize these architectural parameters, along with other preprocessing (e.g., number of i/q samples within each classifier input) and learning hyperparameters, by forming a hyperparameter optimization (hyperopt) problem, which we solve in a near-optimal fashion using the hyperband algorithm. the resulting near-optimal cnn (ocnn) classifier is then used to study classification accuracy for ota as well as simulations datasets, considering various snr values. we show that the number of receivers to construct multi-channel inputs for cnns should be defined as a preprocessing hyperparameter to be optimized via hyperband. ota results reveal that our ocnn classifiers improve classification accuracy by 24.58% compared to manually tuned cnns. we also study the effect of min-max normalization of i/q samples within each classifier's input on generalization accuracy over simulated datasets with snrs other than training set's snr and show an average of 108.05% improvement when i/q samples are normalized."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ,10.1145/3522783.3529524 10.1145/3522783.3529524 10.1145/3522783.3529524 ,2022-04-28 ,           ,"['amir-hossein yazdani-abyaneh', 'marwan krunz']"
2204.13838 ,noise-reducing attention cross fusion learning transformer for   histological image classification of osteosarcoma                                                                      ,eess.iv cs.cv cs.lg                                      ,"the degree of malignancy of osteosarcoma and its tendency to metastasize/spread mainly depend on the pathological grade (determined by observing the morphology of the tumor under a microscope). the purpose of this study is to use artificial intelligence to classify osteosarcoma histological images and to assess tumor survival and necrosis, which will help doctors reduce their workload, improve the accuracy of osteosarcoma cancer detection, and make a better prognosis for patients. the study proposes a typical transformer image classification framework by integrating noise reduction convolutional autoencoder and feature cross fusion learning (nrca-fcfl) to classify osteosarcoma histological images. noise reduction convolutional autoencoder could well denoise histological images of osteosarcoma, resulting in more pure images for osteosarcoma classification. moreover, we introduce feature cross fusion learning, which integrates two scale image patches, to sufficiently explore their interactions by using additional classification tokens. as a result, a refined fusion feature is generated, which is fed to the residual neural network for label predictions. we conduct extensive experiments to evaluate the performance of the proposed approach. the experimental results demonstrate that our method outperforms the traditional and deep learning approaches on various evaluation metrics, with an accuracy of 99.17% to support osteosarcoma diagnosis."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,                                                                        ,2022-04-28 ,           ,"['liangrui pan', 'hetian wang', 'lian wang', 'boya ji', 'mingting liu', 'mitchai chongcheawchamnan', 'jin yuan', 'shaoliang peng']"
2204.13845 ,gendr: a generalized differentiable renderer                                                                                                                                            ,cs.cv cs.lg                                              ,"in this work, we present and study a generalized family of differentiable renderers. we discuss from scratch which components are necessary for differentiable rendering and formalize the requirements for each component. we instantiate our general differentiable renderer, which generalizes existing differentiable renderers like softras and dib-r, with an array of different smoothing distributions to cover a large spectrum of reasonable settings. we evaluate an array of differentiable renderer instantiations on the popular shapenet 3d reconstruction benchmark and analyze the implications of our results. surprisingly, the simple uniform distribution yields the best overall results when averaged over 13 classes; in general, however, the optimal choice of distribution heavily depends on the task."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,                                                                        ,2022-04-28 ,           ,"['felix petersen', 'bastian goldluecke', 'christian borgelt', 'oliver deussen']"
2204.13846 ,rosa: a robust self-aligned framework for node-node graph contrastive   learning                                                                                                        ,cs.lg cs.ai                                              ,"graph contrastive learning has gained significant progress recently. however, existing works have rarely explored non-aligned node-node contrasting. in this paper, we propose a novel graph contrastive learning method named rosa that focuses on utilizing non-aligned augmented views for node-level representation learning. first, we leverage the earth mover's distance to model the minimum effort to transform the distribution of one view to the other as our contrastive objective, which does not require alignment between views. then we introduce adversarial training as an auxiliary method to increase sampling diversity and enhance the robustness of our model. experimental results show that rosa outperforms a series of graph contrastive learning frameworks on homophilous, non-homophilous and dynamic graphs, which validates the effectiveness of our work. to the best of our awareness, rosa is the first work focuses on the non-aligned node-node graph contrastive learning problem. our codes are available at: \href{https://github.com/zhuyun97/rosa}{\texttt{https://github.com/zhuyun97/rosa}}"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2022-04-28 ,           ,"['yun zhu', 'jianhao guo', 'fei wu', 'siliang tang']"
2204.13847 ,catnet: cross-event attention-based time-aware network for medical event   prediction                                                                                                   ,cs.lg cs.ai                                              ,"medical event prediction (mep) is a fundamental task in the medical domain, which needs to predict medical events, including medications, diagnosis codes, laboratory tests, procedures, outcomes, and so on, according to historical medical records. the task is challenging as medical data is a type of complex time series data with heterogeneous and temporal irregular characteristics. many machine learning methods that consider the two characteristics have been proposed for medical event prediction. however, most of them consider the two characteristics separately and ignore the correlations among different types of medical events, especially relations between historical medical events and target medical events. in this paper, we propose a novel neural network based on attention mechanism, called cross-event attention-based time-aware network (catnet), for medical event prediction. it is a time-aware, event-aware and task-adaptive method with the following advantages: 1) modeling heterogeneous information and temporal information in a unified way and considering temporal irregular characteristics locally and globally respectively, 2) taking full advantage of correlations among different types of events via cross-event attention. experiments on two public datasets (mimic-iii and eicu) show catnet can be adaptive with different mep tasks and outperforms other state-of-the-art methods on various mep tasks. the source code of catnet will be released after this manuscript is accepted."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,                                                                        ,2022-04-28 ,           ,"['sicen liu', 'xiaolong wang', 'yang xiang', 'hui xu', 'hui wang', 'buzhou tang']"
2204.13849 ,goldilocks-curriculum domain randomization and fractal perlin noise with   application to sim2real pneumonia lesion detection                                                           ,cs.cv cs.lg                                              ,"a computer-aided detection (cad) system based on machine learning is expected to assist radiologists in making a diagnosis. it is desirable to build cad systems for the various types of diseases accumulating daily in a hospital. an obstacle in developing a cad system for a disease is that the number of medical images is typically too small to improve the performance of the machine learning model. in this paper, we aim to explore ways to address this problem through a sim2real transfer approach in medical image fields. to build a platform to evaluate the performance of sim2real transfer methods in the field of medical imaging, we construct a benchmark dataset that consists of $101$ chest x-images with difficult-to-identify pneumonia lesions judged by an experienced radiologist and a simulator based on fractal perlin noise and the x-ray principle for generating pseudo pneumonia lesions. we then develop a novel domain randomization method, called goldilocks-curriculum domain randomization (gdr) and evaluate our method in this platform."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2022-04-28 ,           ,"['takahiro suzuki', 'shouhei hanaoka', 'issei sato']"
2204.13851 ,covid-net us-x: enhanced deep neural network for detection of covid-19   patient cases from convex ultrasound imaging through extended linear-convex   ultrasound augmentation learning ,eess.iv cs.cv cs.lg                                      ,"as the global population continues to face significant negative impact by the on-going covid-19 pandemic, there has been an increasing usage of point-of-care ultrasound (pocus) imaging as a low-cost and effective imaging modality of choice in the covid-19 clinical workflow. a major barrier with widespread adoption of pocus in the covid-19 clinical workflow is the scarcity of expert clinicians that can interpret pocus examinations, leading to considerable interest in deep learning-driven clinical decision support systems to tackle this challenge. a major challenge to building deep neural networks for covid-19 screening using pocus is the heterogeneity in the types of probes used to capture ultrasound images (e.g., convex vs. linear probes), which can lead to very different visual appearances. in this study, we explore the impact of leveraging extended linear-convex ultrasound augmentation learning on producing enhanced deep neural networks for covid-19 assessment, where we conduct data augmentation on convex probe data alongside linear probe data that have been transformed to better resemble convex probe data. experimental results using an efficient deep columnar anti-aliased convolutional neural network designed via a machined-driven design exploration strategy (which we name covid-net us-x) show that the proposed extended linear-convex ultrasound augmentation learning significantly increases performance, with a gain of 5.1% in test accuracy and 13.6% in auc."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,                                                                        ,2022-04-28 ,           ,"['e. zhixuan zeng', 'adrian florea', 'alexander wong']"
2204.13852 ,h2h: heterogeneous model to heterogeneous system mapping with   computation and communication awareness                                                                                 ,cs.lg cs.ai cs.dc                                        ,"the complex nature of real-world problems calls for heterogeneity in both machine learning (ml) models and hardware systems. the heterogeneity in ml models comes from multi-sensor perceiving and multi-task learning, i.e., multi-modality multi-task (mmmt), resulting in diverse deep neural network (dnn) layers and computation patterns. the heterogeneity in systems comes from diverse processing components, as it becomes the prevailing method to integrate multiple dedicated accelerators into one system. therefore, a new problem emerges: heterogeneous model to heterogeneous system mapping (h2h). while previous mapping algorithms mostly focus on efficient computations, in this work, we argue that it is indispensable to consider computation and communication simultaneously for better system efficiency. we propose a novel h2h mapping algorithm with both computation and communication awareness; by slightly trading computation for communication, the system overall latency and energy consumption can be largely reduced. the superior performance of our work is evaluated based on maestro modeling, demonstrating 15%-74% latency reduction and 23%-64% energy reduction compared with existing computation-prioritized mapping algorithms."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,                                                                        ,2022-04-28 ,           ,"['xinyi zhang', 'cong hao', 'peipei zhou', 'alex jones', 'jingtong hu']"
2204.13853 ,detecting textual adversarial examples based on distributional   characteristics of data representations                                                                                ,cs.cl cs.lg                                              ,"although deep neural networks have achieved state-of-the-art performance in various machine learning tasks, adversarial examples, constructed by adding small non-random perturbations to correctly classified inputs, successfully fool highly expressive deep classifiers into incorrect predictions. approaches to adversarial attacks in natural language tasks have boomed in the last five years using character-level, word-level, phrase-level, or sentence-level textual perturbations. while there is some work in nlp on defending against such attacks through proactive methods, like adversarial training, there is to our knowledge no effective general reactive approaches to defence via detection of textual adversarial examples such as is found in the image processing literature. in this paper, we propose two new reactive methods for nlp to fill this gap, which unlike the few limited application baselines from nlp are based entirely on distribution characteristics of learned representations: we adapt one from the image processing literature (local intrinsic dimensionality (lid)), and propose a novel one (multidistance representation ensemble method (mdre)). adapted lid and mdre obtain state-of-the-art results on character-level, word-level, and phrase-level attacks on the imdb dataset as well as on the later two with respect to the multinli dataset. for future research, we publish our code."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2022-04-28 ,           ,"['na liu', 'mark dras', 'wei emma zhang']"
2204.13878 ,energy minimization for federated asynchronous learning on   battery-powered mobile devices via application co-running                                                                  ,cs.dc cs.lg                                              ,"energy is an essential, but often forgotten aspect in large-scale federated systems. as most of the research focuses on tackling computational and statistical heterogeneity from the machine learning algorithms, the impact on the mobile system still remains unclear. in this paper, we design and implement an online optimization framework by connecting asynchronous execution of federated training with application co-running to minimize energy consumption on battery-powered mobile devices. from a series of experiments, we find that co-running the training process in the background with foreground applications gives the system a deep energy discount with negligible performance slowdown. based on these results, we first study an offline problem assuming all the future occurrences of applications are available, and propose a dynamic programming-based algorithm. then we propose an online algorithm using the lyapunov framework to explore the solution space via the energy-staleness trade-off. the extensive experiments demonstrate that the online optimization framework can save over 60% energy with 3 times faster convergence speed compared to the previous schemes."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ,                                                                        ,2022-04-29 ,           ,"['cong wang', 'bin hu', 'hongyi wu']"
2204.13900 ,framework for behavioral disorder detection using machine learning and   application of virtual cognitive behavioral therapy in covid-19 pandemic                                       ,cs.hc cs.lg                                              ,"in this modern world, people are becoming more self-centered and unsocial. on the other hand, people are stressed, becoming more anxious during covid-19 pandemic situation and exhibits symptoms of behavioral disorder. to measure the symptoms of behavioral disorder, usually psychiatrist use long hour sessions and inputs from specific questionnaire. this process is time consuming and sometime is ineffective to detect the right behavioral disorder. also, reserved people sometime hesitate to follow this process. we have created a digital framework which can detect behavioral disorder and prescribe virtual cognitive behavioral therapy (vcbt) for recovery. by using this framework people can input required data that are highly responsible for the three behavioral disorders namely depression, anxiety and internet addiction. we have applied machine learning technique to detect specific behavioral disorder from samples. this system guides the user with basic understanding and treatment through vcbt from anywhere any time which would potentially be the steppingstone for the user to be conscious and pursue right treatment."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2022-04-29 ,           ,"['tasnim niger', 'hasanur rayhan', 'rashidul islam', 'kazi asif abdullah noor', 'kamrul hasan']"
2204.13908 ,task embedding temporal convolution networks for transfer learning   problems in renewable power time-series forecast                                                                   ,cs.lg                                                    ,"task embeddings in multi-layer perceptrons for multi-task learning and inductive transfer learning in renewable power forecasts have recently been introduced. in many cases, this approach improves the forecast error and reduces the required training data. however, it does not take the seasonal influences in power forecasts within a day into account, i.e., the diurnal cycle. therefore, we extended this idea to temporal convolutional networks to consider those seasonalities. we propose transforming the embedding space, which contains the latent similarities between tasks, through convolution and providing these results to the network's residual block. the proposed architecture significantly improves up to 25 percent for multi-task learning for power forecasts on the europewindfarm and germansolarfarm dataset compared to the multi-layer perceptron approach. based on the same data, we achieve a ten percent improvement for the wind datasets and more than 20 percent in most cases for the solar dataset for inductive transfer learning without catastrophic forgetting. finally, we are the first proposing zero-shot learning for renewable power forecasts to provide predictions even if no training data is available."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ,10.1007/978-3-030-86514-6_8                                             ,2022-04-29 ,           ,"['jens schreiber', 'stephan vogt', 'bernhard sick']"
2204.13916 ,a study of tree-based methods and their combination                                                                                                                                     ,stat.ml cs.lg                                            ,"tree-based methods are popular machine learning techniques used in various fields. in this work, we review their foundations and a general framework the importance sampled learning ensemble (isle) that accelerates their fitting process. furthermore, we describe a model combination strategy called the adaptive regression by mixing (arm), which is feasible for tree-based methods via isle. moreover, three modified isles are proposed, and their performance are evaluated on the real data sets."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ,                                                                        ,2022-04-29 ,           ,['yinuo zeng']
2204.13917 ,a mixed-domain self-attention network for multilabel cardiac   irregularity classification using reduced-lead electrocardiogram                                                         ,cs.lg                                                    ,"electrocardiogram(ecg) is commonly used to detect cardiac irregularities such as atrial fibrillation, bradycardia, and other irregular complexes. while previous studies have achieved great accomplishment classifying these irregularities with standard 12-lead ecgs, there existed limited evidence demonstrating the utility of reduced-lead ecgs in capturing a wide-range of diagnostic information. in addition, classification model's generalizability across multiple recording sources also remained uncovered. as part of the physionet computing in cardiology challenge 2021, our team haowan aiec, proposed mixed-domain self-attention resnet (mdarsn) to identify cardiac abnormalities from reduced-lead ecg. our classifiers received scores of 0.602, 0.593, 0.597, 0.591, and 0.589 (ranked 54th, 37th, 38th, 38th, and 39th) for the 12-lead, 6-lead, 4-lead, 3-lead, and 2-lead versions of the hidden validation set with the evaluation metric defined by the challenge."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,                                                                        ,2022-04-29 ,           ,"['hao-chun yang', 'wan-ting hsieh', 'trista pei-chun chen']"
2204.13963 ,tailored uncertainty estimation for deep learning systems                                                                                                                               ,cs.lg                                                    ,"uncertainty estimation bears the potential to make deep learning (dl) systems more reliable. standard techniques for uncertainty estimation, however, come along with specific combinations of strengths and weaknesses, e.g., with respect to estimation quality, generalization abilities and computational complexity. to actually harness the potential of uncertainty quantification, estimators are required whose properties closely match the requirements of a given use case. in this work, we propose a framework that, firstly, structures and shapes these requirements, secondly, guides the selection of a suitable uncertainty estimation method and, thirdly, provides strategies to validate this choice and to uncover structural weaknesses. by contributing tailored uncertainty estimation in this sense, our framework helps to foster trustworthy dl systems. moreover, it anticipates prospective machine learning regulations that require, e.g., in the eu, evidences for the technical appropriateness of machine learning systems. our framework provides such evidences for system components modeling uncertainty."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,                                                                        ,2022-04-29 ,           ,"['joachim sicking', 'maram akila', 'jan david schneider', 'fabian hüger', 'peter schlicht', 'tim wirtz', 'stefan wrobel']"
2204.13971 ,cost effective mlaas federation: a combinatorial reinforcement learning   approach                                                                                                      ,cs.lg cs.mm                                              ,"with the advancement of deep learning techniques, major cloud providers and niche machine learning service providers start to offer their cloud-based machine learning tools, also known as machine learning as a service (mlaas), to the public. according to our measurement, for the same task, these mlaases from different providers have varying performance due to the proprietary datasets, models, etc. federating different mlaases together allows us to improve the analytic performance further. however, naively aggregating results from different mlaases not only incurs significant momentary cost but also may lead to sub-optimal performance gain due to the introduction of possible false-positive results. in this paper, we propose armol, a framework to federate the right selection of mlaas providers to achieve the best possible analytic performance. we first design a word grouping algorithm to unify the output labels across different providers. we then present a deep combinatorial reinforcement learning based-approach to maximize the accuracy while minimizing the cost. the predictions from the selected providers are then aggregated together using carefully chosen ensemble strategies. the real-world trace-driven evaluation further demonstrates that armol is able to achieve the same accuracy results with $67\%$ less inference cost."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ,                                                                        ,2022-04-29 ,           ,"['shuzhao xie', 'yuan xue', 'yifei zhu', 'zhi wang']"
2204.13976 ,making sense of violence risk predictions using clinical notes                                                                                                                          ,cs.lg cs.cl cs.cy                                        ,"violence risk assessment in psychiatric institutions enables interventions to avoid violence incidents. clinical notes written by practitioners and available in electronic health records (ehr) are valuable resources that are seldom used to their full potential. previous studies have attempted to assess violence risk in psychiatric patients using such notes, with acceptable performance. however, they do not explain why classification works and how it can be improved. we explore two methods to better understand the quality of a classifier in the context of clinical note analysis: random forests using topic models, and choice of evaluation metric. these methods allow us to understand both our data and our methodology more profoundly, setting up the groundwork to work on improved models that build upon this understanding. this is particularly important when it comes to the generalizability of evaluated classifiers to new data, a trustworthiness problem that is of great interest due to the increased availability of new data in electronic format."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,10.1007/978-3-030-61951-0_1                                             ,2022-04-29 ,           ,"['pablo mosteiro', 'emil rijcken', 'kalliopi zervanou', 'uzay kaymak', 'floortje scheepers', 'marco spruit']"
2204.13989 ,"dynamic diagnosis of the progress and shortcomings of student learning   using machine learning based on cognitive, social, and emotional features"                                    ,cs.cy cs.lg                                              ,"student diversity, like academic background, learning styles, career and life goals, ethnicity, age, social and emotional characteristics, course load and work schedule, offers unique opportunities in education, like learning new skills, peer mentoring and example setting. but student diversity can be challenging too as it adds variability in the way in which students learn and progress over time. a single teaching approach is likely to be ineffective and result in students not meeting their potential. automated support could address limitations of traditional teaching by continuously assessing student learning and implementing needed interventions. this paper discusses a novel methodology based on data analytics and machine learning to measure and causally diagnose the progress and shortcomings of student learning, and then utilizes the insight gained on individuals to optimize learning. diagnosis pertains to dynamic diagnostic formative assessment, which aims to uncover the causes of learning shortcomings. the methodology groups learning difficulties into four categories: recall from memory, concept adjustment, concept modification, and problem decomposition into sub-goals (sub-problems) and concept combination. data models are predicting the occurrence of each of the four challenge types, as well as a student's learning trajectory. the models can be used to automatically create real-time, student-specific interventions (e.g., learning cues) to address less understood concepts. we envision that the system will enable new adaptive pedagogical approaches to unleash student learning potential through customization of the course material to the background, abilities, situation, and progress of each student; and leveraging diversity-related learning experiences."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ,                                                                        ,2022-04-13 ,           ,"['alex doboli', 'simona doboli', 'ryan duke', 'sangjin hong', 'wendy tang']"
2204.13991 ,physical deep learning with biologically plausible training method                                                                                                                      ,cs.ne cs.lg nlin.ao physics.optics                       ,"the ever-growing demand for further advances in artificial intelligence motivated research on unconventional computation based on analog physical devices. while such computation devices mimic brain-inspired analog information processing, learning procedures still relies on methods optimized for digital processing such as backpropagation. here, we present physical deep learning by extending a biologically plausible training algorithm called direct feedback alignment. as the proposed method is based on random projection with arbitrary nonlinear activation, we can train a physical neural network without knowledge about the physical system. in addition, we can emulate and accelerate the computation for this training on a simple and scalable physical system. we demonstrate the proof-of-concept using a hierarchically connected optoelectronic recurrent neural network called deep reservoir computer. by constructing an fpga-assisted optoelectronic benchtop, we confirmed the potential for accelerated computation with competitive performance on benchmarks. our results provide practical solutions for the training and acceleration of neuromorphic computation."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,                                                                        ,2022-04-01 ,           ,"['mitsumasa nakajima', 'katsuma inoue', 'kenji tanaka', 'yasuo kuniyoshi', 'toshikazu hashimoto', 'kohei nakajima']"
2204.13996 ,leveraging triplet loss and nonlinear dimensionality reduction for   on-the-fly channel charting                                                                                        ,cs.ni cs.lg eess.sp                                      ,"channel charting is an unsupervised learning method that aims at mapping wireless channels to a so-called chart, preserving as much as possible spatial neighborhoods. in this paper, a model-based deep learning approach to this problem is proposed. it builds on a physically motivated distance measure to structure and initialize a neural network that is subsequently trained using a triplet loss function. the proposed structure exhibits a low number of parameters and clever initialization leads to fast training. these two features make the proposed approach amenable to on-the-fly channel charting. the method is empirically assessed on realistic synthetic channels, yielding encouraging results."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,                                                                        ,2022-04-04 ,           ,"['taha yassine', 'luc le magoarou', 'stéphane paquelet', 'matthieu crussière']"
2204.13999 ,statistical applications of contrastive learning                                                                                                                                        ,cs.lg stat.ml                                            ,"the likelihood function plays a crucial role in statistical inference and experimental design. however, it is computationally intractable for several important classes of statistical models, including energy-based models and simulator-based models. contrastive learning is an intuitive and computationally feasible alternative to likelihood-based learning. we here first provide an introduction to contrastive learning and then show how we can use it to derive methods for diverse statistical problems, namely parameter estimation for energy-based models, bayesian inference for simulator-based models, as well as experimental design."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2022-04-29 ,           ,"['michael u. gutmann', 'steven kleinegesse', 'benjamin rhodes']"
2204.14006 ,no task left behind: multi-task learning of knowledge tracing and option   tracing for better student assessment                                                                        ,cs.cy cs.ai cs.lg                                        ,"student assessment is one of the most fundamental tasks in the field of ai education (aied). one of the most common approach to student assessment is knowledge tracing (kt), which evaluates a student's knowledge state by predicting whether the student will answer a given question correctly or not. however, in the context of multiple choice (polytomous) questions, conventional kt approaches are limited in that they only consider the binary (dichotomous) correctness label (i.e., correct or incorrect), and disregard the specific option chosen by the student. meanwhile, option tracing (ot) attempts to model a student by predicting which option they will choose for a given question, but overlooks the correctness information. in this paper, we propose dichotomous-polytomous multi-task learning (dp-mtl), a multi-task learning framework that combines kt and ot for more precise student assessment. in particular, we show that the kt objective acts as a regularization term for ot in the dp-mtl framework, and propose an appropriate architecture for applying our method on top of existing deep learning-based kt models. we experimentally confirm that dp-mtl significantly improves both kt and ot performances, and also benefits downstream tasks such as score prediction (sp)."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,                                                                        ,2022-04-08 ,           ,"['suyeong an', 'junghoon kim', 'minsam kim', 'juneyoung park']"
2204.14007 ,searching for efficient neural architectures for on-device ml on edge   tpus                                                                                                            ,cs.dc cs.cv cs.lg                                        ,"on-device ml accelerators are becoming a standard in modern mobile system-on-chips (soc). neural architecture search (nas) comes to the rescue for efficiently utilizing the high compute throughput offered by these accelerators. however, existing nas frameworks have several practical limitations in scaling to multiple tasks and different target platforms. in this work, we provide a two-pronged approach to this challenge: (i) a nas-enabling infrastructure that decouples model cost evaluation, search space design, and the nas algorithm to rapidly target various on-device ml tasks, and (ii) search spaces crafted from group convolution based inverted bottleneck (ibn) variants that provide flexible quality/performance trade-offs on ml accelerators, complementing the existing full and depthwise convolution based ibns. using this approach we target a state-of-the-art mobile platform, google tensor soc, and demonstrate neural architectures that improve the quality-performance pareto frontier for various computer vision (classification, detection, segmentation) as well as natural language processing tasks."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ,                                                                        ,2022-04-08 ,           ,"['berkin akin', 'suyog gupta', 'yun long', 'anton spiridonov', 'zhuo wang', 'marie white', 'hao xu', 'ping zhou', 'yanqi zhou']"
2204.14008 ,biologically-inspired neuronal adaptation improves learning in neural   networks                                                                                                        ,cs.ne cs.ai cs.lg                                        ,"since humans still outperform artificial neural networks on many tasks, drawing inspiration from the brain may help to improve current machine learning algorithms. contrastive hebbian learning (chl) and equilibrium propagation (ep) are biologically plausible algorithms that update weights using only local information (without explicitly calculating gradients) and still achieve performance comparable to conventional backpropagation. in this study, we augmented chl and ep with adjusted adaptation, inspired by the adaptation effect observed in neurons, in which a neuron's response to a given stimulus is adjusted after a short time. we add this adaptation feature to multilayer perceptrons and convolutional neural networks trained on mnist and cifar-10. surprisingly, adaptation improved the performance of these networks. we discuss the biological inspiration for this idea and investigate why neuronal adaptation could be an important brain mechanism to improve the stability and accuracy of learning."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,                                                                        ,2022-04-08 ,           ,"['yoshimasa kubo', 'eric chalmers', 'artur luczak']"
2204.14012 ,local explanation of dimensionality reduction                                                                                                                                           ,cs.lg cs.ai cs.ir                                        ,"dimensionality reduction (dr) is a popular method for preparing and analyzing high-dimensional data. reduced data representations are less computationally intensive and easier to manage and visualize, while retaining a significant percentage of their original information. aside from these advantages, these reduced representations can be difficult or impossible to interpret in most circumstances, especially when the dr approach does not provide further information about which features of the original space led to their construction. this problem is addressed by interpretable machine learning, a subfield of explainable artificial intelligence that addresses the opacity of machine learning models. however, current research on interpretable machine learning has been focused on supervised tasks, leaving unsupervised tasks like dimensionality reduction unexplored. in this paper, we introduce lxdr, a technique capable of providing local interpretations of the output of dr techniques. experiment results and two lxdr use case examples are presented to evaluate its usefulness."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,                                                                        ,2022-04-29 ,           ,"['avraam bardos', 'ioannis mollas', 'nick bassiliades', 'grigorios tsoumakas']"
2204.14020 ,exploration and exploitation in federated learning to exclude clients   with poisoned data                                                                                              ,cs.dc cs.lg                                              ,"federated learning (fl) is one of the hot research topics, and it utilizes machine learning (ml) in a distributed manner without directly accessing private data on clients. however, fl faces many challenges, including the difficulty to obtain high accuracy, high communication cost between clients and the server, and security attacks related to adversarial ml. to tackle these three challenges, we propose an fl algorithm inspired by evolutionary techniques. the proposed algorithm groups clients randomly in many clusters, each with a model selected randomly to explore the performance of different models. the clusters are then trained in a repetitive process where the worst performing cluster is removed in each iteration until one cluster remains. in each iteration, some clients are expelled from clusters either due to using poisoned data or low performance. the surviving clients are exploited in the next iteration. the remaining cluster with surviving clients is then used for training the best fl model (i.e., remaining fl model). communication cost is reduced since fewer clients are used in the final training of the fl model. to evaluate the performance of the proposed algorithm, we conduct a number of experiments using femnist dataset and compare the result against the random fl algorithm. the experimental results show that the proposed algorithm outperforms the baseline algorithm in terms of accuracy, communication cost, and security."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,                                                                        ,2022-04-29 ,           ,"['shadha tabatabai', 'ihab mohammed', 'basheer qolomany', 'abdullatif albasser', 'kashif ahmad', 'mohamed abdallah', 'ala al-fuqaha']"
2204.14025 ,data+shift: supporting visual investigation of data distribution shifts   by data scientists                                                                                            ,cs.lg cs.hc                                              ,"machine learning on data streams is increasingly more present in multiple domains. however, there is often data distribution shift that can lead machine learning models to make incorrect decisions. while there are automatic methods to detect when drift is happening, human analysis, often by data scientists, is essential to diagnose the causes of the problem and adjust the system. we propose data+shift, a visual analytics tool to support data scientists in the task of investigating the underlying factors of shift in data features in the context of fraud detection. design requirements were derived from interviews with data scientists. data+shift is integrated with jupyterlab and can be used alongside other data science tools. we validated our approach with a think-aloud experiment where a data scientist used the tool for a fraud detection use case."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2022-04-29 ,           ,"['joão palmeiro', 'beatriz malveiro', 'rita costa', 'david polido', 'ricardo moreira', 'pedro bizarro']"
2204.14046 ,who will stay? using deep learning to predict engagement of citizen   scientists                                                                                                        ,cs.lg cs.hc                                              ,"citizen science and machine learning should be considered for monitoring the coastal and ocean environment due to the scale of threats posed by climate change and the limited resources to fill knowledge gaps. using data from the annotation activity of citizen scientists in a swedish marine project, we constructed deep neural network models to predict forthcoming engagement. we tested the models to identify patterns in annotation engagement. based on the results, it is possible to predict whether an annotator will remain active in future sessions. depending on the goals of individual citizen science projects, it may also be necessary to identify either those volunteers who will leave or those who will continue annotating. this can be predicted by varying the threshold for the prediction. the engagement metrics used to construct the models are based on time and activity and can be used to infer latent characteristics of volunteers and predict their task interest based on their activity patterns. they can estimate if volunteers can accomplish a given number of tasks in a certain amount of time, identify early on who is likely to become a top contributor or identify who is likely to quit and provide them with targeted interventions. the novelty of our predictive models lies in the use of deep neural networks and the sequence of volunteer annotations. a limitation of our models is that they do not use embeddings constructed from user profiles as input data, as many recommender systems do. we expect that including user profiles would improve prediction performance."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,                                                                        ,2022-04-28 ,           ,"['alexander semenov', 'yixin zhang', 'marisa ponti']"
2204.14062 ,multimodal transformer-based model for buchwald-hartwig and   suzuki-miyaura reaction yield prediction                                                                                  ,cs.lg cs.ai                                              ,"predicting the yield percentage of a chemical reaction is useful in many aspects such as reducing wet-lab experimentation by giving the priority to the reactions with a high predicted yield. in this work we investigated the use of multiple type inputs to predict chemical reaction yield. we used simplified molecular-input line-entry system (smiles) as well as calculated chemical descriptors as model inputs. the model consists of a pre-trained bidirectional transformer-based encoder (bert) and a multi-layer perceptron (mlp) with a regression head to predict the yield. we experimented on two high throughput experimentation (hte) datasets for buchwald-hartwig and suzuki-miyaura reactions. the experiments show improvements in the prediction on both datasets compared to systems using only smiles or chemical descriptors as input. we also tested the model's performance on out-of-sample dataset splits of buchwald-hartwig and achieved comparable results with the state-of-the-art. in addition to predicting the yield, we demonstrated the model's ability to suggest the optimum (highest yield) reaction conditions. the model was able to suggest conditions that achieves 94% of the optimum reported yields. this proves the model to be useful in achieving the best results in the wet lab without expensive experimentation."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,                                                                        ,2022-04-27 ,           ,"['shimaa baraka', 'ahmed m. el kerdawy']"
2204.14076 ,dynamic noises of multi-agent environments can improve generalization:   agent-based models meets reinforcement learning                                                                ,cs.ma cs.ai cs.lg                                        ,"we study the benefits of reinforcement learning (rl) environments based on agent-based models (abm). while abms are known to offer microfoundational simulations at the cost of computational complexity, we empirically show in this work that their non-deterministic dynamics can improve the generalization of rl agents. to this end, we examine the control of an epidemic sir environments based on either differential equations or abms. numerical simulations demonstrate that the intrinsic noise in the abm-based dynamics of the sir model not only improve the average reward but also allow the rl agent to generalize on a wider ranges of epidemic parameters."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ,                                                                        ,2022-03-26 ,           ,"['mohamed akrout', 'amal feriani', 'bob mcleod']"
2204.14081 ,few-shot learning for medical text: a systematic review                                                                                                                                 ,cs.cl cs.lg                                              ,"objective: few-shot learning (fsl) methods require small numbers of labeled instances for training. as many medical topics have limited annotated textual data in practical settings, fsl-based natural language processing (nlp) methods hold substantial promise. we aimed to conduct a systematic review to explore the state of fsl methods for medical nlp. materials and methods: we searched for articles published between january 2016 and august 2021 using pubmed/medline, embase, acl anthology, and ieee xplore digital library. to identify the latest relevant methods, we also searched other sources such as preprint servers (eg., medrxiv) via google scholar. we included all articles that involved fsl and any type of medical text. we abstracted articles based on data source(s), aim(s), training set size(s), primary method(s)/approach(es), and evaluation method(s). results: 31 studies met our inclusion criteria-all published after 2018; 22 (71%) since 2020. concept extraction/named entity recognition was the most frequently addressed task (13/31; 42%), followed by text classification (10/31; 32%). twenty-one (68%) studies reconstructed existing datasets to create few-shot scenarios synthetically, and mimic-iii was the most frequently used dataset (7/31; 23%). common methods included fsl with attention mechanisms (12/31; 39%), prototypical networks (8/31; 26%), and meta-learning (6/31; 19%). discussion: despite the potential for fsl in biomedical nlp, progress has been limited compared to domain-independent fsl. this may be due to the paucity of standardized, public datasets, and the relative underperformance of fsl methods on biomedical topics. creation and release of specialized datasets for biomedical fsl may aid method development by enabling comparative analyses."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2022-04-21 ,           ,"['yao ge', 'yuting guo', 'yuan-chi yang', 'mohammed ali al-garadi', 'abeed sarker']"
2204.14096 ,bayesian information criterion for event-based multi-trial ensemble data                                                                                                                ,stat.ml cs.lg q-bio.qm stat.ap                           ,"transient recurring phenomena are ubiquitous in many scientific fields like neuroscience and meteorology. time inhomogenous vector autoregressive models (var) may be used to characterize peri-event system dynamics associated with such phenomena, and can be learned by exploiting multi-dimensional data gathering samples of the evolution of the system in multiple time windows comprising, each associated with one occurrence of the transient phenomenon, that we will call ""trial"". however, optimal var model order selection methods, commonly relying on the akaike or bayesian information criteria (aic/bic), are typically not designed for multi-trial data. here we derive the bic methods for multi-trial ensemble data which are gathered after the detection of the events. we show using simulated bivariate ar models that the multi-trial bic is able to recover the real model order. we also demonstrate with simulated transient events and real data that the multi-trial bic is able to estimate a sufficiently small model order for dynamic system modeling."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ,                                                                        ,2022-04-29 ,           ,"['kaidi shao', 'nikos k. logothetis', 'michel besserve']"
2204.14103 ,reducing neural architecture search spaces with training-free statistics   and computational graph clustering                                                                           ,cs.lg                                                    ,"the computational demands of neural architecture search (nas) algorithms are usually directly proportional to the size of their target search spaces. thus, limiting the search to high-quality subsets can greatly reduce the computational load of nas algorithms. in this paper, we present clustering-based reduction (c-bred), a new technique to reduce the size of nas search spaces. c-bred reduces a nas space by clustering the computational graphs associated with its architectures and selecting the most promising cluster using proxy statistics correlated with network accuracy. when considering the nas-bench-201 (nb201) data set and the cifar-100 task, c-bred selects a subset with 70% average accuracy instead of the whole space's 64% average accuracy."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ,10.1145/3528416.3530873                                                 ,2022-04-29 ,           ,"['thorir mar ingolfsson', 'mark vero', 'xiaying wang', 'lorenzo lamberti', 'luca benini', 'matteo spallanzani']"
2204.14133 ,network topology optimization via deep reinforcement learning                                                                                                                           ,cs.ni cs.ai cs.lg                                        ,"topology impacts important network performance metrics, including link utilization, throughput and latency, and is of central importance to network operators. however, due to the combinatorial nature of network topology, it is extremely difficult to obtain an optimal solution, especially since topology planning in networks also often comes with management-specific constraints. as a result, local optimization with hand-tuned heuristic methods from human experts are often adopted in practice. yet, heuristic methods cannot cover the global topology design space while taking into account constraints, and cannot guarantee to find good solutions.   in this paper, we propose a novel deep reinforcement learning (drl) algorithm, called advantage actor critic-graph searching (a2c-gs), for network topology optimization. a2c-gs consists of three novel components, including a verifier to validate the correctness of a generated network topology, a graph neural network (gnn) to efficiently approximate topology rating, and a drl actor layer to conduct a topology search. a2c-gs can efficiently search over large topology space and output topology with satisfying performance. we conduct a case study based on a real network scenario, and our experimental results demonstrate the superior performance of a2c-gs in terms of both efficiency and performance."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2022-04-19 ,           ,"['zhuoran li', 'xing wang', 'ling pan', 'lin zhu', 'zhendong wang', 'junlan feng', 'chao deng', 'longbo huang']"
2204.14142 ,a framework for constructing machine learning models with feature set   optimisation for evapotranspiration partitioning                                                                ,cs.lg                                                    ,"a deeper understanding of the drivers of evapotranspiration and the modelling of its constituent parts (evaporation and transpiration) could be of significant importance to the monitoring and management of water resources globally over the coming decades. in this work, we developed a framework to identify the best performing machine learning algorithm from a candidate set, select optimal predictive features as well as ranking features in terms of their importance to predictive accuracy. our experiments used 3 separate feature sets across 4 wetland sites as input into 8 candidate machine learning algorithms, providing 96 sets of experimental configurations. given this high number of parameters, our results show strong evidence that there is no singularly optimal machine learning algorithm or feature set across all of the wetland sites studied despite their similarities. a key finding discovered when examining feature importance is that methane flux, a feature whose relationship with evapotranspiration is not generally examined, may contribute to further biophysical process understanding."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ,                                                                        ,2022-04-29 ,           ,"['adam stapleton', 'elke eichelmann', 'mark roantree']"
2204.14180 ,industry-academia research collaboration and knowledge co-creation:   patterns and anti-patterns                                                                                        ,cs.se cs.lg                                              ,"increasing the impact of software engineering research in the software industry and the society at large has long been a concern of high priority for the software engineering community. the problem of two cultures, research conducted in a vacuum (disconnected from the real world), or misaligned time horizons are just some of the many complex challenges standing in the way of successful industry-academia collaborations. this paper reports on the experience of research collaboration and knowledge co-creation between industry and academia in software engineering as a way to bridge the research-practice collaboration gap. our experience spans 14 years of collaboration between researchers in software engineering and the european and norwegian software and it industry. using the participant observation and interview methods we have collected and afterwards analyzed an extensive record of qualitative data. drawing upon the findings made and the experience gained, we provide a set of 14 patterns and 14 anti-patterns for industry-academia collaborations, aimed to support other researchers and practitioners in establishing and running research collaboration projects in software engineering."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ,10.1145/3494519                                                         ,2022-04-29 ,           ,"['dusica marijan', 'sagar sen']"
2204.14187 ,randomized smoothing under attack: how good is it in pratice?                                                                                                                           ,cs.cr cs.ai cs.lg                                        ,"randomized smoothing is a recent and celebrated solution to certify the robustness of any classifier. while it indeed provides a theoretical robustness against adversarial attacks, the dimensionality of current classifiers necessarily imposes monte carlo approaches for its application in practice. this paper questions the effectiveness of randomized smoothing as a defense, against state of the art black-box attacks. this is a novel perspective, as previous research works considered the certification as an unquestionable guarantee. we first formally highlight the mismatch between a theoretical certification and the practice of attacks on classifiers. we then perform attacks on randomized smoothing as a defense. our main observation is that there is a major mismatch in the settings of the rs for obtaining high certified robustness or when defeating black box attacks while preserving the classifier accuracy."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ,                                                                        ,2022-04-28 ,           ,"['thibault maho', 'teddy furon', 'erwan le merrer']"
2204.14192 ,human's role in-the-loop                                                                                                                                                                ,cs.db cs.hc cs.lg                                        ,"data integration has been recently challenged by the need to handle large volumes of data, arriving at high velocity from a variety of sources, which demonstrate varying levels of veracity. this challenging setting, often referred to as big data, renders many of the existing techniques, especially those that are human-intensive, obsolete. big data also produces technological advancements such as internet of things, cloud computing, and deep learning, and accordingly, provides a new, exciting, and challenging research agenda. given the availability of data and the improvement of machine learning techniques, this blog discusses the respective roles of humans and machines in achieving cognitive tasks in matching, aiming to determine whether traditional roles of humans and machines are subject to change. such investigation, we believe, will pave a way to better utilize both human and machine resources in new and innovative manners. we shall discuss two possible modes of change, namely humans out and humans in. humans out aim at exploring out-of-the-box latent matching reasoning using machine learning algorithms when attempting to overpower human matcher performance. pursuing out-of-the-box thinking, machine and deep learning can be involved in matching. humans in explores how to better involve humans in the matching loop by assigning human matchers with a symmetric role to algorithmic matcher in the matching process."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,                                                                        ,2022-04-27 ,           ,"['avigdor gal', 'roee shraga']"
2204.14213 ,modular domain adaptation                                                                                                                                                               ,cs.cl cs.lg                                              ,"off-the-shelf models are widely used by computational social science researchers to measure properties of text, such as sentiment. however, without access to source data it is difficult to account for domain shift, which represents a threat to validity. here, we treat domain adaptation as a modular process that involves separate model producers and model consumers, and show how they can independently cooperate to facilitate more accurate measurements of text. we introduce two lightweight techniques for this scenario, and demonstrate that they reliably increase out-of-domain accuracy on four multi-domain text classification datasets when used with linear and contextual embedding models. we conclude with recommendations for model producers and consumers, and release models and replication code to accompany this paper."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,                                                                        ,2022-04-26 ,           ,"['junshen k. chen', 'dallas card', 'dan jurafsky']"
2205.00007 ,graph learning from multivariate dependent time series via a   multi-attribute formulation                                                                                              ,stat.ml cs.lg eess.sp                                    ,"we consider the problem of inferring the conditional independence graph (cig) of a high-dimensional stationary multivariate gaussian time series. in a time series graph, each component of the vector series is represented by distinct node, and associations between components are represented by edges between the corresponding nodes. we formulate the problem as one of multi-attribute graph estimation for random vectors where a vector is associated with each node of the graph. at each node, the associated random vector consists of a time series component and its delayed copies. we present an alternating direction method of multipliers (admm) solution to minimize a sparse-group lasso penalized negative pseudo log-likelihood objective function to estimate the precision matrix of the random vector associated with the entire multi-attribute graph. the time series cig is then inferred from the estimated precision matrix. a theoretical analysis is provided. numerical results illustrate the proposed approach which outperforms existing frequency-domain approaches in correctly detecting the graph edges."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ,                                                                        ,2022-04-28 ,           ,['jitendra k tugnait']
2205.00029 ,self-aware feedback-based self-learning in large-scale conversational ai                                                                                                                ,cs.cl cs.ai cs.lg                                        ,"self-learning paradigms in large-scale conversational ai agents tend to leverage user feedback in bridging between what they say and what they mean. however, such learning, particularly in markov-based query rewriting systems have far from addressed the impact of these models on future training where successive feedback is inevitably contingent on the rewrite itself, especially in a continually updating environment. in this paper, we explore the consequences of this inherent lack of self-awareness towards impairing the model performance, ultimately resulting in both type i and ii errors over time. to that end, we propose augmenting the markov graph construction with a superposition-based adjacency matrix. here, our method leverages an induced stochasticity to reactively learn a locally-adaptive decision boundary based on the performance of the individual rewrites in a bi-variate beta setting. we also surface a data augmentation strategy that leverages template-based generation in abridging complex conversation hierarchies of dialogs so as to simplify the learning process. all in all, we demonstrate that our self-aware model improves the overall pr-auc by 27.45%, achieves a relative defect reduction of up to 31.22%, and is able to adapt quicker to changes in global preferences across a large number of customers."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,                                                                        ,2022-04-29 ,           ,"['pragaash ponnusamy', 'clint solomon mathialagan', 'gustavo aguilar', 'chengyuan ma', 'chenlei guo']"
2205.00033 ,a human-centric perspective on fairness and transparency in algorithmic   decision-making                                                                                               ,cs.ai cs.hc cs.lg                                        ,"automated decision systems (ads) are increasingly used for consequential decision-making. these systems often rely on sophisticated yet opaque machine learning models, which do not allow for understanding how a given decision was arrived at. this is not only problematic from a legal perspective, but non-transparent systems are also prone to yield unfair outcomes because their sanity is challenging to assess and calibrate in the first place -- which is particularly worrisome for human decision-subjects. based on this observation and building upon existing work, i aim to make the following three main contributions through my doctoral thesis: (a) understand how (potential) decision-subjects perceive algorithmic decisions (with varying degrees of transparency of the underlying ads), as compared to similar decisions made by humans; (b) evaluate different tools for transparent decision-making with respect to their effectiveness in enabling people to appropriately assess the quality and fairness of ads; and (c) develop human-understandable technical artifacts for fair automated decision-making. over the course of the first half of my phd program, i have already addressed substantial pieces of (a) and (c), whereas (b) will be the major focus of the second half."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ,10.1145/3491101.3503811                                                 ,2022-04-29 ,           ,['jakob schoeffer']
2205.00047 ,logically consistent adversarial attacks for soft theorem provers                                                                                                                       ,cs.lg cs.cl cs.cr                                        ,"recent efforts within the ai community have yielded impressive results towards ""soft theorem proving"" over natural language sentences using language models. we propose a novel, generative adversarial framework for probing and improving these models' reasoning capabilities. adversarial attacks in this domain suffer from the logical inconsistency problem, whereby perturbations to the input may alter the label. our logically consistent adversarial attacker, lava, addresses this by combining a structured generative process with a symbolic solver, guaranteeing logical consistency. our framework successfully generates adversarial attacks and identifies global weaknesses common across multiple target models. our analyses reveal naive heuristics and vulnerabilities in these models' reasoning capabilities, exposing an incomplete grasp of logical deduction under logic programs. finally, in addition to effective probing of these models, we show that training on the generated samples improves the target model's performance."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,                                                                        ,2022-04-29 ,           ,"['alexander gaskell', 'yishu miao', 'lucia specia', 'francesca toni']"
2205.00048 ,joint multisided exposure fairness for recommendation                                                                                                                                   ,cs.ir cs.ai cs.lg                                        ,"prior research on exposure fairness in the context of recommender systems has focused mostly on disparities in the exposure of individual or groups of items to individual users of the system. the problem of how individual or groups of items may be systemically under or over exposed to groups of users, or even all users, has received relatively less attention. however, such systemic disparities in information exposure can result in observable social harms, such as withholding economic opportunities from historically marginalized groups (allocative harm) or amplifying gendered and racialized stereotypes (representational harm). previously, diaz et al. developed the expected exposure metric -- that incorporates existing user browsing models that have previously been developed for information retrieval -- to study fairness of content exposure to individual users. we extend their proposed framework to formalize a family of exposure fairness metrics that model the problem jointly from the perspective of both the consumers and producers. specifically, we consider group attributes for both types of stakeholders to identify and mitigate fairness concerns that go beyond individual users and items towards more systemic biases in recommendation. furthermore, we study and discuss the relationships between the different exposure fairness dimensions proposed in this paper, as well as demonstrate how stochastic ranking policies can be optimized towards said fairness goals."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ,                                                                        ,2022-04-29 ,           ,"['haolun wu', 'bhaskar mitra', 'chen ma', 'fernando diaz', 'xue liu']"
2205.00072 ,doubting ai predictions: influence-driven second opinion recommendation                                                                                                                 ,cs.lg cs.cy cs.hc                                        ,"effective human-ai collaboration requires a system design that provides humans with meaningful ways to make sense of and critically evaluate algorithmic recommendations. in this paper, we propose a way to augment human-ai collaboration by building on a common organizational practice: identifying experts who are likely to provide complementary opinions. when machine learning algorithms are trained to predict human-generated assessments, experts' rich multitude of perspectives is frequently lost in monolithic algorithmic recommendations. the proposed approach aims to leverage productive disagreement by (1) identifying whether some experts are likely to disagree with an algorithmic assessment and, if so, (2) recommend an expert to request a second opinion from."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,                                                                        ,2022-04-29 ,           ,"['maria de-arteaga', 'alexandra chouldechova', 'artur dubrawski']"
2205.00084 ,infusing linguistic knowledge of smiles into chemical language models                                                                                                                   ,q-bio.qm cs.ai cs.lg                                     ,"the simplified molecular-input line-entry system (smiles) is the most popular representation of chemical compounds. therefore, many smiles-based molecular property prediction models have been developed. in particular, transformer-based models show promising performance because the model utilizes a massive chemical dataset for self-supervised learning. however, there is no transformer-based model to overcome the inherent limitations of smiles, which result from the generation process of smiles. in this study, we grammatically parsed smiles to obtain connectivity between substructures and their type, which is called the grammatical knowledge of smiles. first, we pretrained the transformers with substructural tokens, which were parsed from smiles. then, we used the training strategy 'same compound model' to better understand smiles grammar. in addition, we injected knowledge of connectivity and type into the transformer with knowledge adapters. as a result, our representation model outperformed previous compound representations for the prediction of molecular properties. finally, we analyzed the attention of the transformer model and adapters, demonstrating that the proposed model understands the grammar of smiles."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ,                                                                        ,2022-04-19 ,           ,"['ingoo lee', 'hojung nam']"
2205.00129 ,gaze-enhanced crossmodal embeddings for emotion recognition                                                                                                                             ,cs.lg cs.cv                                              ,"emotional expressions are inherently multimodal -- integrating facial behavior, speech, and gaze -- but their automatic recognition is often limited to a single modality, e.g. speech during a phone call. while previous work proposed crossmodal emotion embeddings to improve monomodal recognition performance, despite its importance, an explicit representation of gaze was not included. we propose a new approach to emotion recognition that incorporates an explicit representation of gaze in a crossmodal emotion embedding framework. we show that our method outperforms the previous state of the art for both audio-only and video-only emotion classification on the popular one-minute gradual emotion recognition dataset. furthermore, we report extensive ablation experiments and provide detailed insights into the performance of different state-of-the-art gaze representations and integration strategies. our results not only underline the importance of gaze for emotion recognition but also demonstrate a practical and highly effective approach to leveraging gaze information for this task."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,10.1145/3530879                                                         ,2022-04-29 ,           ,"['ahmed abdou', 'ekta sood', 'philipp müller', 'andreas bulling']"
2205.00130 ,exsum: from local explanations to model understanding                                                                                                                                   ,cs.cl cs.lg                                              ,"interpretability methods are developed to understand the working mechanisms of black-box models, which is crucial to their responsible deployment. fulfilling this goal requires both that the explanations generated by these methods are correct and that people can easily and reliably understand them. while the former has been addressed in prior work, the latter is often overlooked, resulting in informal model understanding derived from a handful of local explanations. in this paper, we introduce explanation summary (exsum), a mathematical framework for quantifying model understanding, and propose metrics for its quality assessment. on two domains, exsum highlights various limitations in the current practice, helps develop accurate model understanding, and reveals easily overlooked properties of the model. we also connect understandability to other properties of explanations such as human alignment, robustness, and counterfactual minimality and plausibility."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ,                                                                        ,2022-04-29 ,           ,"['yilun zhou', 'marco tulio ribeiro', 'julie shah']"
2205.00142 ,multimodal representation learning with text and images                                                                                                                                 ,cs.lg cs.cl cs.cv                                        ,"in recent years, multimodal ai has seen an upward trend as researchers are integrating data of different types such as text, images, speech into modelling to get the best results. this project leverages multimodal ai and matrix factorization techniques for representation learning, on text and image data simultaneously, thereby employing the widely used techniques of natural language processing (nlp) and computer vision. the learnt representations are evaluated using downstream classification and regression tasks. the methodology adopted can be extended beyond the scope of this project as it uses auto-encoders for unsupervised representation learning."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,                                                                        ,2022-04-29 ,           ,"['aishwarya jayagopal', 'ankireddy monica aiswarya', 'ankita garg', 'srinivasan kolumam nandakumar']"
2205.00163 ,deep ensemble as a gaussian process approximate posterior                                                                                                                               ,cs.lg                                                    ,"deep ensemble (de) is an effective alternative to bayesian neural networks for uncertainty quantification in deep learning. the uncertainty of de is usually conveyed by the functional inconsistency among the ensemble members, say, the disagreement among their predictions. yet, the functional inconsistency stems from unmanageable randomness and may easily collapse in specific cases. to render the uncertainty of de reliable, we propose a refinement of de where the functional inconsistency is explicitly characterized, and further tuned w.r.t. the training data and certain priori beliefs. specifically, we describe the functional inconsistency with the empirical covariance of the functions dictated by ensemble members, which, along with the mean, define a gaussian process (gp). then, with specific priori uncertainty imposed, we maximize functional evidence lower bound to make the gp specified by de approximate the bayesian posterior. in this way, we relate de to bayesian inference to enjoy reliable bayesian uncertainty. moreover, we provide strategies to make the training efficient. our approach consumes only marginally added training cost than the standard de, but achieves better uncertainty quantification than de and its variants across diverse scenarios."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2022-04-30 ,           ,"['zhijie deng', 'feng zhou', 'jianfei chen', 'guoqiang wu', 'jun zhu']"
2205.00172 ,fedic: federated learning on non-iid and long-tailed data via calibrated   distillation                                                                                                 ,cs.lg                                                    ,"federated learning provides a privacy guarantee for generating good deep learning models on distributed clients with different kinds of data. nevertheless, dealing with non-iid data is one of the most challenging problems for federated learning. researchers have proposed a variety of methods to eliminate the negative influence of non-iidness. however, they only focus on the non-iid data provided that the universal class distribution is balanced. in many real-world applications, the universal class distribution is long-tailed, which causes the model seriously biased. therefore, this paper studies the joint problem of non-iid and long-tailed data in federated learning and proposes a corresponding solution called federated ensemble distillation with imbalance calibration (fedic). to deal with non-iid data, fedic uses model ensemble to take advantage of the diversity of models trained on non-iid data. then, a new distillation method with logit adjustment and calibration gating network is proposed to solve the long-tail problem effectively. we evaluate fedic on cifar-10-lt, cifar-100-lt, and imagenet-lt with a highly non-iid experimental setting, in comparison with the state-of-the-art methods of federated learning and long-tail learning. our code is available at https://github.com/shangxinyi/fedic."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ,                                                                        ,2022-04-30 ,           ,"['xinyi shang', 'yang lu', 'yiu-ming cheung', 'hanzi wang']"
2205.00210 ,software testing for machine learning                                                                                                                                                   ,cs.se cs.ai cs.lg                                        ,"machine learning has become prevalent across a wide variety of applications. unfortunately, machine learning has also shown to be susceptible to deception, leading to errors, and even fatal failures. this circumstance calls into question the widespread use of machine learning, especially in safety-critical applications, unless we are able to assure its correctness and trustworthiness properties. software verification and testing are established technique for assuring such properties, for example by detecting errors. however, software testing challenges for machine learning are vast and profuse - yet critical to address. this summary talk discusses the current state-of-the-art of software testing for machine learning. more specifically, it discusses six key challenge areas for software testing of machine learning systems, examines current approaches to these challenges and highlights their limitations. the paper provides a research agenda with elaborated directions for making progress toward advancing the state-of-the-art on testing of machine learning."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,10.1609/aaai.v34i09.7084                                                ,2022-04-30 ,           ,"['dusica marijan', 'arnaud gotlieb']"
2205.00254 ,pgd: a large-scale professional go dataset for data-driven analytics                                                                                                                    ,cs.ai cs.lg                                              ,"lee sedol is on a winning streak--does this legend rise again after the competition with alphago? ke jie is invincible in the world championship--can he still win the title this time? go is one of the most popular board games in east asia, with a stable professional sports system that has lasted for decades in china, japan, and korea. there are mature data-driven analysis technologies for many sports, such as soccer, basketball, and esports. however, developing such technology for go remains nontrivial and challenging due to the lack of datasets, meta-information, and in-game statistics. this paper creates the professional go dataset (pgd), containing 98,043 games played by 2,148 professional players from 1950 to 2021. after manual cleaning and labeling, we provide detailed meta-information for each player, game, and tournament. moreover, the dataset includes analysis results for each move in the match evaluated by advanced alphazero-based ai. to establish a benchmark for pgd, we further analyze the data and extract meaningful in-game features based on prior knowledge related to go that can indicate the game status. with the help of complete meta-information and constructed in-game features, our results prediction system achieves an accuracy of 75.30%, much higher than several state-of-the-art approaches (64%-65%). as far as we know, pgd is the first dataset for data-driven analytics in go and even in board games. beyond this promising result, we provide more examples of tasks that benefit from our dataset. the ultimate goal of this paper is to bridge this ancient game and the modern data science community. it will advance research on go-related analytics to enhance the fan experience, help players improve their ability, and facilitate other promising aspects. the dataset will be made publicly available."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,                                                                        ,2022-04-30 ,           ,['yifan gao']
2205.00263 ,complete verification via multi-neuron relaxation guided   branch-and-bound                                                                                                             ,cs.lg cs.se                                              ,"state-of-the-art neural network verifiers are fundamentally based on one of two paradigms: either encoding the whole verification problem via tight multi-neuron convex relaxations or applying a branch-and-bound (bab) procedure leveraging imprecise but fast bounding methods on a large number of easier subproblems. the former can capture complex multi-neuron dependencies but sacrifices completeness due to the inherent limitations of convex relaxations. the latter enables complete verification but becomes increasingly ineffective on larger and more challenging networks. in this work, we present a novel complete verifier which combines the strengths of both paradigms: it leverages multi-neuron relaxations to drastically reduce the number of subproblems generated during the bab process and an efficient gpu-based dual optimizer to solve the remaining ones. an extensive evaluation demonstrates that our verifier achieves a new state-of-the-art on both established benchmarks as well as networks with significantly higher accuracy than previously considered. the latter result (up to 28% certification gains) indicates meaningful progress towards creating verifiers that can handle practically relevant networks."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,                                                                        ,2022-04-30 ,           ,"['claudio ferrari', 'mark niklas muller', 'nikola jovanovic', 'martin vechev']"
2205.00283 ,leveraging emotion-specific features to improve transformer performance   for emotion classification                                                                                    ,cs.cl cs.ai cs.lg                                        ,"this paper describes the approach to the emotion classification shared task held at wassa 2022 by team pvgs ai club. this track 2 sub-task focuses on building models which can predict a multi-class emotion label based on essays from news articles where a person, group or another entity is affected. baseline transformer models have been demonstrating good results on sequence classification tasks, and we aim to improve this performance with the help of ensembling techniques, and by leveraging two variations of emotion-specific representations. we observe better results than our baseline models and achieve an accuracy of 0.619 and a macro f1 score of 0.520 on the emotion classification task."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ,                                                                        ,2022-04-30 ,           ,"['shaily desai', 'atharva kshirsagar', 'aditi sidnerlikar', 'nikhil khodake', 'manisha marathe']"
2205.00302 ,shape: an unified approach to evaluate the contribution and cooperation   of individual modalities                                                                                      ,cs.lg                                                    ,"as deep learning advances, there is an ever-growing demand for models capable of synthesizing information from multi-modal resources to address the complex tasks raised from real-life applications. recently, many large multi-modal datasets have been collected, on which researchers actively explore different methods of fusing multi-modal information. however, little attention has been paid to quantifying the contribution of different modalities within the proposed models. in this paper, we propose the {\bf sh}apley v{\bf a}lue-based {\bf pe}rceptual (shape) scores that measure the marginal contribution of individual modalities and the degree of cooperation across modalities. using these scores, we systematically evaluate different fusion methods on different multi-modal datasets for different tasks. our experiments suggest that for some tasks where different modalities are complementary, the multi-modal models still tend to use the dominant modality alone and ignore the cooperation across modalities. on the other hand, models learn to exploit cross-modal cooperation when different modalities are indispensable for the task. in this case, the scores indicate it is better to fuse different modalities at relatively early stages. we hope our scores can help improve the understanding of how the present multi-modal models operate on different modalities and encourage more sophisticated methods of integrating multiple modalities."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,                                                                        ,2022-04-30 ,           ,"['pengbo hu', 'xingyu li', 'yi zhou']"
2205.00313 ,fairsr: fairness-aware sequential recommendation through multi-task   learning with preference graph embeddings                                                                         ,cs.ir cs.lg cs.si                                        ,"sequential recommendation (sr) learns from the temporal dynamics of user-item interactions to predict the next ones. fairness-aware recommendation mitigates a variety of algorithmic biases in the learning of user preferences. this paper aims at bringing a marriage between sr and algorithmic fairness. we propose a novel fairness-aware sequential recommendation task, in which a new metric, interaction fairness, is defined to estimate how recommended items are fairly interacted by users with different protected attribute groups. we propose a multi-task learning based deep end-to-end model, fairsr, which consists of two parts. one is to learn and distill personalized sequential features from the given user and her item sequence for sr. the other is fairness-aware preference graph embedding (fpge). the aim of fpge is two-fold: incorporating the knowledge of users' and items' attributes and their correlation into entity representations, and alleviating the unfair distributions of user attributes on items. extensive experiments conducted on three datasets show fairsr can outperform state-of-the-art sr models in recommendation performance. in addition, the recommended items by fairsr also exhibit promising interaction fairness."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,10.1145/3495163                                                         ,2022-04-30 ,           ,"['cheng-te li', 'cheng hsu', 'yang zhang']"
2205.00354 ,graph anisotropic diffusion                                                                                                                                                             ,cs.lg                                                    ,"traditional graph neural networks (gnns) rely on message passing, which amounts to permutation-invariant local aggregation of neighbour features. such a process is isotropic and there is no notion of `direction' on the graph. we present a new gnn architecture called graph anisotropic diffusion. our model alternates between linear diffusion, for which a closed-form solution is available, and local anisotropic filters to obtain efficient multi-hop anisotropic kernels. we test our model on two common molecular property prediction benchmarks (zinc and qm9) and show its competitive performance."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,                                                                        ,2022-04-30 ,           ,"['ahmed a. a. elhag', 'gabriele corso', 'hannes stärk', 'michael m. bronstein']"
2205.00361 ,combined learning of neural network weights for privacy in collaborative   tasks                                                                                                        ,cs.lg cs.ai cs.cr                                        ,"we introduce coln, combined learning of neural network weights, a novel method to securely combine machine learning models over sensitive data with no sharing of data. with coln, local hosts use the same neural network architecture and base parameters to train a model using only locally available data. locally trained models are then submitted to a combining agent, which produces a combined model. the new model's parameters can be sent back to hosts, and can then be used as initial parameters for a new training iteration. coln is capable of combining several distributed neural networks of the same kind but is not restricted to any single neural architecture. in this paper we detail the combination algorithm and present experiments with feed-forward, convolutional, and recurrent neural network architectures, showing that the coln combined model approximates the performance of a hypothetical ideal centralized model, trained using the combination of the local datasets. coln can contribute to secure collaborative research, as required in the medical area, where privacy issues preclude data sharing, but where the limitations of local data demand information derived from larger datasets."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,                                                                        ,2022-04-30 ,           ,"['aline r. ioste', 'alan m. durham', 'marcelo finger']"
2205.00377 ,detecting covid-19 conspiracy theories with transformers and tf-idf                                                                                                                     ,cs.cl cs.lg                                              ,"the sharing of fake news and conspiracy theories on social media has wide-spread negative effects. by designing and applying different machine learning models, researchers have made progress in detecting fake news from text. however, existing research places a heavy emphasis on general, common-sense fake news, while in reality fake news often involves rapidly changing topics and domain-specific vocabulary. in this paper, we present our methods and results for three fake news detection tasks at mediaeval benchmark 2021 that specifically involve covid-19 related topics. we experiment with a group of text-based models including support vector machines, random forest, bert, and roberta. we find that a pre-trained transformer yields the best validation results, but a randomly initialized transformer with smart design can also be trained to reach accuracies close to that of the pre-trained transformer."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ,                                                                        ,2022-04-30 ,           ,"['haoming guo', 'tianyi huang', 'huixuan huang', 'mingyue fan', 'gerald friedland']"
2205.00388 ,abnormal-aware multi-person evaluation system with improved fuzzy   weighting                                                                                                           ,cs.cy cs.lg stat.ap                                      ,"there exists a phenomenon that subjectivity highly lies in the daily evaluation process. our research primarily concentrates on a multi-person evaluation system with anomaly detection to minimize the possible inaccuracy that subjective assessment brings. we choose the two-stage screening method, which consists of rough screening and score-weighted kendall-$\tau$ distance to winnow out abnormal data, coupled with hypothesis testing to narrow global discrepancy. then we use fuzzy synthetic evaluation method(fse) to determine the significance of scores given by reviewers as well as their reliability, culminating in a more impartial weight for each reviewer in the final conclusion. the results demonstrate a clear and comprehensive ranking instead of unilateral scores, and we get to have an efficiency in filtering out abnormal data as well as a reasonably objective weight determination mechanism. we can sense that through our study, people will have a chance of modifying a multi-person evaluation system to attain both equity and a relatively superior competitive atmosphere."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ,                                                                        ,2022-04-30 ,           ,['shutong ni']
2205.00427 ,tinylight: adaptive traffic signal control on devices with extremely   limited resources                                                                                                ,cs.lg cs.ai                                              ,"recent advances in deep reinforcement learning (drl) have largely promoted the performance of adaptive traffic signal control (atsc). nevertheless, regarding the implementation, most works are cumbersome in terms of storage and computation. this hinders their deployment on scenarios where resources are limited. in this work, we propose tinylight, the first drl-based atsc model that is designed for devices with extremely limited resources. tinylight first constructs a super-graph to associate a rich set of candidate features with a group of light-weighted network blocks. then, to diminish the model's resource consumption, we ablate edges in the super-graph automatically with a novel entropy-minimized objective function. this enables tinylight to work on a standalone microcontroller with merely 2kb ram and 32kb rom. we evaluate tinylight on multiple road networks with real-world traffic demands. experiments show that even with extremely limited resources, tinylight still achieves competitive performance. the source code and appendix of this work can be found at \url{https://bit.ly/38hh8t8}."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,                                                                        ,2022-05-01 ,           ,"['dong xing', 'qian zheng', 'qianhui liu', 'gang pan']"
2205.00449 ,molecular identification from afm images using the iupac nomenclature   and attribute multimodal recurrent neural networks                                                              ,cond-mat.mtrl-sci cond-mat.dis-nn cs.lg                  ,"despite being the main tool to visualize molecules at the atomic scale, afm with co-functionalized metal tips is unable to chemically identify the observed molecules. here we present a strategy to address this challenging task using deep learning techniques. instead of identifying a finite number of molecules following a traditional classification approach, we define the molecular identification as an image captioning problem. we design an architecture, composed of two multimodal recurrent neural networks, capable of identifying the structure and composition of an unknown molecule using a 3d-afm image stack as input. the neural network is trained to provide the name of each molecule according to the iupac nomenclature rules. to train and test this algorithm we use the novel quam-afm dataset, which contains almost 700,000 molecules and 165 million afm images. the accuracy of the predictions is remarkable, achieving a high score quantified by the cumulative bleu 4-gram, a common metric in language recognition studies."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,                                                                        ,2022-05-01 ,           ,"['jaime carracedo-cosme', 'carlos romero-muñiz', 'pablo pou', 'rubén pérez']"
2205.00456 ,an analysis of the features considerable for nft recommendations                                                                                                                        ,cs.ir cs.cy cs.hc cs.lg                                  ,"this research explores the methods that nfts can be recommended to people who interact with nft-marketplaces to explore nfts of preference and similarity to what they have been searching for. while exploring past methods that can be adopted for recommendations, the use of nft traits for recommendations has been explored. the outcome of the research highlights the necessity of using multiple recommender systems to present the user with the best possible nfts when interacting with decentralized systems."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2022-05-01 ,           ,"['dinuka piyadigama', 'guhanathan poravi']"
2205.00476 ,none class ranking loss for document-level relation extraction                                                                                                                          ,cs.cl cs.lg                                              ,"document-level relation extraction (re) aims at extracting relations among entities expressed across multiple sentences, which can be viewed as a multi-label classification problem. in a typical document, most entity pairs do not express any pre-defined relation and are labeled as ""none"" or ""no relation"". for good document-level re performance, it is crucial to distinguish such none class instances (entity pairs) from those of pre-defined classes (relations). however, most existing methods only estimate the probability of pre-defined relations independently without considering the probability of ""no relation"". this ignores the context of entity pairs and the label correlations between the none class and pre-defined classes, leading to sub-optimal predictions. to address this problem, we propose a new multi-label loss that encourages large margins of label confidence scores between each pre-defined class and the none class, which enables captured label correlations and context-dependent thresholding for label prediction. to gain further robustness against positive-negative imbalance and mislabeled data that could appear in real-world re datasets, we propose a margin regularization and a margin shifting technique. experimental results demonstrate that our method significantly outperforms existing multi-label losses for document-level re and works well in other multi-label tasks such as emotion classification when none class instances are available for training."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,                                                                        ,2022-05-01 ,2022-05-03 ,"['yang zhou', 'wee sun lee']"
2205.00484 ,dynamic programming in rank space: scaling structured inference with   low-rank hmms and pcfgs                                                                                          ,cs.cl cs.lg                                              ,"hidden markov models (hmms) and probabilistic context-free grammars (pcfgs) are widely used structured models, both of which can be represented as factor graph grammars (fggs), a powerful formalism capable of describing a wide range of models. recent research found it beneficial to use large state spaces for hmms and pcfgs. however, inference with large state spaces is computationally demanding, especially for pcfgs. to tackle this challenge, we leverage tensor rank decomposition (aka.\ cpd) to decrease inference computational complexities for a subset of fggs subsuming hmms and pcfgs. we apply cpd on the factors of an fgg and then construct a new fgg defined in the rank space. inference with the new fgg produces the same result but has a lower time complexity when the rank size is smaller than the state size. we conduct experiments on hmm language modeling and unsupervised pcfg parsing, showing better performance than previous work. our code is publicly available at \url{https://github.com/vpeterv/rankspace-models}."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2022-05-01 ,           ,"['songlin yang', 'wei liu', 'kewei tu']"
2205.00501 ,is your toxicity my toxicity? exploring the impact of rater identity on   toxicity annotation                                                                                           ,cs.hc cs.ai cs.cl cs.lg                                  ,"machine learning models are commonly used to detect toxicity in online conversations. these models are trained on datasets annotated by human raters. we explore how raters' self-described identities impact how they annotate toxicity in online comments. we first define the concept of specialized rater pools: rater pools formed based on raters' self-described identities, rather than at random. we formed three such rater pools for this study--specialized rater pools of raters from the u.s. who identify as african american, lgbtq, and those who identify as neither. each of these rater pools annotated the same set of comments, which contains many references to these identity groups. we found that rater identity is a statistically significant factor in how raters will annotate toxicity for identity-related annotations. using preliminary content analysis, we examined the comments with the most disagreement between rater pools and found nuanced differences in the toxicity annotations. next, we trained models on the annotations from each of the different rater pools, and compared the scores of these models on comments from several test sets. finally, we discuss how using raters that self-identify with the subjects of comments can create more inclusive machine learning models, and provide more nuanced ratings than those by random raters."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,                                                                        ,2022-05-01 ,           ,"['nitesh goyal', 'ian kivlichan', 'rachel rosen', 'lucy vasserman']"
2205.00506 ,preserve pre-trained knowledge: transfer learning with self-distillation   for action recognition                                                                                       ,cs.cv cs.lg                                              ,"video-based action recognition is one of the most popular topics in computer vision. with recent advances of selfsupervised video representation learning approaches, action recognition usually follows a two-stage training framework, i.e., self-supervised pre-training on large-scale unlabeled sets and transfer learning on a downstream labeled set. however, catastrophic forgetting of the pre-trained knowledge becomes the main issue in the downstream transfer learning of action recognition, resulting in a sub-optimal solution. in this paper, to alleviate the above issue, we propose a novel transfer learning approach that combines self-distillation in fine-tuning to preserve knowledge from the pre-trained model learned from the large-scale dataset. specifically, we fix the encoder from the last epoch as the teacher model to guide the training of the encoder from the current epoch in the transfer learning. with such a simple yet effective learning strategy, we outperform state-of-the-art methods on widely used ucf101 and hmdb51 datasets in action recognition task."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ,                                                                        ,2022-05-01 ,           ,"['yang zhou', 'zhanhao he', 'keyu lu', 'guanhong wang', 'gaoang wang']"
2205.00517 ,accurate non-stationary short-term traffic flow prediction method                                                                                                                       ,cs.lg cs.ro                                              ,"precise and timely traffic flow prediction plays a critical role in developing intelligent transportation systems and has attracted considerable attention in recent decades. despite the significant progress in this area brought by deep learning, challenges remain. traffic flows usually change dramatically in a short period, which prevents the current methods from accurately capturing the future trend and likely causes the over-fitting problem, leading to unsatisfied accuracy. to this end, this paper proposes a long short-term memory (lstm) based method that can forecast the short-term traffic flow precisely and avoid local optimum problems during training. specifically, instead of using the non-stationary raw traffic data directly, we first decompose them into sub-components, where each one is less noisy than the original input. afterward, sample entropy (se) is employed to merge similar components to reduce the computation cost. the merged features are fed into the lstm, and we then introduce a spatiotemporal module to consider the neighboring relationships in the recombined signals to avoid strong autocorrelation. during training, we utilize the grey wolf algorithm (gwo) to optimize the parameters of lstm, which overcome the overfitting issue. we conduct the experiments on a uk public highway traffic flow dataset, and the results show that the proposed method performs favorably against other state-of-the-art methods with better adaption performance on extreme outliers, delay effects, and trend-changing responses."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,                                                                        ,2022-05-01 ,           ,['wenzheng zhao']
2205.00525 ,deep vs. shallow learning: a benchmark study in low magnitude earthquake   detection                                                                                                    ,cs.lg cs.cv physics.geo-ph                               ,"while deep learning models have seen recent high uptake in the geosciences, and are appealing in their ability to learn from minimally processed input data, as black box models they do not provide an easy means to understand how a decision is reached, which in safety-critical tasks especially can be problematical. an alternative route is to use simpler, more transparent white box models, in which task-specific feature construction replaces the more opaque feature discovery process performed automatically within deep learning models. using data from the groningen gas field in the netherlands, we build on an existing logistic regression model by the addition of four further features discovered using elastic net driven data mining within the catch22 time series analysis package. we then evaluate the performance of the augmented logistic regression model relative to a deep (cnn) model, pre-trained on the groningen data, on progressively increasing noise-to-signal ratios. we discover that, for each ratio, our logistic regression model correctly detects every earthquake, while the deep model fails to detect nearly 20 % of seismic events, thus justifying at least a degree of caution in the application of deep models, especially to data with higher noise-to-signal ratios."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,                                                                        ,2022-05-01 ,           ,"['akshat goel', 'denise gorse']"
2205.00534 ,generalized reference kernel for one-class classification                                                                                                                               ,cs.lg                                                    ,"in this paper, we formulate a new generalized reference kernel hoping to improve the original base kernel using a set of reference vectors. depending on the selected reference vectors, our formulation shows similarities to approximate kernels, random mappings, and non-linear projection trick. focusing on small-scale one-class classification, our analysis and experimental results show that the new formulation provides approaches to regularize, adjust the rank, and incorporate additional information into the kernel itself, leading to improved one-class classification accuracy."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,                                                                        ,2022-05-01 ,2022-05-04 ,"['jenni raitoharju', 'alexandros iosifidis']"
2205.00538 ,can information behaviour inform machine learning?                                                                                                                                      ,cs.lg cs.hc                                              ,"the objective of this paper is to explore the opportunities for human information behaviour research to inform and influence the field of machine learning and the resulting machine information behaviour. using the development of foundation models in machine learning as an example, the paper illustrates how human information behaviour research can bring to machine learning a more nuanced view of information and informing, a better understanding of information need and how that affects the communication among people and systems, guidance on the nature of context and how to operationalize that in models and systems, and insights into bias, misinformation, and marginalization. despite their clear differences, the fields of information behaviour and machine learning share many common objectives, paradigms, and key research questions. the example of foundation models illustrates that human information behaviour research has much to offer in addressing some of the challenges emerging in the nascent area of machine information behaviour."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,                                                                        ,2022-05-01 ,           ,['michael ridley']
2205.00550 ,federated semi-supervised classification of multimedia flows for 3d   networks                                                                                                          ,cs.lg cs.ni                                              ,"automatic traffic classification is increasingly becoming important in traffic engineering, as the current trend of encrypting transport information (e.g., behind http-encrypted tunnels) prevents intermediate nodes from accessing end-to-end packet headers. however, this information is crucial for traffic shaping, network slicing, and quality of service (qos) management, for preventing network intrusion, and for anomaly detection. 3d networks offer multiple routes that can guarantee different levels of qos. therefore, service classification and separation are essential to guarantee the required qos level to each traffic sub-flow through the appropriate network trunk. in this paper, a federated feature selection and feature reduction learning scheme is proposed to classify network traffic in a semi-supervised cooperative manner. the federated gateways of 3d network help to enhance the global knowledge of network traffic to improve the accuracy of anomaly and intrusion detection and service identification of a new traffic flow."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,                                                                        ,2022-05-01 ,           ,"['saira bano', 'achilles machumilane', 'lorenzo valerio', 'pietro cassarà', 'alberto gotta']"
2205.00581 ,using a novel fractional-order gradient method for cnn back-propagation                                                                                                                 ,cs.cv cs.lg eess.iv                                      ,"computer-aided diagnosis tools have experienced rapid growth and development in recent years. among all, deep learning is the most sophisticated and popular tool. in this paper, researchers propose a novel deep learning model and apply it to covid-19 diagnosis. our model uses the tool of fractional calculus, which has the potential to improve the performance of gradient methods. to this end, the researcher proposes a fractional-order gradient method for the back-propagation of convolutional neural networks based on the caputo definition. however, if only the first term of the infinite series of the caputo definition is used to approximate the fractional-order derivative, the length of the memory is truncated. therefore, the fractional-order gradient (fgd) method with a fixed memory step and an adjustable number of terms is used to update the weights of the layers. experiments were performed on the covidx dataset to demonstrate fast convergence, good accuracy, and the ability to bypass the local optimal point. we also compared the performance of the developed fractional-order neural networks and integer-order neural networks. the results confirmed the effectiveness of our proposed model in the diagnosis of covid-19."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,                                                                        ,2022-05-01 ,           ,"['mundher mohammed taresh', 'ningbo zhu', 'talal ahmed ali ali', 'mohammed alghaili', 'weihua guo']"
2205.00618 ,loopstack: a lightweight tensor algebra compiler stack                                                                                                                                  ,cs.lg cs.pf cs.sc                                        ,"we present loopstack, a domain specific compiler stack for tensor operations, composed of a frontend, looptool, and an efficient optimizing code generator, loopnest. this stack enables us to compile entire neural networks and generate code targeting the avx2, avx512, neon, and neonfp16 instruction sets while incorporating optimizations often missing from other machine learning compiler backends. we evaluate our stack on a collection of full neural networks and commonly used network blocks as well as individual operators, and show that loopstack generates machine code that matches and frequently exceeds the performance of in state-of-the-art machine learning frameworks in both cases. we also show that for a large collection of schedules loopnest's compilation is orders of magnitude faster than llvm, while resulting in equal or improved run time performance. additionally, loopstack has a very small memory footprint - a binary size of 245kb, and under 30k lines of effective code makes it ideal for use on mobile and embedded devices."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,                                                                        ,2022-05-01 ,           ,"['bram wasti', 'josé pablo cambronero', 'benoit steiner', 'hugh leather', 'aleksandar zlateski']"
2205.00662 ,skeptical binary inferences in multi-label problems with sets of   probabilities                                                                                                        ,stat.ml cs.ai cs.lg math.co                              ,"in this paper, we consider the problem of making distributionally robust, skeptical inferences for the multi-label problem, or more generally for boolean vectors. by distributionally robust, we mean that we consider a set of possible probability distributions, and by skeptical we understand that we consider as valid only those inferences that are true for every distribution within this set. such inferences will provide partial predictions whenever the considered set is sufficiently big. we study in particular the hamming loss case, a common loss function in multi-label problems, showing how skeptical inferences can be made in this setting. our experimental results are organised in three sections; (1) the first one indicates the gain computational obtained from our theoretical results by using synthetical data sets, (2) the second one indicates that our approaches produce relevant cautiousness on those hard-to-predict instances where its precise counterpart fails, and (3) the last one demonstrates experimentally how our approach copes with imperfect information (generated by a downsampling procedure) better than the partial abstention [31] and the rejection rules."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ,                                                                        ,2022-05-02 ,           ,"['yonatan carlos carranza alarcón', 'sébastien destercke']"
2205.00694 ,a multi-stage deep architecture for summary generation of soccer videos                                                                                                                 ,cs.cv cs.ai cs.lg cs.mm                                  ,"video content is present in an ever-increasing number of fields, both scientific and commercial. sports, particularly soccer, is one of the industries that has invested the most in the field of video analytics, due to the massive popularity of the game and the emergence of new markets. previous state-of-the-art methods on soccer matches video summarization rely on handcrafted heuristics to generate summaries which are poorly generalizable, but these works have yet proven that multiple modalities help detect the best actions of the game. on the other hand, machine learning models with higher generalization potential have entered the field of summarization of general-purpose videos, offering several deep learning approaches. however, most of them exploit content specificities that are not appropriate for sport whole-match videos. although video content has been for many years the main source for automatizing knowledge extraction in soccer, the data that records all the events happening on the field has become lately very important in sports analytics, since this event data provides richer context information and requires less processing. we propose a method to generate the summary of a soccer match exploiting both the audio and the event metadata. the results show that our method can detect the actions of the match, identify which of these actions should belong to the summary and then propose multiple candidate summaries which are similar enough but with relevant variability to provide different options to the final editor. furthermore, we show the generalization capability of our work since it can transfer knowledge between datasets from different broadcasting companies, different competitions, acquired in different conditions, and corresponding to summaries of different lengths"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,                                                                        ,2022-05-02 ,           ,"['melissa sanabria', 'frédéric precioso', 'pierre-alexandre mattei', 'thomas menguy']"
2205.00698 ,unsupervised denoising of optical coherence tomography images with   dual_merged cyclewgan                                                                                              ,eess.iv cs.cv cs.lg                                      ,"nosie is an important cause of low quality optical coherence tomography (oct) image. the neural network model based on convolutional neural networks(cnns) has demonstrated its excellent performance in image denoising. however, oct image denoising still faces great challenges because many previous neural network algorithms required a large number of labeled data, which might cost much time or is expensive. besides, these cnn-based algorithms need numerous parameters and good tuning techniques, which is hardware resources consuming. to solved above problems, we proposed a new cycle-consistent generative adversarial nets called dual-merged cycle-wgan for retinal oct image denoiseing, which has remarkable performance with less unlabeled traning data. our model consists of two cycle-gan networks with imporved generator, descriminator and wasserstein loss to achieve good training stability and better performance. using image merge technique between two cycle-gan networks, our model could obtain more detailed information and hence better training effect. the effectiveness and generality of our proposed network has been proved via ablation experiments and comparative experiments. compared with other state-of-the-art methods, our unsupervised method obtains best subjective visual effect and higher evaluation objective indicators."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,                                                                        ,2022-05-02 ,           ,"['jie du', 'xujian yang', 'kecheng jin', 'xuanzheng qi', 'hu chen']"
2205.00706 ,feddkd: federated learning with decentralized knowledge distillation                                                                                                                    ,cs.lg cs.ai cs.cv                                        ,"the performance of federated learning in neural networks is generally influenced by the heterogeneity of the data distribution. for a well-performing global model, taking a weighted average of the local models, as done by most existing federated learning algorithms, may not guarantee consistency with local models in the space of neural network maps. in this paper, we propose a novel framework of federated learning equipped with the process of decentralized knowledge distillation (feddkd) (i.e., without data on the server). the feddkd introduces a module of decentralized knowledge distillation (dkd) to distill the knowledge of the local models to train the global model by approaching the neural network map average based on the metric of divergence defined in the loss function, other than only averaging parameters as done in literature. numeric experiments on various heterogeneous datasets reveal that feddkd outperforms the state-of-the-art methods with more efficient communication and training in a few dkd steps, especially on some extremely heterogeneous datasets."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2022-05-02 ,           ,"['xinjia li', 'boyu chen', 'wenlian lu']"
2205.00741 ,smoothed online convex optimization based on discounted-normal-predictor                                                                                                                ,cs.lg math.oc                                            ,"in this paper, we investigate an online prediction strategy named as discounted-normal-predictor (kapralov and panigrahy, 2010) for smoothed online convex optimization (soco), in which the learner needs to minimize not only the hitting cost but also the switching cost. in the setting of learning with expert advice, daniely and mansour (2019) demonstrate that discounted-normal-predictor can be utilized to yield nearly optimal regret bounds over any interval, even in the presence of switching costs. inspired by their results, we develop a simple algorithm for soco: combining online gradient descent (ogd) with different step sizes sequentially by discounted-normal-predictor. despite its simplicity, we prove that it is able to minimize the adaptive regret with switching cost, i.e., attaining nearly optimal regret with switching cost on every interval. by exploiting the theoretical guarantee of ogd for dynamic regret, we further show that the proposed algorithm can minimize the dynamic regret with switching cost in every interval."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,                                                                        ,2022-05-02 ,           ,"['lijun zhang', 'wei jiang', 'jinfeng yi', 'tianbao yang']"
2205.00763 ,data-driven emotional body language generation for social robotics                                                                                                                      ,cs.ro cs.ai cs.hc cs.lg                                  ,"in social robotics, endowing humanoid robots with the ability to generate bodily expressions of affect can improve human-robot interaction and collaboration, since humans attribute, and perhaps subconsciously anticipate, such traces to perceive an agent as engaging, trustworthy, and socially present. robotic emotional body language needs to be believable, nuanced and relevant to the context. we implemented a deep learning data-driven framework that learns from a few hand-designed robotic bodily expressions and can generate numerous new ones of similar believability and lifelikeness. the framework uses the conditional variational autoencoder model and a sampling approach based on the geometric properties of the model's latent space to condition the generative process on targeted levels of valence and arousal. the evaluation study found that the anthropomorphism and animacy of the generated expressions are not perceived differently from the hand-designed ones, and the emotional conditioning was adequately differentiable between most levels except the pairs of neutral-positive valence and low-medium arousal. furthermore, an exploratory analysis of the results reveals a possible impact of the conditioning on the perceived dominance of the robot, as well as on the participants' attention."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2022-05-02 ,           ,"['mina marmpena', 'fernando garcia', 'angelica lim', 'nikolas hemion', 'thomas wennekers']"
2205.00777 ,bsra: block-based super resolution accelerator with hardware efficient   pixel attention                                                                                                ,cs.ar cs.cv cs.lg eess.iv                                ,"increasingly, convolution neural network (cnn) based super resolution models have been proposed for better reconstruction results, but their large model size and complicated structure inhibit their real-time hardware implementation. current hardware designs are limited to a plain network and suffer from lower quality and high memory bandwidth requirements. this paper proposes a super resolution hardware accelerator with hardware efficient pixel attention that just needs 25.9k parameters and simple structure but achieves 0.38db better reconstruction images than the widely used fsrcnn. the accelerator adopts full model block wise convolution for full model layer fusion to reduce external memory access to model input and output only. in addition, cnn and pixel attention are well supported by pe arrays with distributed weights. the final implementation can support full hd image reconstruction at 30 frames per second with tsmc 40nm cmos process."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2022-05-02 ,           ,"['dun-hao yang', 'tian-sheuan chang']"
2205.00778 ,sparse compressed spiking neural network accelerator for object   detection                                                                                                             ,cs.ar cs.cv cs.lg cs.ne                                  ,"spiking neural networks (snns), which are inspired by the human brain, have recently gained popularity due to their relatively simple and low-power hardware for transmitting binary spikes and highly sparse activation maps. however, because snns contain extra time dimension information, the snn accelerator will require more buffers and take longer to infer, especially for the more difficult high-resolution object detection task. as a result, this paper proposes a sparse compressed spiking neural network accelerator that takes advantage of the high sparsity of activation maps and weights by utilizing the proposed gated one-to-all product for low power and highly parallel model execution. the experimental result of the neural network shows 71.5$\%$ map with mixed (1,3) time steps on the ivs 3cls dataset. the accelerator with the tsmc 28nm cmos process can achieve 1024$\times$576@29 frames per second processing when running at 500mhz with 35.88tops/w energy efficiency and 1.05mj energy consumption per frame."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,10.1109/tcsi.2022.3149006                                               ,2022-05-02 ,           ,"['hong-han lien', 'tian-sheuan chang']"
2205.00779 ,zebra: memory bandwidth reduction for cnn accelerators with zero block   regularization of activation maps                                                                              ,cs.ar cs.cv cs.lg                                        ,"the large amount of memory bandwidth between local buffer and external dram has become the speedup bottleneck of cnn hardware accelerators, especially for activation maps. to reduce memory bandwidth, we propose to learn pruning unimportant blocks dynamically with zero block regularization of activation maps (zebra). this strategy has low computational overhead and could easily integrate with other pruning methods for better performance. the experimental results show that the proposed method can reduce 70\% of memory bandwidth for resnet-18 on tiny-imagenet within 1\% accuracy drops and 2\% accuracy gain with the combination of network slimming."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,                                                                        ,2022-05-02 ,           ,"['hsu-tung shih', 'tian-sheuan chang']"
2205.00807 ,deep-attack over the deep reinforcement learning                                                                                                                                        ,cs.lg cs.ai cs.cr cs.cy                                  ,"recent adversarial attack developments have made reinforcement learning more vulnerable, and different approaches exist to deploy attacks against it, where the key is how to choose the right timing of the attack. some work tries to design an attack evaluation function to select critical points that will be attacked if the value is greater than a certain threshold. this approach makes it difficult to find the right place to deploy an attack without considering the long-term impact. in addition, there is a lack of appropriate indicators of assessment during attacks. to make the attacks more intelligent as well as to remedy the existing problems, we propose the reinforcement learning-based attacking framework by considering the effectiveness and stealthy spontaneously, while we also propose a new metric to evaluate the performance of the attack model in these two aspects. experimental results show the effectiveness of our proposed model and the goodness of our proposed evaluation metric. furthermore, we validate the transferability of the model, and also its robustness under the adversarial training."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2022-05-02 ,           ,"['yang li', 'quan pan', 'erik cambria']"
2205.00824 ,exploration in deep reinforcement learning: a survey                                                                                                                                    ,cs.lg                                                    ,"this paper reviews exploration techniques in deep reinforcement learning. exploration techniques are of primary importance when solving sparse reward problems. in sparse reward problems, the reward is rare, which means that the agent will not find the reward often by acting randomly. in such a scenario, it is challenging for reinforcement learning to learn rewards and actions association. thus more sophisticated exploration methods need to be devised. this review provides a comprehensive overview of existing exploration approaches, which are categorized based on the key contributions as follows reward novel states, reward diverse behaviours, goal-based methods, probabilistic methods, imitation-based methods, safe exploration and random-based methods. then, the unsolved challenges are discussed to provide valuable future research directions. finally, the approaches of different categories are compared in terms of complexity, computational effort and overall performance."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,10.1016/j.inffus.2022.03.003                                            ,2022-05-02 ,           ,"['pawel ladosz', 'lilian weng', 'minwoo kim', 'hyondong oh']"
2205.00833 ,predicting and optimizing for energy efficient acmv systems:   computational intelligence approaches                                                                                    ,eess.sy cs.ai cs.lg cs.ne cs.sy                          ,"in this study, a novel application of neural networks that predict thermal comfort states of occupants is proposed with accuracy over 95%, and two optimization algorithms are proposed and evaluated under two real cases (general offices and lecture theatres/conference rooms scenarios) in singapore. the two optimization algorithms are bayesian gaussian process optimization (bgpo) and augmented firefly algorithm (afa). based on our earlier studies, the models of energy consumption were developed and well-trained through neural networks. this study focuses on using novel active approaches to evaluate thermal comfort of occupants and so as to solves a multiple-objective problem that aims to balance energy-efficiency of centralized air-conditioning systems and thermal comfort of occupants. the study results show that both bgpo and afa are feasible to resolve this no prior knowledge-based optimization problem effectively. however, the optimal solutions of afa are more consistent than those of bgpo at given sample sizes. the best energy saving rates (esr) of bgpo and afa are around -21% and -10% respectively at energy-efficient user preference for both case 1 and case 2. as a result, an potential benefit of s$1219.1 can be achieved annually for this experimental laboratory level in singapore."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ,                                                                        ,2022-04-19 ,           ,"['deqing zhai', 'yeng chai soh']"
2205.00853 ,lightweight image enhancement network for mobile devices using   self-feature extraction and dense modulation                                                                           ,eess.iv cs.lg                                            ,"convolutional neural network (cnn) based image enhancement methods such as super-resolution and detail enhancement have achieved remarkable performances. however, amounts of operations including convolution and parameters within the networks cost high computing power and need huge memory resource, which limits the applications with on-device requirements. lightweight image enhancement network should restore details, texture, and structural information from low-resolution input images while keeping their fidelity. to address these issues, a lightweight image enhancement network is proposed. the proposed network include self-feature extraction module which produces modulation parameters from low-quality image itself, and provides them to modulate the features in the network. also, dense modulation block is proposed for unit block of the proposed network, which uses dense connections of concatenated features applied in modulation layers. experimental results demonstrate better performance over existing approaches in terms of both quantitative and qualitative evaluations."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,                                                                        ,2022-05-02 ,           ,"['sangwook baek', 'yongsup park', 'youngo park', 'jungmin lee', 'kwangpyo choi']"
2205.00865 ,weatherbench probability: a benchmark dataset for probabilistic   medium-range weather forecasting along with deep learning baseline models                                             ,physics.ao-ph cs.lg                                      ,"weatherbench is a benchmark dataset for medium-range weather forecasting of geopotential, temperature and precipitation, consisting of preprocessed data, predefined evaluation metrics and a number of baseline models. weatherbench probability extends this to probabilistic forecasting by adding a set of established probabilistic verification metrics (continuous ranked probability score, spread-skill ratio and rank histograms) and a state-of-the-art operational baseline using the ecwmf ifs ensemble forecast. in addition, we test three different probabilistic machine learning methods -- monte carlo dropout, parametric prediction and categorical prediction, in which the probability distribution is discretized. we find that plain monte carlo dropout severely underestimates uncertainty. the parametric and categorical models both produce fairly reliable forecasts of similar quality. the parametric models have fewer degrees of freedom while the categorical model is more flexible when it comes to predicting non-gaussian distributions. none of the models are able to match the skill of the operational ifs model. we hope that this benchmark will enable other researchers to evaluate their probabilistic approaches."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ,                                                                        ,2022-05-02 ,           ,"['sagar garg', 'stephan rasp', 'nils thuerey']"
2205.00874 ,"family of two dimensional transition metal dichlorides fundamental   properties, structural defects, and environmental stability"                                                      ,cond-mat.mtrl-sci cs.lg physics.app-ph                   ,"a large number of novel two-dimensional (2d) materials are constantly discovered and deposed into the databases. consolidate implementation of machine learning algorithms and density functional theory (dft) based predictions have allowed creating several databases containing an unimaginable amount of 2d samples. the next step in this chain, the investigation leads to a comprehensive study of the functionality of the invented materials. in this work, a family of transition metal dichlorides has been screened out for systematical investigation of their structural stability, fundamental properties, structural defects, and environmental stability via dft based calculations. the work highlights the importance of using the potential of the invented materials and proposes a comprehensive characterization of a new family of 2d materials."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ,10.1021/acs.jpclett.2c00367                                             ,2022-04-29 ,           ,"['andrey a. kistanov', 'stepan a. shcherbinin', 'romain botella', 'artur davletshin', 'wei cao']"
2205.00894 ,modeling and mitigation of occupational safety risks in dynamic   industrial environments                                                                                               ,stat.ap cs.lg                                            ,"identifying and mitigating safety risks is paramount in a number of industries. in addition to guidelines and best practices, many industries already have safety management systems (smss) designed to monitor and reinforce good safety behaviors. the analytic capabilities to analyze the data acquired through such systems, however, are still lacking in terms of their ability to robustly quantify risks posed by various occupational hazards. moreover, best practices and modern smss are unable to account for dynamically evolving environments/behavioral characteristics commonly found in many industrial settings. this article proposes a method to address these issues by enabling continuous and quantitative assessment of safety risks in a data-driven manner. the backbone of our method is an intuitive hierarchical probabilistic model that explains sparse and noisy safety data collected by a typical sms. a fully bayesian approach is developed to calibrate this model from safety data in an online fashion. thereafter, the calibrated model holds necessary information that serves to characterize risk posed by different safety hazards. additionally, the proposed model can be leveraged for automated decision making, for instance solving resource allocation problems -- targeted towards risk mitigation -- that are often encountered in resource-constrained industrial environments. the methodology is rigorously validated on a simulated test-bed and its scalability is demonstrated on real data from large maintenance projects at a petrochemical plant."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,                                                                        ,2022-05-02 ,           ,"['ashutosh tewari', 'antonio r. paiva']"
2205.00905 ,fastgcl: fast self-supervised learning on graphs via contrastive   neighborhood aggregation                                                                                             ,cs.lg cs.ai                                              ,"graph contrastive learning (gcl), as a popular approach to graph self-supervised learning, has recently achieved a non-negligible effect. to achieve superior performance, the majority of existing gcl methods elaborate on graph data augmentation to construct appropriate contrastive pairs. however, existing methods place more emphasis on the complex graph data augmentation which requires extra time overhead, and pay less attention to developing contrastive schemes specific to encoder characteristics. we argue that a better contrastive scheme should be tailored to the characteristics of graph neural networks (e.g., neighborhood aggregation) and propose a simple yet effective method named fastgcl. specifically, by constructing weighted-aggregated and non-aggregated neighborhood information as positive and negative samples respectively, fastgcl identifies the potential semantic information of data without disturbing the graph topology and node attributes, resulting in faster training and convergence speeds. extensive experiments have been conducted on node classification and graph classification tasks, showing that fastgcl has competitive classification performance and significant training speedup compared to existing state-of-the-art methods."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2022-05-02 ,           ,"['yuansheng wang', 'wangbin sun', 'kun xu', 'zulun zhu', 'liang chen', 'zibin zheng']"
2205.00973 ,wireless lan sensing with smart antennas                                                                                                                                                ,cs.ni cs.lg eess.sp                                      ,"the paper targets the problem of human motion detection using wireless local area network devices (wifi) equipped with pattern reconfigurable antennas. motion sensing is obtained by monitoring the body-induced alterations of the ambient wifi signals originated from smart antennas supporting the beam-steering technology, thus allowing to channelize the antenna radiation pattern to pre-defined spots of interest. we first discuss signal and channel state information (csi) processing and sanitization. next, we describe the motion detection algorithm based on angle-of-arrival (aoa) monitoring. proposed algorithms are validated experimentally inside a large size smart home environment."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,                                                                        ,2022-04-27 ,           ,"['marco santoboni', 'riccardo bersan', 'stefano savazzi', 'alberto zecchin', 'vittorio rampa daniele piazza']"
2205.00974 ,cross cryptocurrency relationship mining for bitcoin price prediction                                                                                                                   ,q-fin.st cs.ai cs.lg                                     ,"blockchain finance has become a part of the world financial system, most typically manifested in the attention to the price of bitcoin. however, a great deal of work is still limited to using technical indicators to capture bitcoin price fluctuation, with little consideration of historical relationships and interactions between related cryptocurrencies. in this work, we propose a generic cross-cryptocurrency relationship mining module, named c2rm, which can effectively capture the synchronous and asynchronous impact factors between bitcoin and related altcoins. specifically, we utilize the dynamic time warping algorithm to extract the lead-lag relationship, yielding lead-lag variance kernel, which will be used for aggregating the information of altcoins to form relational impact factors. comprehensive experimental results demonstrate that our c2rm can help existing price prediction methods achieve significant performance improvement, suggesting the effectiveness of cross-cryptocurrency interactions on benefitting bitcoin price prediction."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,                                                                        ,2022-04-27 ,           ,"['panpan li', 'shengbo gong', 'shaocong xu', 'jiajun zhou', 'yu shanqing', 'qi xuan']"
2205.00984 ,a sharp memory-regret trade-off for multi-pass streaming bandits                                                                                                                        ,cs.lg stat.ml                                            ,"the stochastic $k$-armed bandit problem has been studied extensively due to its applications in various domains ranging from online advertising to clinical trials. in practice however, the number of arms can be very large resulting in large memory requirements for simultaneously processing them. in this paper we consider a streaming setting where the arms are presented in a stream and the algorithm uses limited memory to process these arms. here, the goal is not only to minimize regret, but also to do so in minimal memory. previous algorithms for this problem operate in one of the two settings: they either use $\omega(\log \log t)$ passes over the stream (rathod, 2021; chaudhuri and kalyanakrishnan, 2020; liau et al., 2018), or just a single pass (maiti et al., 2021).   in this paper we study the trade-off between memory and regret when $b$ passes over the stream are allowed, for any $b \geq 1$, and establish tight regret upper and lower bounds for any $b$-pass algorithm. our results uncover a surprising *sharp transition phenomenon*: $o(1)$ memory is sufficient to achieve $\widetilde\theta\big(t^{\frac{1}{2} + \frac{1}{2^{b+2}-2}}\big)$ regret in $b$ passes, and increasing the memory to any quantity that is $o(k)$ has almost no impact on further reducing this regret, unless we use $\omega(k)$ memory. our main technical contribution is our lower bound which requires the use of information-theoretic techniques as well as ideas from round elimination to show that the *residual problem* remains challenging over subsequent passes."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,                                                                        ,2022-05-02 ,           ,"['arpit agarwal', 'sanjeev khanna', 'prathamesh patil']"
2205.01030 ,gmss: graph-based multi-task self-supervised learning for eeg emotion   recognition                                                                                                     ,eess.sp cs.ai cs.lg                                      ,"previous electroencephalogram (eeg) emotion recognition relies on single-task learning, which may lead to overfitting and learned emotion features lacking generalization. in this paper, a graph-based multi-task self-supervised learning model (gmss) for eeg emotion recognition is proposed. gmss has the ability to learn more general representations by integrating multiple self-supervised tasks, including spatial and frequency jigsaw puzzle tasks, and contrastive learning tasks. by learning from multiple tasks simultaneously, gmss can find a representation that captures all of the tasks thereby decreasing the chance of overfitting on the original task, i.e., emotion recognition task. in particular, the spatial jigsaw puzzle task aims to capture the intrinsic spatial relationships of different brain regions. considering the importance of frequency information in eeg emotional signals, the goal of the frequency jigsaw puzzle task is to explore the crucial frequency bands for eeg emotion recognition. to further regularize the learned features and encourage the network to learn inherent representations, contrastive learning task is adopted in this work by mapping the transformed data into a common feature space. the performance of the proposed gmss is compared with several popular unsupervised and supervised methods. experiments on seed, seed-iv, and mped datasets show that the proposed model has remarkable advantages in learning more discriminative and general features for eeg emotional signals."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2022-04-11 ,           ,"['yang li', 'ji chen', 'fu li', 'boxun fu', 'hao wu', 'youshuo ji', 'yijin zhou', 'yi niu', 'guangming shi', 'wenming zheng']"
2205.01037 ,data justice in practice: a guide for developers                                                                                                                                        ,cs.cy cs.ai cs.db cs.hc cs.lg                            ,"the advancing data justice research and practice project aims to broaden understanding of the social, historical, cultural, political, and economic forces that contribute to discrimination and inequity in contemporary ecologies of data collection, governance, and use. this is the consultation draft of a guide for developers and organisations, which are producing, procuring, or using data-intensive technologies.in the first section, we introduce the field of data justice, from its early discussions to more recent proposals to relocate understandings of what data justice means. this section includes a description of the six pillars of data justice around which this guidance revolves. next, to support developers in designing, developing, and deploying responsible and equitable data-intensive and ai/ml systems, we outline the ai/ml project lifecycle through a sociotechnical lens. to support the operationalisation data justice throughout the entirety of the ai/ml lifecycle and within data innovation ecosystems, we then present five overarching principles of responsible, equitable, and trustworthy data research and innovation practices, the safe-d principles-safety, accountability, fairness, explainability, and data quality, integrity, protection, and privacy. the final section presents guiding questions that will help developers both address data justice issues throughout the ai/ml lifecycle and engage in reflective innovation practices that ensure the design, development, and deployment of responsible and equitable data-intensive and ai/ml systems."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,10.5281/zenodo.6428185                                                  ,2022-04-12 ,           ,"['david leslie', 'michael katell', 'mhairi aitken', 'jatinder singh', 'morgan briggs', 'rosamund powell', 'cami rincón', 'antonella perini', 'smera jayadeva', 'christopher burr']"
2205.01040 ,a survey on uncertainty toolkits for deep learning                                                                                                                                      ,cs.lg                                                    ,"the success of deep learning (dl) fostered the creation of unifying frameworks such as tensorflow or pytorch as much as it was driven by their creation in return. having common building blocks facilitates the exchange of, e.g., models or concepts and makes developments easier replicable. nonetheless, robust and reliable evaluation and assessment of dl models has often proven challenging. this is at odds with their increasing safety relevance, which recently culminated in the field of ""trustworthy ml"". we believe that, among others, further unification of evaluation and safeguarding methodologies in terms of toolkits, i.e., small and specialized framework derivatives, might positively impact problems of trustworthiness as well as reproducibility. to this end, we present the first survey on toolkits for uncertainty estimation (ue) in dl, as ue forms a cornerstone in assessing model reliability. we investigate 11 toolkits with respect to modeling and evaluation capabilities, providing an in-depth comparison for the three most promising ones, namely pyro, tensorflow probability, and uncertainty quantification 360. while the first two provide a large degree of flexibility and seamless integration into their respective framework, the last one has the larger methodological scope."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ,                                                                        ,2022-05-02 ,           ,"['maximilian pintz', 'joachim sicking', 'maximilian poretschkin', 'maram akila']"
2205.01054 ,a change dynamic model for the online detection of gradual change                                                                                                                       ,stat.ml cs.lg stat.ap                                    ,"changes in the statistical properties of a stochastic process are typically assumed to occur via change-points, which demark instantaneous moments of complete and total change in process behavior. in cases where these transitions occur gradually, this assumption can result in a reduced ability to properly identify and respond to process change. with this observation in mind, we introduce a novel change-dynamic model for the online detection of gradual change in a bayesian framework, in which change-points are used within a hierarchical model to indicate moments of gradual change onset or termination. we apply this model to synthetic data and eeg readings drawn during epileptic seizure, where we find our change-dynamic model can enable faster and more accurate identification of gradual change than traditional change-point models allow."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,                                                                        ,2022-05-02 ,2022-05-03 ,['chris browne']
2205.01057 ,causal discovery on the effect of antipsychotic drugs on delirium   patients in the icu using large ehr dataset                                                                         ,cs.lg cs.ai                                              ,"delirium occurs in about 80% cases in the intensive care unit (icu) and is associated with a longer hospital stay, increased mortality and other related issues. delirium does not have any biomarker-based diagnosis and is commonly treated with antipsychotic drugs (apd). however, multiple studies have shown controversy over the efficacy or safety of apd in treating delirium. since randomized controlled trials (rct) are costly and time-expensive, we aim to approach the research question of the efficacy of apd in the treatment of delirium using retrospective cohort analysis. we plan to use the causal inference framework to look for the underlying causal structure model, leveraging the availability of large observational data on icu patients. to explore safety outcomes associated with apd, we aim to build a causal model for delirium in the icu using large observational data sets connecting various covariates correlated with delirium. we utilized the mimic iii database, an extensive electronic health records (ehr) dataset with 53,423 distinct hospital admissions. our null hypothesis is: there is no significant difference in outcomes for delirium patients under different drug-group in the icu. through our exploratory, machine learning based and causal analysis, we had findings such as: mean length-of-stay and max length-of-stay is higher for patients in haloperidol drug group, and haloperidol group has a higher rate of death in a year compared to other two-groups. our generated causal model explicitly shows the functional relationships between different covariates. for future work, we plan to do time-varying analysis on the dataset."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,                                                                        ,2022-04-28 ,           ,"['riddhiman adib', 'md osman gani', 'sheikh iqbal ahamed', 'mohammad adibuzzaman']"
2205.01064 ,meta transfer learning for early success prediction in moocs                                                                                                                            ,cs.cy cs.lg                                              ,"despite the increasing popularity of massive open online courses (moocs), many suffer from high dropout and low success rates. early prediction of student success for targeted intervention is therefore essential to ensure no student is left behind in a course. there exists a large body of research in success prediction for moocs, focusing mainly on training models from scratch for individual courses. this setting is impractical in early success prediction as the performance of a student is only known at the end of the course. in this paper, we aim to create early success prediction models that can be transferred between moocs from different domains and topics. to do so, we present three novel strategies for transfer: 1) pre-training a model on a large set of diverse courses, 2) leveraging the pre-trained model by including meta information about courses, and 3) fine-tuning the model on previous course iterations. our experiments on 26 moocs with over 145,000 combined enrollments and millions of interactions show that models combining interaction data and course information have comparable or better performance than models which have access to previous iterations of the course. with these models, we aim to effectively enable educators to warm-start their predictions for new and ongoing courses."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,                                                                        ,2022-04-25 ,           ,"['vinitra swamy', 'mirko marras', 'tanja käser']"
2205.01069 ,deep learning: from basics to building deep neural networks with python                                                                                                                 ,cs.lg                                                    ,this book is intended for beginners who have no familiarity with deep learning. our only expectation from readers is that they already have the basic programming skills in python.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,                                                                        ,2022-04-22 ,           ,['milad vazan']
2205.01072 ,the equity framework: fairness beyond equalized predictive outcomes                                                                                                                     ,cs.cy cs.ai cs.lg                                        ,"machine learning (ml) decision-making algorithms are now widely used in predictive decision-making, for example, to determine who to admit and give a loan. their wide usage and consequential effects on individuals led the ml community to question and raise concerns on how the algorithms differently affect different people and communities. in this paper, we study fairness issues that arise when decision-makers use models (proxy models) that deviate from the models that depict the physical and social environment in which the decisions are situated (intended models). we also highlight the effect of obstacles on individual access and utilization of the models. to this end, we formulate an equity framework that considers equal access to the model, equal outcomes from the model, and equal utilization of the model, and consequentially achieves equity and higher social welfare than current fairness notions that aim for equality. we show how the three main aspects of the framework are connected and provide an equity scoring algorithm and questions to guide decision-makers towards equitable decision-making. we show how failure to consider access, outcome, and utilization would exacerbate proxy gaps leading to an infinite inequity loop that reinforces structural inequities through inaccurate and incomplete ground truth curation. we, therefore, recommend a more critical look at the model design and its effect on equity and a shift towards equity achieving predictive decision-making models."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,                                                                        ,2022-04-18 ,           ,"['keziah naggita', 'j. ceasar aguma']"
2205.01076 ,classification of buildings' potential for seismic damage by means of   artificial intelligence techniques                                                                              ,cs.lg                                                    ,"developing a rapid, but also reliable and efficient, method for classifying the seismic damage potential of buildings constructed in countries with regions of high seismicity is always at the forefront of modern scientific research. such a technique would be essential for estimating the pre-seismic vulnerability of the buildings, so that the authorities will be able to develop earthquake safety plans for seismic rehabilitation of the highly earthquake-susceptible structures. in the last decades, several researchers have proposed such procedures, some of which were adopted by seismic code guidelines. these procedures usually utilize methods based either on simple calculations or on the application of statistics theory. recently, the increase of the computers' power has led to the development of modern statistical methods based on the adoption of machine learning algorithms. these methods have been shown to be useful for predicting seismic performance and classifying structural damage level by means of extracting patterns from data collected via various sources. a large training dataset is used for the implementation of the classification algorithms. to this end, 90 3d r/c buildings with three different masonry infills' distributions are analysed utilizing nonlinear time history analysis method for 65 real seismic records. the level of the seismic damage is expressed in terms of the maximum interstory drift ratio. a large number of machine learning algorithms is utilized in order to estimate the buildings' damage response. the most significant conclusion which is extracted is that the machine learning methods that are mathematically well-established and their operations that are clearly interpretable step by step can be used to solve some of the most sophisticated real-world problems in consideration with high accuracy."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ,                                                                        ,2022-04-06 ,           ,"['konstantinos kostinakis', 'konstantinos morfidis', 'konstantinos demertzis', 'lazaros iliadis']"
2205.01080 ,a probabilistic interpretation of transformers                                                                                                                                          ,cs.lg                                                    ,"we propose a probabilistic interpretation of exponential dot product attention of transformers and contrastive learning based off of exponential families. the attention sublayer of transformers is equivalent to a gradient ascent step of the log normalizer, which is the log-sum-exp term in the hopfield theory of attention. this ascent step induces a parallel expansion of points, which is counterbalanced by a contraction from layer normalization. we also state theoretical limitations of our theory and the hopfield theory and suggest directions for resolution."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ,                                                                        ,2022-04-28 ,           ,['alexander shim']
2205.01081 ,distributed intelligence on the edge-to-cloud continuum: a systematic   literature review                                                                                               ,cs.lg cs.dc                                              ,"the explosion of data volumes generated by an increasing number of applications is strongly impacting the evolution of distributed digital infrastructures for data analytics and machine learning (ml). while data analytics used to be mainly performed on cloud infrastructures, the rapid development of iot infrastructures and the requirements for low-latency, secure processing has motivated the development of edge analytics. today, to balance various trade-offs, ml-based analytics tends to increasingly leverage an interconnected ecosystem that allows complex applications to be executed on hybrid infrastructures where iot edge devices are interconnected to cloud/hpc systems in what is called the computing continuum, the digital continuum, or the transcontinuum.enabling learning-based analytics on such complex infrastructures is challenging. the large scale and optimized deployment of learning-based workflows across the edge-to-cloud continuum requires extensive and reproducible experimental analysis of the application execution on representative testbeds. this is necessary to help understand the performance trade-offs that result from combining a variety of learning paradigms and supportive frameworks. a thorough experimental analysis requires the assessment of the impact of multiple factors, such as: model accuracy, training time, network overhead, energy consumption, processing latency, among others.this review aims at providing a comprehensive vision of the main state-of-the-art libraries and frameworks for machine learning and data analytics available today. it describes the main learning paradigms enabling learning-based analytics on the edge-to-cloud continuum. the main simulation, emulation, deployment systems, and testbeds for experimental research on the edge-to-cloud continuum available today are also surveyed. furthermore, we analyze how the selected systems provide support for experiment reproducibility. we conclude our review with a detailed discussion of relevant open research challenges and of future directions in this domain such as: holistic understanding of performance; performance optimization of applications;efficient deployment of artificial intelligence (ai) workflows on highly heterogeneous infrastructures; and reproducible analysis of experiments on the computing continuum." ,10.1016/j.jpdc.2022.04.004                                              ,2022-04-29 ,           ,"['daniel rosendo', 'alexandru costan', 'patrick valduriez', 'gabriel antoniu']"
2205.01086 ,wav2seq: pre-training speech-to-text encoder-decoder models using pseudo   languages                                                                                                    ,cs.cl cs.lg cs.sd eess.as                                ,"we introduce wav2seq, the first self-supervised approach to pre-train both parts of encoder-decoder models for speech data. we induce a pseudo language as a compact discrete representation, and formulate a self-supervised pseudo speech recognition task -- transcribing audio inputs into pseudo subword sequences. this process stands on its own, or can be applied as low-cost second-stage pre-training. we experiment with automatic speech recognition (asr), spoken named entity recognition, and speech-to-text translation. we set new state-of-the-art results for end-to-end spoken named entity recognition, and show consistent improvements on 20 language pairs for speech-to-text translation, even when competing methods use additional text data for training. finally, on asr, our approach enables encoder-decoder methods to benefit from pre-training for all parts of the network, and shows comparable performance to highly optimized recent methods."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,                                                                        ,2022-05-02 ,           ,"['felix wu', 'kwangyoun kim', 'shinji watanabe', 'kyu han', 'ryan mcdonald', 'kilian q. weinberger', 'yoav artzi']"
2205.01088 ,ensemble pruning via an integer programming approach with diversity   constraints                                                                                                       ,cs.lg math.oc                                            ,"ensemble learning combines multiple classifiers in the hope of obtaining better predictive performance. empirical studies have shown that ensemble pruning, that is, choosing an appropriate subset of the available classifiers, can lead to comparable or better predictions than using all classifiers. in this paper, we consider a binary classification problem and propose an integer programming (ip) approach for selecting optimal classifier subsets. we propose a flexible objective function to adapt to desired criteria of different datasets. we also propose constraints to ensure minimum diversity levels in the ensemble. despite the general case of ip being np-hard, state-of-the-art solvers are able to quickly obtain good solutions for datasets with up to 60000 data points. our approach yields competitive results when compared to some of the best and most used pruning methods in literature."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,                                                                        ,2022-05-02 ,           ,"['marcelo antônio mendes bastos', 'humberto brandão césar de oliveira', 'cristiano arbex valle']"
2205.01089 ,comphy: compositional physical reasoning of objects and events from   videos                                                                                                            ,cs.cv cs.ai cs.lg cs.ro                                  ,"objects' motions in nature are governed by complex interactions and their properties. while some properties, such as shape and material, can be identified via the object's visual appearances, others like mass and electric charge are not directly visible. the compositionality between the visible and hidden properties poses unique challenges for ai models to reason from the physical world, whereas humans can effortlessly infer them with limited observations. existing studies on video reasoning mainly focus on visually observable elements such as object appearance, movement, and contact interaction. in this paper, we take an initial step to highlight the importance of inferring the hidden physical properties not directly observable from visual appearances, by introducing the compositional physical reasoning (comphy) dataset. for a given set of objects, comphy includes few videos of them moving and interacting under different initial conditions. the model is evaluated based on its capability to unravel the compositional hidden properties, such as mass and charge, and use this knowledge to answer a set of questions posted on one of the videos. evaluation results of several state-of-the-art video reasoning models on comphy show unsatisfactory performance as they fail to capture these hidden properties. we further propose an oracle neural-symbolic framework named compositional physics learner (cpl), combining visual perception, physical property learning, dynamic prediction, and symbolic execution into a unified framework. cpl can effectively identify objects' physical properties from their interactions and predict their dynamics to answer questions."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,                                                                        ,2022-05-02 ,           ,"['zhenfang chen', 'kexin yi', 'yunzhu li', 'mingyu ding', 'antonio torralba', 'joshua b. tenenbaum', 'chuang gan']"
2205.01135 ,d-dpcc: deep dynamic point cloud compression via 3d motion prediction                                                                                                                   ,cs.cv cs.lg eess.iv                                      ,"the non-uniformly distributed nature of the 3d dynamic point cloud (dpc) brings significant challenges to its high-efficient inter-frame compression. this paper proposes a novel 3d sparse convolution-based deep dynamic point cloud compression (d-dpcc) network to compensate and compress the dpc geometry with 3d motion estimation and motion compensation in the feature space. in the proposed d-dpcc network, we design a {\it multi-scale motion fusion} (mmf) module to accurately estimate the 3d optical flow between the feature representations of adjacent point cloud frames. specifically, we utilize a 3d sparse convolution-based encoder to obtain the latent representation for motion estimation in the feature space and introduce the proposed mmf module for fused 3d motion embedding. besides, for motion compensation, we propose a 3d {\it adaptively weighted interpolation} (3dawi) algorithm with a penalty coefficient to adaptively decrease the impact of distant neighbors. we compress the motion embedding and the residual with a lossy autoencoder-based network. to our knowledge, this paper is the first work proposing an end-to-end deep dynamic point cloud compression framework. the experimental result shows that the proposed d-dpcc framework achieves an average 76\% bd-rate (bjontegaard delta rate) gains against state-of-the-art video-based point cloud compression (v-pcc) v13 in inter mode."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,                                                                        ,2022-05-02 ,           ,"['tingyu fan', 'linyao gao', 'yiling xu', 'zhu li', 'dong wang']"
2205.01155 ,emotion-controllable generalized talking face generation                                                                                                                                ,cs.cv cs.lg cs.mm                                        ,"despite the significant progress in recent years, very few of the ai-based talking face generation methods attempt to render natural emotions. moreover, the scope of the methods is majorly limited to the characteristics of the training dataset, hence they fail to generalize to arbitrary unseen faces. in this paper, we propose a one-shot facial geometry-aware emotional talking face generation method that can generalize to arbitrary faces. we propose a graph convolutional neural network that uses speech content feature, along with an independent emotion input to generate emotion and speech-induced motion on facial geometry-aware landmark representation. this representation is further used in our optical flow-guided texture generation network for producing the texture. we propose a two-branch texture generation network, with motion and texture branches designed to consider the motion and texture content independently. compared to the previous emotion talking face methods, our method can adapt to arbitrary faces captured in-the-wild by fine-tuning with only a single image of the target identity in neutral emotion."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,                                                                        ,2022-05-02 ,           ,"['sanjana sinha', 'sandika biswas', 'ravindra yadav', 'brojeshwar bhowmick']"
2205.01156 ,selc: self-ensemble label correction improves learning with noisy labels                                                                                                                ,cs.cv cs.lg                                              ,"deep neural networks are prone to overfitting noisy labels, resulting in poor generalization performance. to overcome this problem, we present a simple and effective method self-ensemble label correction (selc) to progressively correct noisy labels and refine the model. we look deeper into the memorization behavior in training with noisy labels and observe that the network outputs are reliable in the early stage. to retain this reliable knowledge, selc uses ensemble predictions formed by an exponential moving average of network outputs to update the original noisy labels. we show that training with selc refines the model by gradually reducing supervision from noisy labels and increasing supervision from ensemble predictions. despite its simplicity, compared with many state-of-the-art methods, selc obtains more promising and stable results in the presence of class-conditional, instance-dependent, and real-world label noise. the code is available at https://github.com/maclll/selc."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,                                                                        ,2022-05-02 ,           ,"['yangdi lu', 'wenbo he']"
2205.01158 ,reproducing kernels and new approaches in compositional data analysis                                                                                                                   ,stat.ml cs.lg math.st stat.th                            ,"compositional data, such as human gut microbiomes, consist of non-negative variables whose only the relative values to other variables are available. analyzing compositional data such as human gut microbiomes needs a careful treatment of the geometry of the data. a common geometrical understanding of compositional data is via a regular simplex. majority of existing approaches rely on a log-ratio or power transformations to overcome the innate simplicial geometry. in this work, based on the key observation that a compositional data are projective in nature, and on the intrinsic connection between projective and spherical geometry, we re-interpret the compositional domain as the quotient topology of a sphere modded out by a group action. this re-interpretation allows us to understand the function space on compositional domains in terms of that on spheres and to use spherical harmonics theory along with reflection group actions for constructing a compositional reproducing kernel hilbert space (rkhs). this construction of rkhs for compositional data will widely open research avenues for future methodology developments. in particular, well-developed kernel embedding methods can be now introduced to compositional data analysis. the polynomial nature of compositional rkhs has both theoretical and computational benefits. the wide applicability of the proposed theoretical framework is exemplified with nonparametric density estimation and kernel exponential family for compositional data."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,                                                                        ,2022-05-02 ,           ,"['binglin li', 'jeongyoun ahn']"
2205.01180 ,using machine learning to evaluate real estate prices using location big   data                                                                                                         ,cs.lg                                                    ,"with everyone trying to enter the real estate market nowadays, knowing the proper valuations for residential and commercial properties has become crucial. past researchers have been known to utilize static real estate data (e.g. number of beds, baths, square footage) or even a combination of real estate and demographic information to predict property prices. in this investigation, we attempted to improve upon past research. so we decided to explore a unique approach: we wanted to determine if mobile location data could be used to improve the predictive power of popular regression and tree-based models. to prepare our data for our models, we processed the mobility data by attaching it to individual properties from the real estate data that aggregated users within 500 meters of the property for each day of the week. we removed people that lived within 500 meters of each property, so each property's aggregated mobility data only contained non-resident census features. on top of these dynamic census features, we also included static census features, including the number of people in the area, the average proportion of people commuting, and the number of residents in the area. finally, we tested multiple models to predict real estate prices. our proposed model is two stacked random forest modules combined using a ridge regression that uses the random forest outputs as predictors. the first random forest model used static features only and the second random forest model used dynamic features only. comparing our models with and without the dynamic mobile location features concludes the model with dynamic mobile location features achieves 3/% percent lower mean squared error than the same model but without dynamic mobile location features."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,                                                                        ,2022-05-02 ,           ,"['walter coleman', 'ben johann', 'nicholas pasternak', 'jaya vellayan', 'natasha foutz', 'heman shakeri']"
2205.01184 ,performance weighting for robust federated learning against corrupted   sources                                                                                                         ,cs.lg cs.cr                                              ,"federated learning has emerged as a dominant computational paradigm for distributed machine learning. its unique data privacy properties allow us to collaboratively train models while offering participating clients certain privacy-preserving guarantees. however, in real-world applications, a federated environment may consist of a mixture of benevolent and malicious clients, with the latter aiming to corrupt and degrade federated model's performance. different corruption schemes may be applied such as model poisoning and data corruption. here, we focus on the latter, the susceptibility of federated learning to various data corruption attacks. we show that the standard global aggregation scheme of local weights is inefficient in the presence of corrupted clients. to mitigate this problem, we propose a class of task-oriented performance-based methods computed over a distributed validation dataset with the goal to detect and mitigate corrupted clients. specifically, we construct a robust weight aggregation scheme based on geometric mean and demonstrate its effectiveness under random label shuffling and targeted label flipping attacks."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,                                                                        ,2022-05-02 ,           ,"['dimitris stripelis', 'marcin abram', 'jose luis ambite']"
2205.01204 ,multi-task text classification using graph convolutional networks for   large-scale low resource language                                                                               ,cs.cl cs.ai cs.lg                                        ,"graph convolutional networks (gcn) have achieved state-of-art results on single text classification tasks like sentiment analysis, emotion detection, etc. however, the performance is achieved by testing and reporting on resource-rich languages like english. applying gcn for multi-task text classification is an unexplored area. moreover, training a gcn or adopting an english gcn for indian languages is often limited by data availability, rich morphological variation, syntax, and semantic differences. in this paper, we study the use of gcn for the telugu language in single and multi-task settings for four natural language processing (nlp) tasks, viz. sentiment analysis (sa), emotion identification (ei), hate-speech (hs), and sarcasm detection (sar). in order to evaluate the performance of gcn with one of the indian languages, telugu, we analyze the gcn based models with extensive experiments on four downstream tasks. in addition, we created an annotated telugu dataset, tel-nlp, for the four nlp tasks. further, we propose a supervised graph reconstruction method, multi-task text gcn (mt-text gcn) on the telugu that leverages to simultaneously (i) learn the low-dimensional word and sentence graph embeddings from word-sentence graph reconstruction using graph autoencoder (gae) and (ii) perform multi-task text classification using these latent sentence graph embeddings. we argue that our proposed mt-text gcn achieves significant improvements on tel-nlp over existing telugu pretrained word embeddings, and multilingual pretrained transformer models: mbert, and xlm-r. on tel-nlp, we achieve a high f1-score for four nlp tasks: sa (0.84), ei (0.55), hs (0.83) and sar (0.66). finally, we show our model's quantitative and qualitative analysis on the four nlp tasks in telugu."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,                                                                        ,2022-05-02 ,           ,"['mounika marreddy', 'subba reddy oota', 'lakshmi sireesha vakada', 'venkata charan chinni', 'radhika mamidi']"
2205.01210 ,applications of deep learning to the design of enhanced wireless   communication systems                                                                                                ,cs.it cs.lg eess.sp math.it                              ,"innovation in the physical layer of communication systems has traditionally been achieved by breaking down the transceivers into sets of processing blocks, each optimized independently based on mathematical models. conversely, deep learning (dl)-based systems are able to handle increasingly complex tasks for which no tractable models are available. this thesis aims at comparing different approaches to unlock the full potential of dl in the physical layer.   first, we describe a neural network (nn)-based block strategy, where an nn is optimized to replace a block in a communication system. we apply this strategy to introduce a multi-user multiple-input multiple-output (mu-mimo) detector that builds on top of an existing dl-based architecture. second, we detail an end-to-end strategy, in which the transmitter and receiver are modeled as an autoencoder. this approach is illustrated with the design of waveforms that achieve high throughputs while satisfying peak-to-average power ratio (papr) and adjacent channel leakage ratio (aclr) constraints. lastly, we propose a hybrid strategy, where multiple dl components are inserted into a traditional architecture but are trained to optimize the end-to-end performance. to demonstrate its benefits, we propose a dl-enhanced mu-mimo receiver that both enable lower bit error rates (bers) compared to a conventional receiver and remains scalable to any number of users.   each approach has its own strengths and shortcomings. while the first one is the easiest to implement, its individual block optimization does not ensure the overall system optimality. on the other hand, systems designed with the second approach are computationally complex but allow for new opportunities such as pilotless transmissions. finally, the combined flexibility and end-to-end performance gains of the third approach motivate its use for short-term practical implementations."                                                                                                                                                                                                                                                                                                                                                                                                                                        ,                                                                        ,2022-05-02 ,           ,['mathieu goutay']
2205.01214 ,an improvement to a result about graph isomorphism networks using the   prime factorization theorem                                                                                     ,cs.lg                                                    ,the unique prime factorization theorem is used to show the existence of a function on a countable set $\mathcal{x}$ so that the sum aggregator function is injective on all multisets of $\mathcal{x}$ of finite size.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,                                                                        ,2022-05-02 ,           ,['rahul sarkar']
2205.01222 ,leveraging stochastic predictions of bayesian neural networks for fluid   simulations                                                                                                   ,physics.flu-dyn cs.lg                                    ,"we investigate uncertainty estimation and multimodality via the non-deterministic predictions of bayesian neural networks (bnns) in fluid simulations. to this end, we deploy bnns in three challenging experimental test-cases of increasing complexity: we show that bnns, when used as surrogate models for steady-state fluid flow predictions, provide accurate physical predictions together with sensible estimates of uncertainty. further, we experiment with perturbed temporal sequences from navier-stokes simulations and evaluate the capabilities of bnns to capture multimodal evolutions. while our findings indicate that this is problematic for large perturbations, our results show that the networks learn to correctly predict high uncertainties in such situations. finally, we study bnns in the context of solver interactions with turbulent plasma flows. we find that bnn-based corrector networks can stabilize coarse-grained simulations and successfully create multimodal trajectories."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,                                                                        ,2022-05-02 ,           ,"['maximilian mueller', 'robin greif', 'frank jenko', 'nils thuerey']"
2205.01224 ,comet flows: towards generative modeling of multivariate extremes and   tail dependence                                                                                                 ,cs.lg stat.ml                                            ,"normalizing flows, a popular class of deep generative models, often fail to represent extreme phenomena observed in real-world processes. in particular, existing normalizing flow architectures struggle to model multivariate extremes, characterized by heavy-tailed marginal distributions and asymmetric tail dependence among variables. in light of this shortcoming, we propose comet (copula multivariate extreme) flows, which decompose the process of modeling a joint distribution into two parts: (i) modeling its marginal distributions, and (ii) modeling its copula distribution. comet flows capture heavy-tailed marginal distributions by combining a parametric tail belief at extreme quantiles of the marginals with an empirical kernel density function at mid-quantiles. in addition, comet flows capture asymmetric tail dependence among multivariate extremes by viewing such dependence as inducing a low-dimensional manifold structure in feature space. experimental results on both synthetic and real-world datasets demonstrate the effectiveness of comet flows in capturing both heavy-tailed marginals and asymmetric tail dependence compared to other state-of-the-art baseline architectures. all code is available on github at https://github.com/andrewmcdonald27/cometflows."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,                                                                        ,2022-05-02 ,           ,"['andrew mcdonald', 'pang-ning tan', 'lifeng luo']"
2205.01226 ,adversarial attacks on an optical neural network                                                                                                                                        ,cs.cr cs.cv cs.lg                                        ,"adversarial attacks have been extensively investigated for machine learning systems including deep learning in the digital domain. however, the adversarial attacks on optical neural networks (onn) have been seldom considered previously. in this work, we first construct an accurate image classifier with an onn using a mesh of interconnected mach-zehnder interferometers (mzi). then a corresponding adversarial attack scheme is proposed for the first time. the attacked images are visually very similar to the original ones but the onn system becomes malfunctioned and generates wrong classification results in most time. the results indicate that adversarial attack is also a significant issue for optical machine learning systems."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,                                                                        ,2022-04-29 ,           ,"['shuming jiao', 'ziwei song', 'shuiying xiang']"
2205.01230 ,retrieval-enhanced machine learning                                                                                                                                                     ,cs.lg cs.cl cs.ir                                        ,"although information access systems have long supported people in accomplishing a wide range of tasks, we propose broadening the scope of users of information access systems to include task-driven machines, such as machine learning models. in this way, the core principles of indexing, representation, retrieval, and ranking can be applied and extended to substantially improve model generalization, scalability, robustness, and interpretability. we describe a generic retrieval-enhanced machine learning (reml) framework, which includes a number of existing models as special cases. reml challenges information retrieval conventions, presenting opportunities for novel advances in core areas, including optimization. the reml research agenda lays a foundation for a new style of information access research and paves a path towards advancing machine learning and artificial intelligence."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,10.1145/3477495.3531722                                                 ,2022-05-02 ,           ,"['hamed zamani', 'fernando diaz', 'mostafa dehghani', 'donald metzler', 'michael bendersky']"
2205.01233 ,one weird trick to improve your semi-weakly supervised semantic   segmentation model                                                                                                    ,cs.cv cs.lg                                              ,"semi-weakly supervised semantic segmentation (swsss) aims to train a model to identify objects in images based on a small number of images with pixel-level labels, and many more images with only image-level labels. most existing swsss algorithms extract pixel-level pseudo-labels from an image classifier - a very difficult task to do well, hence requiring complicated architectures and extensive hyperparameter tuning on fully-supervised validation sets. we propose a method called prediction filtering, which instead of extracting pseudo-labels, just uses the classifier as a classifier: it ignores any segmentation predictions from classes which the classifier is confident are not present. adding this simple post-processing method to baselines gives results competitive with or better than prior swsss algorithms. moreover, it is compatible with pseudo-label methods: adding prediction filtering to existing swsss algorithms further improves segmentation performance."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,                                                                        ,2022-05-02 ,           ,"['wonho bae', 'junhyug noh', 'milad jalali asadabadi', 'danica j. sutherland']"
2205.01235 ,triangular dropout: variable network width without retraining                                                                                                                           ,cs.lg cs.ne                                              ,"one of the most fundamental design choices in neural networks is layer width: it affects the capacity of what a network can learn and determines the complexity of the solution. this latter property is often exploited when introducing information bottlenecks, forcing a network to learn compressed representations. however, such an architecture decision is typically immutable once training begins; switching to a more compressed architecture requires retraining. in this paper we present a new layer design, called triangular dropout, which does not have this limitation. after training, the layer can be arbitrarily reduced in width to exchange performance for narrowness. we demonstrate the construction and potential use cases of such a mechanism in three areas. firstly, we describe the formulation of triangular dropout in autoencoders, creating models with selectable compression after training. secondly, we add triangular dropout to vgg19 on imagenet, creating a powerful network which, without retraining, can be significantly reduced in parameters. lastly, we explore the application of triangular dropout to reinforcement learning (rl) policies on selected control problems."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,                                                                        ,2022-05-02 ,           ,"['edward w. staley', 'jared markowitz']"
2205.01257 ,norm-agnostic linear bandits                                                                                                                                                            ,stat.ml cs.ai cs.lg                                      ,"linear bandits have a wide variety of applications including recommendation systems yet they make one strong assumption: the algorithms must know an upper bound $s$ on the norm of the unknown parameter $\theta^*$ that governs the reward generation. such an assumption forces the practitioner to guess $s$ involved in the confidence bound, leaving no choice but to wish that $\|\theta^*\|\le s$ is true to guarantee that the regret will be low. in this paper, we propose novel algorithms that do not require such knowledge for the first time. specifically, we propose two algorithms and analyze their regret bounds: one for the changing arm set setting and the other for the fixed arm set setting. our regret bound for the former shows that the price of not knowing $s$ does not affect the leading term in the regret bound and inflates only the lower order term. for the latter, we do not pay any price in the regret for now knowing $s$. our numerical experiments show standard algorithms assuming knowledge of $s$ can fail catastrophically when $\|\theta^*\|\le s$ is not true whereas our algorithms enjoy low regret."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ,                                                                        ,2022-05-02 ,           ,"['n/a spencer', 'n/a gales', 'sunder sethuraman', 'kwang-sung jun']"
2205.01300 ,towards an ensemble regressor model for anomalous isp traffic prediction                                                                                                                ,cs.lg cs.ni                                              ,"prediction of network traffic behavior is significant for the effective management of modern telecommunication networks. however, the intuitive approach of predicting network traffic using administrative experience and market analysis data is inadequate for an efficient forecast framework. as a result, many different mathematical models have been studied to capture the general trend of the network traffic and predict accordingly. but the comprehensive performance analysis of varying regression models and their ensemble has not been studied before for analyzing real-world anomalous traffic. in this paper, several regression models such as extra gradient boost (xgboost), light gradient boosting machine (lightgbm), stochastic gradient descent (sgd), gradient boosting regressor (gbr), and catboost regressor were analyzed to predict real traffic without and with outliers and show the significance of outlier detection in real-world traffic prediction. also, we showed the outperformance of the ensemble regression model over the individual prediction model. we compared the performance of different regression models based on five different feature sets of lengths 6, 9, 12, 15, and 18. our ensemble regression model achieved the minimum average gap of 5.04% between actual and predicted traffic with nine outlier-adjusted inputs. in general, our experimental results indicate that the outliers in the data can significantly impact the quality of the prediction. thus, outlier detection and mitigation assist the regression model in learning the general trend and making better predictions."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,                                                                        ,2022-05-03 ,           ,"['sajal saha', 'anwar haque', 'greg sidebottom']"
2205.01314 ,distilling governing laws and source input for dynamical systems from   videos                                                                                                          ,cs.cv cs.ai cs.lg physics.app-ph                         ,"distilling interpretable physical laws from videos has led to expanded interest in the computer vision community recently thanks to the advances in deep learning, but still remains a great challenge. this paper introduces an end-to-end unsupervised deep learning framework to uncover the explicit governing equations of dynamics presented by moving object(s), based on recorded videos. instead in the pixel (spatial) coordinate system of image space, the physical law is modeled in a regressed underlying physical coordinate system where the physical states follow potential explicit governing equations. a numerical integrator-based sparse regression module is designed and serves as a physical constraint to the autoencoder and coordinate system regression, and, in the meanwhile, uncover the parsimonious closed-form governing equations from the learned physical states. experiments on simulated dynamical scenes show that the proposed method is able to distill closed-form governing equations and simultaneously identify unknown excitation input for several dynamical systems recorded by videos, which fills in the gap in literature where no existing methods are available and applicable for solving this type of problem."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ,                                                                        ,2022-05-03 ,           ,"['lele luan', 'yang liu', 'hao sun']"
2205.01317 ,"open vs closed-ended questions in attitudinal surveys -- comparing,   combining, and interpreting using natural language processing"                                                   ,econ.gn cs.cl cs.lg q-fin.ec                             ,"to improve the traveling experience, researchers have been analyzing the role of attitudes in travel behavior modeling. although most researchers use closed-ended surveys, the appropriate method to measure attitudes is debatable. topic modeling could significantly reduce the time to extract information from open-ended responses and eliminate subjective bias, thereby alleviating analyst concerns. our research uses topic modeling to extract information from open-ended questions and compare its performance with closed-ended responses. furthermore, some respondents might prefer answering questions using their preferred questionnaire type. so, we propose a modeling framework that allows respondents to use their preferred questionnaire type to answer the survey and enable analysts to use the modeling frameworks of their choice to predict behavior. we demonstrate this using a dataset collected from the usa that measures the intention to use autonomous vehicles for commute trips. respondents were presented with alternative questionnaire versions (open- and closed- ended). since our objective was also to compare the performance of alternative questionnaire versions, the survey was designed to eliminate influences resulting from statements, behavioral framework, and the choice experiment. results indicate the suitability of using topic modeling to extract information from open-ended responses; however, the models estimated using the closed-ended questions perform better compared to them. besides, the proposed model performs better compared to the models used currently. furthermore, our proposed framework will allow respondents to choose the questionnaire type to answer, which could be particularly beneficial to them when using voice-based surveys."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,10.1016/j.trc.2022.103589                                               ,2022-05-03 ,           ,"['vishnu baburajan', 'joão de abreu e silva', 'francisco camara pereira']"
2205.01324 ,learning discrete structured variational auto-encoder using natural   evolution strategies                                                                                              ,cs.lg cs.ne stat.ml                                      ,"discrete variational auto-encoders (vaes) are able to represent semantic latent spaces in generative learning. in many real-life settings, the discrete latent space consists of high-dimensional structures, and propagating gradients through the relevant structures often requires enumerating over an exponentially large latent space. recently, various approaches were devised to propagate approximated gradients without enumerating over the space of possible structures. in this work, we use natural evolution strategies (nes), a class of gradient-free black-box optimization algorithms, to learn discrete structured vaes. the nes algorithms are computationally appealing as they estimate gradients with forward pass evaluations only, thus they do not require to propagate gradients through their discrete structures. we demonstrate empirically that optimizing discrete structured vaes using nes is as effective as gradient-based approximations. lastly, we prove nes converges for non-lipschitz functions as appear in discrete structured vaes."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,                                                                        ,2022-05-03 ,           ,"['alon berliner', 'guy rotman', 'yossi adi', 'roi reichart', 'tamir hazan']"
2205.01335 ,predicting issue types with sebert                                                                                                                                                      ,cs.se cs.cl cs.lg                                        ,"pre-trained transformer models are the current state-of-the-art for natural language models processing. sebert is such a model, that was developed based on the bert architecture, but trained from scratch with software engineering data. we fine-tuned this model for the nlbse challenge for the task of issue type prediction. our model dominates the baseline fasttext for all three issue types in both recall and precisio} to achieve an overall f1-score of 85.7%, which is an increase of 4.1% over the baseline."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ,                                                                        ,2022-05-03 ,           ,"['alexander trautsch', 'steffen herbold']"
2205.01358 ,learning label initialization for time-dependent harmonic extension                                                                                                                     ,cs.lg                                                    ,"node classification on graphs can be formulated as the dirichlet problem on graphs where the signal is given at the labeled nodes, and the harmonic extension is done on the unlabeled nodes. this paper considers a time-dependent version of the dirichlet problem on graphs and shows how to improve its solution by learning the proper initialization vector on the unlabeled nodes. further, we show that the improved solution is at par with state-of-the-art methods used for node classification. finally, we conclude this paper by discussing the importance of parameter t, pros, and future directions."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,                                                                        ,2022-05-03 ,           ,['amitoz azad']
2205.01366 ,finding patterns in knowledge attribution for transformers                                                                                                                              ,cs.cl cs.lg                                              ,"we analyze the knowledge neurons framework for the attribution of factual and relational knowledge to particular neurons in the transformer network. we use a 12-layer multi-lingual bert model for our experiments. our study reveals various interesting phenomena. we observe that mostly factual knowledge can be attributed to middle and higher layers of the network($\ge 6$). further analysis reveals that the middle layers($6-9$) are mostly responsible for relational information, which is further refined into actual factual knowledge or the ""correct answer"" in the last few layers($10-12$). our experiments also show that the model handles prompts in different languages, but representing the same fact, similarly, providing further evidence for effectiveness of multi-lingual pre-training. applying the attribution scheme for grammatical knowledge, we find that grammatical knowledge is far more dispersed among the neurons than factual knowledge."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,                                                                        ,2022-05-03 ,2022-05-04 ,"['jeevesh juneja', 'ritu agarwal']"
2205.01380 ,deep learning in multimodal remote sensing data fusion: a comprehensive   review                                                                                                        ,cs.cv cs.lg eess.sp                                      ,"with the extremely rapid advances in remote sensing (rs) technology, a great quantity of earth observation (eo) data featuring considerable and complicated heterogeneity is readily available nowadays, which renders researchers an opportunity to tackle current geoscience applications in a fresh way. with the joint utilization of eo data, much research on multimodal rs data fusion has made tremendous progress in recent years, yet these developed traditional algorithms inevitably meet the performance bottleneck due to the lack of the ability to comprehensively analyse and interpret these strongly heterogeneous data. hence, this non-negligible limitation further arouses an intense demand for an alternative tool with powerful processing competence. deep learning (dl), as a cutting-edge technology, has witnessed remarkable breakthroughs in numerous computer vision tasks owing to its impressive ability in data representation and reconstruction. naturally, it has been successfully applied to the field of multimodal rs data fusion, yielding great improvement compared with traditional methods. this survey aims to present a systematic overview in dl-based multimodal rs data fusion. more specifically, some essential knowledge about this topic is first given. subsequently, a literature survey is conducted to analyse the trends of this field. some prevalent sub-fields in the multimodal rs data fusion are then reviewed in terms of the to-be-fused data modalities, i.e., spatiospectral, spatiotemporal, light detection and ranging-optical, synthetic aperture radar-optical, and rs-geospatial big data fusion. furthermore, we collect and summarize some valuable resources for the sake of the development in multimodal rs data fusion. finally, the remaining challenges and potential future directions are highlighted."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ,                                                                        ,2022-05-03 ,           ,"['jiaxin li', 'danfeng hong', 'lianru gao', 'jing yao', 'ke zheng', 'bing zhang', 'jocelyn chanussot']"
2205.01385 ,smooth over-parameterized solvers for non-smooth structured optimization                                                                                                                ,math.oc cs.lg stat.ml                                    ,"non-smooth optimization is a core ingredient of many imaging or machine learning pipelines. non-smoothness encodes structural constraints on the solutions, such as sparsity, group sparsity, low-rank and sharp edges. it is also the basis for the definition of robust loss functions and scale-free functionals such as square-root lasso. standard approaches to deal with non-smoothness leverage either proximal splitting or coordinate descent. these approaches are effective but usually require parameter tuning, preconditioning or some sort of support pruning. in this work, we advocate and study a different route, which operates a non-convex but smooth over-parametrization of the underlying non-smooth optimization problems. this generalizes quadratic variational forms that are at the heart of the popular iterative reweighted least squares (irls). our main theoretical contribution connects gradient descent on this reformulation to a mirror descent flow with a varying hessian metric. this analysis is crucial to derive convergence bounds that are dimension-free. this explains the efficiency of the method when using small grid sizes in imaging. our main algorithmic contribution is to apply the variable projection (varpro) method which defines a new formulation by explicitly minimizing over part of the variables. this leads to a better conditioning of the minimized functional and improves the convergence of simple but very efficient gradient-based methods, for instance quasi-newton solvers. we exemplify the use of this new solver for the resolution of regularized regression problems for inverse problems and supervised learning, including total variation prior and non-convex regularizers."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,                                                                        ,2022-05-03 ,           ,"['clarice poon', 'gabriel peyré']"
2205.01419 ,an empirical analysis of the use of real-time reachability for the   safety assurance of autonomous vehicles                                                                            ,cs.ro cs.cv cs.fl cs.lg cs.sy eess.sy                    ,"recent advances in machine learning technologies and sensing have paved the way for the belief that safe, accessible, and convenient autonomous vehicles may be realized in the near future. despite tremendous advances within this context, fundamental challenges around safety and reliability are limiting their arrival and comprehensive adoption. autonomous vehicles are often tasked with operating in dynamic and uncertain environments. as a result, they often make use of highly complex components, such as machine learning approaches, to handle the nuances of sensing, actuation, and control. while these methods are highly effective, they are notoriously difficult to assure. moreover, within uncertain and dynamic environments, design time assurance analyses may not be sufficient to guarantee safety. thus, it is critical to monitor the correctness of these systems at runtime. one approach for providing runtime assurance of systems with components that may not be amenable to formal analysis is the simplex architecture, where an unverified component is wrapped with a safety controller and a switching logic designed to prevent dangerous behavior. in this paper, we propose using a real-time reachability algorithm for the implementation of the simplex architecture to assure the safety of a 1/10 scale open source autonomous vehicle platform known as f1/10. the reachability algorithm that we leverage (a) provides provable guarantees of safety, and (b) is used to detect potentially unsafe scenarios. in our approach, the need to analyze an underlying controller is abstracted away, instead focusing on the effects of the controller's decisions on the system's future states. we demonstrate the efficacy of our architecture through a vast set of experiments conducted both in simulation and on an embedded hardware platform."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2022-05-03 ,           ,"['patrick musau', 'nathaniel hamilton', 'diego manzanas lopez', 'preston robinette', 'taylor t. johnson']"
2205.01445 ,high-dimensional asymptotics of feature learning: how one gradient step   improves the representation                                                                                   ,stat.ml cs.lg math.st stat.th                            ,"we study the first gradient descent step on the first-layer parameters $\boldsymbol{w}$ in a two-layer neural network: $f(\boldsymbol{x}) = \frac{1}{\sqrt{n}}\boldsymbol{a}^\top\sigma(\boldsymbol{w}^\top\boldsymbol{x})$, where $\boldsymbol{w}\in\mathbb{r}^{d\times n}, \boldsymbol{a}\in\mathbb{r}^{n}$ are randomly initialized, and the training objective is the empirical mse loss: $\frac{1}{n}\sum_{i=1}^n (f(\boldsymbol{x}_i)-y_i)^2$. in the proportional asymptotic limit where $n,d,n\to\infty$ at the same rate, and an idealized student-teacher setting, we show that the first gradient update contains a rank-1 ""spike"", which results in an alignment between the first-layer weights and the linear component of the teacher model $f^*$. to characterize the impact of this alignment, we compute the prediction risk of ridge regression on the conjugate kernel after one gradient step on $\boldsymbol{w}$ with learning rate $\eta$, when $f^*$ is a single-index model. we consider two scalings of the first step learning rate $\eta$. for small $\eta$, we establish a gaussian equivalence property for the trained feature map, and prove that the learned kernel improves upon the initial random features model, but cannot defeat the best linear model on the input. whereas for sufficiently large $\eta$, we prove that for certain $f^*$, the same ridge estimator on trained features can go beyond this ""linear regime"" and outperform a wide range of random features and rotationally invariant kernels. our results demonstrate that even one gradient step can lead to a considerable advantage over random features, and highlight the role of learning rate scaling in the initial phase of training."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,                                                                        ,2022-05-03 ,           ,"['jimmy ba', 'murat a. erdogdu', 'taiji suzuki', 'zhichao wang', 'denny wu', 'greg yang']"
2205.01457 ,efficient implementation of incremental proximal-point methods                                                                                                                          ,cs.lg math.oc                                            ,"model training algorithms which observe a small portion of the training set in each computational step are ubiquitous in practical machine learning, and include both stochastic and online optimization methods. in the vast majority of cases, such algorithms typically observe the training samples via the gradients of the cost functions the samples incur. thus, these methods exploit are the \emph{slope} of the cost functions via their first-order approximations.   to address limitations of gradient-based methods, such as sensitivity to step-size choice in the stochastic setting, or inability to exploit small function variability in the online setting, several streams of research attempt to exploit more information about the cost functions than just their gradients via the well-known proximal framework of optimization. however, implementing such methods in practice poses a challenge, since each iteration step boils down to computing a proximal operator, which may not be easy. in this work we provide efficient algorithms and corresponding implementations of proximal operators in order to make experimentation with incremental proximal optimization algorithms accessible to a larger audience of researchers and practitioners, and in particular to promote additional theoretical research into these methods by closing the gap between their theoretical description in research papers and their use in practice. the corresponding code is published at https://github.com/alexshtf/inc_prox_pt."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,                                                                        ,2022-05-03 ,           ,['alex shtoff']
2205.01469 ,on the convergence of fictitious play: a decomposition approach                                                                                                                         ,cs.gt cs.ai cs.lg cs.ma                                  ,"fictitious play (fp) is one of the most fundamental game-theoretical learning frameworks for computing nash equilibrium in $n$-player games, which builds the foundation for modern multi-agent learning algorithms. although fp has provable convergence guarantees on zero-sum games and potential games, many real-world problems are often a mixture of both and the convergence property of fp has not been fully studied yet. in this paper, we extend the convergence results of fp to the combinations of such games and beyond. specifically, we derive new conditions for fp to converge by leveraging game decomposition techniques. we further develop a linear relationship unifying cooperation and competition in the sense that these two classes of games are mutually transferable. finally, we analyze a non-convergent example of fp, the shapley game, and develop sufficient conditions for fp to converge."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,                                                                        ,2022-05-03 ,           ,"['yurong chen', 'xiaotie deng', 'chenchen li', 'david mguni', 'jun wang', 'xiang yan', 'yaodong yang']"
2205.01470 ,revisiting communication-efficient federated learning with balanced   global and local updates                                                                                          ,cs.lg cs.dc eess.sp                                      ,"in federated learning (fl), a number of devices train their local models and upload the corresponding parameters or gradients to the base station (bs) to update the global model while protecting their data privacy. however, due to the limited computation and communication resources, the number of local trainings (a.k.a. local update) and that of aggregations (a.k.a. global update) need to be carefully chosen. in this paper, we investigate and analyze the optimal trade-off between the number of local trainings and that of global aggregations to speed up the convergence and enhance the prediction accuracy over the existing works. our goal is to minimize the global loss function under both the delay and the energy consumption constraints. in order to make the optimization problem tractable, we derive a new and tight upper bound on the loss function, which allows us to obtain closed-form expressions for the number of local trainings and that of global aggregations. simulation results show that our proposed scheme can achieve a better performance in terms of the prediction accuracy, and converge much faster than the baseline schemes."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2022-05-03 ,           ,"['zhigang yan', 'dong li', 'zhichao zhang', 'jiguang he']"
2205.01486 ,scalable regularised joint mixture models                                                                                                                                               ,stat.ml cs.lg stat.me                                    ,"in many applications, data can be heterogeneous in the sense of spanning latent groups with different underlying distributions. when predictive models are applied to such data the heterogeneity can affect both predictive performance and interpretability. building on developments at the intersection of unsupervised learning and regularised regression, we propose an approach for heterogeneous data that allows joint learning of (i) explicit multivariate feature distributions, (ii) high-dimensional regression models and (iii) latent group labels, with both (i) and (ii) specific to latent groups and both elements informing (iii). the approach is demonstrably effective in high dimensions, combining data reduction for computational efficiency with a re-weighting scheme that retains key signals even when the number of features is large. we discuss in detail these aspects and their impact on modelling and computation, including em convergence. the approach is modular and allows incorporation of data reductions and high-dimensional estimators that are suitable for specific applications. we show results from extensive simulations and real data experiments, including highly non-gaussian data. our results allow efficient, effective analysis of high-dimensional data in settings, such as biomedicine, where both interpretable prediction and explicit feature space models are needed but hidden heterogeneity may be a concern."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ,                                                                        ,2022-05-03 ,           ,"['thomas lartigue', 'sach mukherjee']"
2205.01492 ,a unified view on self-organizing maps (soms) and stochastic neighbor   embedding (sne)                                                                                                 ,cs.lg cs.ne stat.ml                                      ,"we propose a unified view on two widely used data visualization techniques: self-organizing maps (soms) and stochastic neighbor embedding (sne). we show that they can both be derived from a common mathematical framework. leveraging this formulation, we propose to compare som and sne quantitatively on two datasets, and discuss possible avenues for future work to take advantage of both approaches."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,                                                                        ,2022-05-03 ,           ,"['thibaut kulak', 'anthony fillion', 'françois blayo']"
2205.01508 ,compact neural networks via stacking designed basic units                                                                                                                               ,cs.cv cs.ai cs.lg                                        ,"unstructured pruning has the limitation of dealing with the sparse and irregular weights. by contrast, structured pruning can help eliminate this drawback but it requires complex criterion to determine which components to be pruned. to this end, this paper presents a new method termed tissuenet, which directly constructs compact neural networks with fewer weight parameters by independently stacking designed basic units, without requiring additional judgement criteria anymore. given the basic units of various architectures, they are combined and stacked in a certain form to build up compact neural networks. we formulate tissuenet in diverse popular backbones for comparison with the state-of-the-art pruning methods on different benchmark datasets. moreover, two new metrics are proposed to evaluate compression performance. experiment results show that tissuenet can achieve comparable classification accuracy while saving up to around 80% flops and 89.7% parameters. that is, stacking basic units provides a new promising way for network compression."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ,                                                                        ,2022-05-03 ,           ,"['weichao lan', 'yiu-ming cheung', 'juyong jiang']"
2205.01510 ,exsplinet: an interpretable and expressive spline-based neural network                                                                                                                  ,cs.lg cs.na math.na                                      ,"in this paper we present exsplinet, an interpretable and expressive neural network model. the model combines ideas of kolmogorov neural networks, ensembles of probabilistic trees, and multivariate b-spline representations. we give a probabilistic interpretation of the model and show its universal approximation properties. we also discuss how it can be efficiently encoded by exploiting b-spline properties. finally, we test the effectiveness of the proposed model on synthetic approximation problems and classical machine learning benchmark datasets."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2022-05-03 ,           ,"['daniele fakhoury', 'emanuele fakhoury', 'hendrik speleers']"
2205.01512 ,fair feature subset selection using multiobjective genetic algorithm                                                                                                                    ,cs.ne cs.cy cs.lg                                        ,"the feature subset selection problem aims at selecting the relevant subset of features to improve the performance of a machine learning (ml) algorithm on training data. some features in data can be inherently noisy, costly to compute, improperly scaled, or correlated to other features, and they can adversely affect the accuracy, cost, and complexity of the induced algorithm. the goal of traditional feature selection approaches has been to remove such irrelevant features. in recent years ml is making a noticeable impact on the decision-making processes of our everyday lives. we want to ensure that these decisions do not reflect biased behavior towards certain groups or individuals based on protected attributes such as age, sex, or race. in this paper, we present a feature subset selection approach that improves both fairness and accuracy objectives and computes pareto-optimal solutions using the nsga-ii algorithm. we use statistical disparity as a fairness metric and f1-score as a metric for model performance. our experiments on the most commonly used fairness benchmark datasets with three different machine learning algorithms show that using the evolutionary algorithm we can effectively explore the trade-off between fairness and accuracy."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2022-04-30 ,           ,"['ayaz ur rehman', 'anas nadeem', 'muhammad zubair malik']"
2205.01556 ,privacy amplification via random participation in federated learning                                                                                                                    ,cs.lg cs.cr                                              ,"running a randomized algorithm on a subsampled dataset instead of the entire dataset amplifies differential privacy guarantees. in this work, in a federated setting, we consider random participation of the clients in addition to subsampling their local datasets. since such random participation of the clients creates correlation among the samples of the same client in their subsampling, we analyze the corresponding privacy amplification via non-uniform subsampling. we show that when the size of the local datasets is small, the privacy guarantees via random participation is close to those of the centralized setting, in which the entire dataset is located in a single host and subsampled. on the other hand, when the local datasets are large, observing the output of the algorithm may disclose the identities of the sampled clients with high confidence. our analysis reveals that, even in this case, privacy guarantees via random participation outperform those via only local subsampling."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,                                                                        ,2022-05-03 ,           ,"['burak hasircioglu', 'deniz gunduz']"
2205.01568 ,raft-msf: self-supervised monocular scene flow using recurrent optimizer                                                                                                                ,cs.cv cs.lg cs.ro                                        ,"learning scene flow from a monocular camera still remains a challenging task due to its ill-posedness as well as lack of annotated data. self-supervised methods demonstrate learning scene flow estimation from unlabeled data, yet their accuracy lags behind (semi-)supervised methods. in this paper, we introduce a self-supervised monocular scene flow method that substantially improves the accuracy over the previous approaches. based on raft, a state-of-the-art optical flow model, we design a new decoder to iteratively update 3d motion fields and disparity maps simultaneously. furthermore, we propose an enhanced upsampling layer and a disparity initialization technique, which overall further improves accuracy up to 7.2%. our method achieves state-of-the-art accuracy among all self-supervised monocular scene flow methods, improving accuracy by 34.2%. our fine-tuned model outperforms the best previous semi-supervised method with 228 times faster runtime. code will be publicly available."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ,                                                                        ,2022-05-03 ,           ,"['bayram bayramli', 'junhwa hur', 'hongtao lu']"
2205.01569 ,pscnn: a 885.86 tops/w programmable sram-based computing-in-memory   processor for keyword spotting                                                                                     ,cs.ar cs.lg eess.as                                      ,"computing-in-memory (cim) has attracted significant attentions in recent years due to its massive parallelism and low power consumption. however, current cim designs suffer from large area overhead of small cim macros and bad programmablity for model execution. this paper proposes a programmable cim processor with a single large sized cim macro instead of multiple smaller ones for power efficient computation and a flexible instruction set to support various binary 1-d convolution neural network (cnn) models in an easy way. furthermore, the proposed architecture adopts the pooling write-back method to support fused or independent convolution/pooling operations to reduce 35.9\% of latency, and the flexible ping-pong feature sram to fit different feature map sizes during layer-by-layer execution.the design fabricated in tsmc 28nm technology achieves 150.8 gops throughput and 885.86 tops/w power efficiency at 10 mhz when executing our binary keyword spotting model, which has higher power efficiency and flexibility than previous designs."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2022-05-02 ,           ,"['shu-hung kuo', 'tian-sheuan chang']"
2205.01570 ,rangeseg: range-aware real time segmentation of 3d lidar point clouds                                                                                                                   ,cs.cv cs.lg                                              ,"semantic outdoor scene understanding based on 3d lidar point clouds is a challenging task for autonomous driving due to the sparse and irregular data structure. this paper takes advantages of the uneven range distribution of different lidar laser beams to propose a range aware instance segmentation network, rangeseg. rangeseg uses a shared encoder backbone with two range dependent decoders. a heavy decoder only computes top of a range image where the far and small objects locate to improve small object detection accuracy, and a light decoder computes whole range image for low computational cost. the results are further clustered by the dbscan method with a resolution weighted distance function to get instance-level segmentation results. experiments on the kitti dataset show that rangeseg outperforms the state-of-the-art semantic segmentation methods with enormous speedup and improves the instance-level segmentation performance on small and far objects. the whole rangeseg pipeline meets the real time requirement on nvidia\textsuperscript{\textregistered} jetson agx xavier with 19 frames per second in average."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,10.1109/tiv.2021.3085827                                                ,2022-05-02 ,           ,"['tzu-hsuan chen', 'tian sheuan chang']"
2205.01571 ,a real time 1280x720 object detection chip with 585mb/s memory traffic                                                                                                                  ,cs.ar cs.cv cs.lg                                        ,"memory bandwidth has become the real-time bottleneck of current deep learning accelerators (dla), particularly for high definition (hd) object detection. under resource constraints, this paper proposes a low memory traffic dla chip with joint hardware and software optimization. to maximize hardware utilization under memory bandwidth, we morph and fuse the object detection model into a group fusion-ready model to reduce intermediate data access. this reduces the yolov2's feature memory traffic from 2.9 gb/s to 0.15 gb/s. to support group fusion, our previous dla based hardware employes a unified buffer with write-masking for simple layer-by-layer processing in a fusion group. when compared to our previous dla with the same pe numbers, the chip implemented in a tsmc 40nm process supports 1280x720@30fps object detection and consumes 7.9x less external dram access energy, from 2607 mj to 327.6 mj."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,10.1109/tvlsi.2022.3149768                                              ,2022-05-02 ,           ,"['kuo-wei chang', 'hsu-tung shih', 'tian-sheuan chang', 'shang-hong tsai', 'chih-chyau yang', 'chien-ming wu', 'chun-ming huang']"
2205.01592 ,conditional $\beta$-vae for de novo molecular generation                                                                                                                                ,q-bio.bm cs.lg q-bio.mn                                  ,"deep learning has significantly advanced and accelerated de novo molecular generation. generative networks, namely variational autoencoders (vaes) can not only randomly generate new molecules, but also alter molecular structures to optimize specific chemical properties which are pivotal for drug-discovery. while vaes have been proposed and researched in the past for pharmaceutical applications, they possess deficiencies which limit their ability to both optimize properties and decode syntactically valid molecules. we present a recurrent, conditional $\beta$-vae which disentangles the latent space to enhance post hoc molecule optimization. we create a mutual information driven training protocol and data augmentations to both increase molecular validity and promote longer sequence generation. we demonstrate the efficacy of our framework on the zinc-250k dataset, achieving sota unconstrained optimization results on the penalized logp (plogp) and qed scores, while also matching current sota results for validity, novelty and uniqueness scores for random generation. we match the current sota on qed for top-3 molecules at 0.948, while setting a new sota for plogp optimization at 104.29, 90.12, 69.68 and demonstrating improved results on the constrained optimization task."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,                                                                        ,2022-05-01 ,           ,"['ryan j richards', 'austen m groener']"
2205.01608 ,local stochastic bilevel optimization with momentum-based variance   reduction                                                                                                          ,cs.lg math.oc                                            ,"bilevel optimization has witnessed notable progress recently with new emerging efficient algorithms and has been applied to many machine learning tasks such as data cleaning, few-shot learning, and neural architecture search. however, little attention has been paid to solve the bilevel problems under distributed setting. federated learning (fl) is an emerging paradigm which solves machine learning tasks over distributed-located data. fl problems are challenging to solve due to the heterogeneity and communication bottleneck. however, it is unclear how these challenges will affect the convergence of bilevel optimization algorithms. in this paper, we study federated bilevel optimization problems. specifically, we first propose the fedbio, a deterministic gradient-based algorithm and we show it requires $o(\epsilon^{-2})$ number of iterations to reach an $\epsilon$-stationary point. then we propose fedbioacc to accelerate fedbio with the momentum-based variance-reduction technique under the stochastic scenario. we show fedbioacc has complexity of $o(\epsilon^{-1.5})$. finally, we validate our proposed algorithms via the important fair federated learning task. more specifically, we define a bilevel-based group fair fl objective. our algorithms show superior performances compared to other baselines in numerical experiments."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,                                                                        ,2022-05-03 ,           ,"['junyi li', 'feihu huang', 'heng huang']"
2205.01625 ,toward robust spiking neural network against adversarial perturbation                                                                                                                   ,cs.ne cs.ai cs.cr cs.lg                                  ,"as spiking neural networks (snns) are deployed increasingly in real-world efficiency critical applications, the security concerns in snns attract more attention. currently, researchers have already demonstrated an snn can be attacked with adversarial examples. how to build a robust snn becomes an urgent issue. recently, many studies apply certified training in artificial neural networks (anns), which can improve the robustness of an nn model promisely. however, existing certifications cannot transfer to snns directly because of the distinct neuron behavior and input formats for snns. in this work, we first design s-ibp and s-crown that tackle the non-linear functions in snns' neuron modeling. then, we formalize the boundaries for both digital and spike inputs. finally, we demonstrate the efficiency of our proposed robust training method in different datasets and model architectures. based on our experiment, we can achieve a maximum $37.7\%$ attack error reduction with $3.7\%$ original accuracy loss. to the best of our knowledge, this is the first analysis on robust training of snns."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,                                                                        ,2022-04-12 ,           ,"['ling liang', 'kaidi xu', 'xing hu', 'lei deng', 'yuan xie']"
2205.01639 ,dynamic and context-dependent stock price prediction using attention   modules and news sentiment                                                                                       ,q-fin.cp cs.lg                                           ,"the growth of machine-readable data in finance, such as alternative data, requires new modeling techniques that can handle non-stationary and non-parametric data. due to the underlying causal dependence and the size and complexity of the data, we propose a new modeling approach for financial time series data, the $\alpha_{t}$-rim (recurrent independent mechanism). this architecture makes use of key-value attention to integrate top-down and bottom-up information in a context-dependent and dynamic way. to model the data in such a dynamic manner, the $\alpha_{t}$-rim utilizes an exponentially smoothed recurrent neural network, which can model non-stationary times series data, combined with a modular and independent recurrent structure. we apply our approach to the closing prices of three selected stocks of the s\&p 500 universe as well as their news sentiment score. the results suggest that the $\alpha_{t}$-rim is capable of reflecting the causal structure between stock prices and news sentiment, as well as the seasonality and trends. consequently, this modeling approach markedly improves the generalization performance, that is, the prediction of unseen data, and outperforms state-of-the-art networks such as long short-term memory models."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,                                                                        ,2022-03-13 ,           ,['nicole koenigstein']
2205.01671 ,the scope for ai-augmented interpretation of building blueprints in   commercial and industrial property insurance                                                                      ,cs.cv cs.ai cs.lg eess.iv                                ,"this report, commissioned by the wtw research network, investigates the use of ai in property risk assessment. it (i) reviews existing work on risk assessment in commercial and industrial properties and automated information extraction from building blueprints; and (ii) presents an exploratory 'proof-of concept-solution' exploring the feasibility of using machine learning for the automated extraction of information from building blueprints to support insurance risk assessment."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,                                                                        ,2022-04-29 ,2022-05-05 ,"['long chen', 'mao ye', 'alistair milne', 'john hillier', 'frances oglesby']"
2205.01672 ,branch & learn for recursively and iteratively solvable problems in   predict+optimize                                                                                                  ,cs.lg cs.ai math.oc                                      ,"this paper proposes branch & learn, a framework for predict+optimize to tackle optimization problems containing parameters that are unknown at the time of solving. given an optimization problem solvable by a recursive algorithm satisfying simple conditions, we show how a corresponding learning algorithm can be constructed directly and methodically from the recursive algorithm. our framework applies also to iterative algorithms by viewing them as a degenerate form of recursion. extensive experimentation shows better performance for our proposal over classical and state-of-the-art approaches."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,                                                                        ,2022-05-01 ,           ,"['xinyi hu', 'jasper c. h. lee', 'jimmy h. m. lee', 'allen z. zhong']"
2205.01673 ,a deep learning-based integrated framework for quality-aware   undersampled cine cardiac mri reconstruction and analysis                                                                ,eess.iv cs.cv cs.lg                                      ,"cine cardiac magnetic resonance (cmr) imaging is considered the gold standard for cardiac function evaluation. however, cine cmr acquisition is inherently slow and in recent decades considerable effort has been put into accelerating scan times without compromising image quality or the accuracy of derived results. in this paper, we present a fully-automated, quality-controlled integrated framework for reconstruction, segmentation and downstream analysis of undersampled cine cmr data. the framework enables active acquisition of radial k-space data, in which acquisition can be stopped as soon as acquired data are sufficient to produce high quality reconstructions and segmentations. this results in reduced scan times and automated analysis, enabling robust and accurate estimation of functional biomarkers. to demonstrate the feasibility of the proposed approach, we perform realistic simulations of radial k-space acquisitions on a dataset of subjects from the uk biobank and present results on in-vivo cine cmr k-space data collected from healthy subjects. the results demonstrate that our method can produce quality-controlled images in a mean scan time reduced from 12 to 4 seconds per slice, and that image quality is sufficient to allow clinically relevant parameters to be automatically estimated to within 5% mean absolute difference."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,                                                                        ,2022-05-02 ,           ,"['inês p. machado', 'esther puyol-antón', 'kerstin hammernik', 'gastão cruz', 'devran ugurlu', 'ihsane olakorede', 'ilkay oksuz', 'bram ruijsink', 'miguel castelo-branco', 'alistair a. young', 'claudia prieto', 'julia a. schnabel', 'andrew p. king']"
2205.01685 ,deep sequence modeling for anomalous isp traffic prediction                                                                                                                             ,cs.lg cs.ni eess.sp                                      ,"internet traffic in the real world is susceptible to various external and internal factors which may abruptly change the normal traffic flow. those unexpected changes are considered outliers in traffic. however, deep sequence models have been used to predict complex ip traffic, but their comparative performance for anomalous traffic has not been studied extensively. in this paper, we investigated and evaluated the performance of different deep sequence models for anomalous traffic prediction. several deep sequences models were implemented to predict real traffic without and with outliers and show the significance of outlier detection in real-world traffic prediction. first, two different outlier detection techniques, such as the three-sigma rule and isolation forest, were applied to identify the anomaly. second, we adjusted those abnormal data points using the backward filling technique before training the model. finally, the performance of different models was compared for abnormal and adjusted traffic. lstm_encoder_decoder (lstm_en_de) is the best prediction model in our experiment, reducing the deviation between actual and predicted traffic by more than 11\% after adjusting the outliers. all other models, including recurrent neural network (rnn), long short-term memory (lstm), lstm_en_de with attention layer (lstm_en_de_atn), gated recurrent unit (gru), show better prediction after replacing the outliers and decreasing prediction error by more than 29%, 24%, 19%, and 10% respectively. our experimental results indicate that the outliers in the data can significantly impact the quality of the prediction. thus, outlier detection and mitigation assist the deep sequence model in learning the general trend and making better predictions."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ,                                                                        ,2022-05-03 ,           ,"['sajal saha', 'anwar haque', 'greg sidebottom']"
2205.01707 ,memse: fast mse prediction for noisy memristor-based dnn accelerators                                                                                                                   ,cs.lg cs.et cs.ne                                        ,"memristors enable the computation of matrix-vector multiplications (mvm) in memory and, therefore, show great potential in highly increasing the energy efficiency of deep neural network (dnn) inference accelerators. however, computations in memristors suffer from hardware non-idealities and are subject to different sources of noise that may negatively impact system performance. in this work, we theoretically analyze the mean squared error of dnns that use memristor crossbars to compute mvm. we take into account both the quantization noise, due to the necessity of reducing the dnn model size, and the programming noise, stemming from the variability during the programming of the memristance value. simulations on pre-trained dnn models showcase the accuracy of the analytical prediction. furthermore the proposed method is almost two order of magnitude faster than monte-carlo simulation, thus making it possible to optimize the implementation parameters to achieve minimal error for a given power constraint."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2022-05-03 ,           ,"['jonathan kern', 'sébastien henwood', 'gonçalo mordido', 'elsa dupraz', 'abdeldjalil aïssa-el-bey', 'yvon savaria', 'françois leduc-primeau']"
2205.01714 ,"don't sweat the small stuff, classify the rest: sample shielding to   protect text classifiers against adversarial attacks"                                                            ,cs.cl cs.cr cs.lg                                        ,"deep learning (dl) is being used extensively for text classification. however, researchers have demonstrated the vulnerability of such classifiers to adversarial attacks. attackers modify the text in a way which misleads the classifier while keeping the original meaning close to intact. state-of-the-art (sota) attack algorithms follow the general principle of making minimal changes to the text so as to not jeopardize semantics. taking advantage of this we propose a novel and intuitive defense strategy called sample shielding. it is attacker and classifier agnostic, does not require any reconfiguration of the classifier or external resources and is simple to implement. essentially, we sample subsets of the input text, classify them and summarize these into a final decision. we shield three popular dl text classifiers with sample shielding, test their resilience against four sota attackers across three datasets in a realistic threat setting. even when given the advantage of knowing about our shielding strategy the adversary's attack success rate is <=10% with only one exception and often < 5%. additionally, sample shielding maintains near original accuracy when applied to original texts. crucially, we show that the `make minimal changes' approach of sota attackers leads to critical vulnerabilities that can be defended against with an intuitive sampling strategy."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ,                                                                        ,2022-05-03 ,           ,"['jonathan rusert', 'padmini srinivasan']"
2205.01729 ,pre-rtl dnn hardware evaluator with fused layer support                                                                                                                                 ,cs.ar cs.lg                                              ,"with the popularity of the deep neural network (dnn), hardware accelerators are demanded for real time execution. however, lengthy design process and fast evolving dnn models make hardware evaluation hard to meet the time to market need. this paper proposes a pre-rtl dnn hardware evaluator that supports conventional layer-by-layer processing as well as the fused layer processing for low external bandwidth requirement. the evaluator supports two state-of-the-art accelerator architectures and finds the best hardware and layer fusion group the experimental results show the layer fusion scheme can achieve 55.6% memory bandwidth reduction, 36.7% latency improvement and 49.2% energy reduction compared with layer-by-layer operation."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ,10.1109/isocc53507.2021.9614027                                         ,2022-05-02 ,           ,"['chih-chyau yang', 'tian-sheuan chang']"
2205.01753 ,self-focusing virtual screening with active design space pruning                                                                                                                        ,q-bio.qm cs.lg                                           ,"high-throughput virtual screening is an indispensable technique utilized in the discovery of small molecules. in cases where the library of molecules is exceedingly large, the cost of an exhaustive virtual screen may be prohibitive. model-guided optimization has been employed to lower these costs through dramatic increases in sample efficiency compared to random selection. however, these techniques introduce new costs to the workflow through the surrogate model training and inference steps. in this study, we propose an extension to the framework of model-guided optimization that mitigates inferences costs using a technique we refer to as design space pruning (dsp), which irreversibly removes poor-performing candidates from consideration. we study the application of dsp to a variety of optimization tasks and observe significant reductions in overhead costs while exhibiting similar performance to the baseline optimization. dsp represents an attractive extension of model-guided optimization that can limit overhead costs in optimization settings where these costs are non-negligible relative to objective costs, such as docking."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,                                                                        ,2022-05-03 ,           ,"['david e. graff', 'matteo aldeghi', 'joseph a. morrone', 'kirk e. jordan', 'edward o. pyzer-knapp', 'connor w. coley']"
2205.01757 ,xltime: a cross-lingual knowledge transfer framework for temporal   expression extraction                                                                                               ,cs.cl cs.lg                                              ,"temporal expression extraction (tee) is essential for understanding time in natural language. it has applications in natural language processing (nlp) tasks such as question answering, information retrieval, and causal inference. to date, work in this area has mostly focused on english as there is a scarcity of labeled data for other languages. we propose xltime, a novel framework for multilingual tee. xltime works on top of pre-trained language models and leverages multi-task learning to prompt cross-language knowledge transfer both from english and within the non-english languages. xltime alleviates problems caused by a shortage of data in the target language. we apply xltime with different language models and show that it outperforms the previous automatic sota methods on french, spanish, portuguese, and basque, by large margins. xltime also closes the gap considerably on the handcrafted heideltime method."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2022-05-03 ,           ,"['yuwei cao', 'william groves', 'tanay kumar saha', 'joel r. tetreault', 'alex jaimes', 'hao peng', 'philip s. yu']"
2205.01758 ,differentiable simulation of soft multi-body systems                                                                                                                                    ,cs.lg cs.gr cs.ro                                        ,"we present a method for differentiable simulation of soft articulated bodies. our work enables the integration of differentiable physical dynamics into gradient-based pipelines. we develop a top-down matrix assembly algorithm within projective dynamics and derive a generalized dry friction model for soft continuum using a new matrix splitting strategy. we derive a differentiable control framework for soft articulated bodies driven by muscles, joint torques, or pneumatic tubes. the experiments demonstrate that our designs make soft body simulation more stable and realistic compared to other frameworks. our method accelerates the solution of system identification problems by more than an order of magnitude, and enables efficient gradient-based learning of motion control with soft robots."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,                                                                        ,2022-05-03 ,           ,"['yi-ling qiao', 'junbang liang', 'vladlen koltun', 'ming c. lin']"
2205.01794 ,meta-cognition. an inverse-inverse reinforcement learning approach for   cognitive radars                                                                                               ,eess.sp cs.lg                                            ,"this paper considers meta-cognitive radars in an adversarial setting. a cognitive radar optimally adapts its waveform (response) in response to maneuvers (probes) of a possibly adversarial moving target. a meta-cognitive radar is aware of the adversarial nature of the target and seeks to mitigate the adversarial target. how should the meta-cognitive radar choose its responses to sufficiently confuse the adversary trying to estimate the radar's utility function? this paper abstracts the radar's meta-cognition problem in terms of the spectra (eigenvalues) of the state and observation noise covariance matrices, and embeds the algebraic riccati equation into an economics-based utility maximization setup. this adversarial target is an inverse reinforcement learner. by observing a noisy sequence of radar's responses (waveforms), the adversarial target uses a statistical hypothesis test to detect if the radar is a utility maximizer. in turn, the meta-cognitive radar deliberately chooses sub-optimal responses that increasing its type-i error probability of the adversary's detector. we call this counter-adversarial step taken by the meta-cognitive radar as inverse inverse reinforcement learning (i-irl). we illustrate the meta-cognition results of this paper via simple numerical examples. our approach for meta-cognition in this paper is based on revealed preference theory in micro-economics and inspired by results in differential privacy and adversarial obfuscation in machine learning."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,                                                                        ,2022-05-03 ,           ,"['kunal pattanayak', 'vikram krishnamurthy', 'christopher berry']"
2205.01800 ,synthesized speech detection using convolutional transformer-based   spectrogram analysis                                                                                               ,cs.sd cs.cv cs.lg eess.as                                ,"synthesized speech is common today due to the prevalence of virtual assistants, easy-to-use tools for generating and modifying speech signals, and remote work practices. synthesized speech can also be used for nefarious purposes, including creating a purported speech signal and attributing it to someone who did not speak the content of the signal. we need methods to detect if a speech signal is synthesized. in this paper, we analyze speech signals in the form of spectrograms with a compact convolutional transformer (cct) for synthesized speech detection. a cct utilizes a convolutional layer that introduces inductive biases and shared weights into a network, allowing a transformer architecture to perform well with fewer data samples used for training. the cct uses an attention mechanism to incorporate information from all parts of a signal under analysis. trained on both genuine human voice signals and synthesized human voice signals, we demonstrate that our cct approach successfully differentiates between genuine and synthesized speech signals."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,10.1109/ieeeconf53345.2021.9723142                                      ,2022-05-03 ,           ,"['emily r. bartusiak', 'edward j. delp']"
2205.01805 ,splicing detection and localization in satellite imagery using   conditional gans                                                                                                       ,cs.cv cs.lg eess.iv                                      ,"the widespread availability of image editing tools and improvements in image processing techniques allow image manipulation to be very easy. oftentimes, easy-to-use yet sophisticated image manipulation tools yields distortions/changes imperceptible to the human observer. distribution of forged images can have drastic ramifications, especially when coupled with the speed and vastness of the internet. therefore, verifying image integrity poses an immense and important challenge to the digital forensic community. satellite images specifically can be modified in a number of ways, including the insertion of objects to hide existing scenes and structures. in this paper, we describe the use of a conditional generative adversarial network (cgan) to identify the presence of such spliced forgeries within satellite images. additionally, we identify their locations and shapes. trained on pristine and falsified images, our method achieves high success on these detection and localization objectives."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,10.1109/mipr.2019.00024                                                 ,2022-05-03 ,           ,"['emily r. bartusiak', 'sri kalyan yarlagadda', 'david güera', 'paolo bestagini', 'stefano tubaro', 'fengqing m. zhu', 'edward j. delp']"
2205.01806 ,frequency domain-based detection of generated audio                                                                                                                                     ,cs.sd cs.cv cs.lg eess.as                                ,"attackers may manipulate audio with the intent of presenting falsified reports, changing an opinion of a public figure, and winning influence and power. the prevalence of inauthentic multimedia continues to rise, so it is imperative to develop a set of tools that determines the legitimacy of media. we present a method that analyzes audio signals to determine whether they contain real human voices or fake human voices (i.e., voices generated by neural acoustic and waveform models). instead of analyzing the audio signals directly, the proposed approach converts the audio signals into spectrogram images displaying frequency, intensity, and temporal content and evaluates them with a convolutional neural network (cnn). trained on both genuine human voice signals and synthesized voice signals, we show our approach achieves high accuracy on this classification task."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,                                                                        ,2022-05-03 ,           ,"['emily r. bartusiak', 'edward j. delp']"
2205.01811 ,assessing dataset bias in computer vision                                                                                                                                               ,cs.cv cs.lg                                              ,"a biased dataset is a dataset that generally has attributes with an uneven class distribution. these biases have the tendency to propagate to the models that train on them, often leading to a poor performance in the minority class. in this project, we will explore the extent to which various data augmentation methods alleviate intrinsic biases within the dataset. we will apply several augmentation techniques on a sample of the utkface dataset, such as undersampling, geometric transformations, variational autoencoders (vaes), and generative adversarial networks (gans). we then trained a classifier for each of the augmented datasets and evaluated their performance on the native test set and on external facial recognition datasets. we have also compared their performance to the state-of-the-art attribute classifier trained on the fairface dataset. through experimentation, we were able to find that training the model on stargan-generated images led to the best overall performance. we also found that training on geometrically transformed images lead to a similar performance with a much quicker training time. additionally, the best performing models also exhibit a uniform performance across the classes within each attribute. this signifies that the model was also able to mitigate the biases present in the baseline model that was trained on the original training set. finally, we were able to show that our model has a better overall performance and consistency on age and ethnicity classification on multiple datasets when compared with the fairface model. our final model has an accuracy on the utkface test set of 91.75%, 91.30%, and 87.20% for the gender, age, and ethnicity attribute respectively, with a standard deviation of less than 0.1 between the accuracies of the classes of each attribute."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ,10.13140/rg.2.2.19950.89924                                             ,2022-05-03 ,           ,['athiya deviyani']
2205.01813 ,diverse image captioning with grounded style                                                                                                                                            ,cs.cv cs.lg                                              ,"stylized image captioning as presented in prior work aims to generate captions that reflect characteristics beyond a factual description of the scene composition, such as sentiments. such prior work relies on given sentiment identifiers, which are used to express a certain global style in the caption, e.g. positive or negative, however without taking into account the stylistic content of the visual scene. to address this shortcoming, we first analyze the limitations of current stylized captioning datasets and propose coco attribute-based augmentations to obtain varied stylized captions from coco annotations. furthermore, we encode the stylized information in the latent space of a variational autoencoder; specifically, we leverage extracted image attributes to explicitly structure its sequential latent space according to different localized style characteristics. our experiments on the senticap and coco datasets show the ability of our approach to generate accurate captions with diversity in styles that are grounded in the image."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,                                                                        ,2022-05-03 ,           ,"['franz klein', 'shweta mahajan', 'stefan roth']"
2205.01818 ,i-code: an integrative and composable multimodal learning framework                                                                                                                     ,cs.lg cs.ai cs.cl cs.cv eess.as                          ,"human intelligence is multimodal; we integrate visual, linguistic, and acoustic signals to maintain a holistic worldview. most current pretraining methods, however, are limited to one or two modalities. we present i-code, a self-supervised pretraining framework where users may flexibly combine the modalities of vision, speech, and language into unified and general-purpose vector representations. in this framework, data from each modality are first given to pretrained single-modality encoders. the encoder outputs are then integrated with a multimodal fusion network, which uses novel attention mechanisms and other architectural innovations to effectively combine information from the different modalities. the entire system is pretrained end-to-end with new objectives including masked modality unit modeling and cross-modality contrastive learning. unlike previous research using only video for pretraining, the i-code framework can dynamically process single, dual, and triple-modality data during training and inference, flexibly projecting different combinations of modalities into a single representation space. experimental results demonstrate how i-code can outperform state-of-the-art techniques on five video understanding tasks and the glue nlp benchmark, improving by as much as 11% and demonstrating the power of integrative multimodal pretraining."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ,                                                                        ,2022-05-03 ,2022-05-05 ,"['ziyi yang', 'yuwei fang', 'chenguang zhu', 'reid pryzant', 'dongdong chen', 'yu shi', 'yichong xu', 'yao qian', 'mei gao', 'yi-ling chen', 'liyang lu', 'yujia xie', 'robert gmyr', 'noel codella', 'naoyuki kanda', 'bin xiao', 'lu yuan', 'takuya yoshioka', 'michael zeng', 'xuedong huang']"
2205.01821 ,zero-shot sonnet generation with discourse-level planning and aesthetics   features                                                                                                     ,cs.cl cs.ai cs.lg                                        ,"poetry generation, and creative language generation in general, usually suffers from the lack of large training data. in this paper, we present a novel framework to generate sonnets that does not require training on poems. we design a hierarchical framework which plans the poem sketch before decoding. specifically, a content planning module is trained on non-poetic texts to obtain discourse-level coherence; then a rhyme module generates rhyme words and a polishing module introduces imagery and similes for aesthetics purposes. finally, we design a constrained decoding algorithm to impose the meter-and-rhyme constraint of the generated sonnets. automatic and human evaluation show that our multi-stage approach without training on poem corpora generates more coherent, poetic, and creative sonnets than several strong baselines."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,                                                                        ,2022-05-03 ,           ,"['yufei tian', 'nanyun peng']"
2205.01825 ,ambipun: generating humorous puns with ambiguous context                                                                                                                                ,cs.cl cs.ai cs.lg                                        ,"in this paper, we propose a simple yet effective way to generate pun sentences that does not require any training on existing puns. our approach is inspired by humor theories that ambiguity comes from the context rather than the pun word itself. given a pair of definitions of a pun word, our model first produces a list of related concepts through a reverse dictionary. we then utilize one-shot gpt3 to generate context words and then generate puns incorporating context words from both concepts. human evaluation shows that our method successfully generates pun 52\% of the time, outperforming well-crafted baselines and the state-of-the-art models by a large margin."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ,                                                                        ,2022-05-03 ,           ,"['anirudh mittal', 'yufei tian', 'nanyun peng']"
2205.01853 ,smlt: a serverless framework for scalable and adaptive machine learning   design and training                                                                                           ,cs.dc cs.lg                                              ,"in today's production machine learning (ml) systems, models are continuously trained, improved, and deployed. ml design and training are becoming a continuous workflow of various tasks that have dynamic resource demands. serverless computing is an emerging cloud paradigm that provides transparent resource management and scaling for users and has the potential to revolutionize the routine of ml design and training. however, hosting modern ml workflows on existing serverless platforms has non-trivial challenges due to their intrinsic design limitations such as stateless nature, limited communication support across function instances, and limited function execution duration. these limitations result in a lack of an overarching view and adaptation mechanism for training dynamics and an amplification of existing problems in ml workflows.   to address the above challenges, we propose smlt, an automated, scalable, and adaptive serverless framework to enable efficient and user-centric ml design and training. smlt employs an automated and adaptive scheduling mechanism to dynamically optimize the deployment and resource scaling for ml tasks during training. smlt further enables user-centric ml workflow execution by supporting user-specified training deadlines and budget limits. in addition, by providing an end-to-end design, smlt solves the intrinsic problems in serverless platforms such as the communication overhead, limited function execution duration, need for repeated initialization, and also provides explicit fault tolerance for ml training. smlt is open-sourced and compatible with all major ml frameworks. our experimental evaluation with large, sophisticated modern ml models demonstrate that smlt outperforms the state-of-the-art vm based systems and existing serverless ml training frameworks in both training speed (up to 8x) and monetary cost (up to 3x)"                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ,                                                                        ,2022-05-03 ,           ,"['ahsan ali', 'syed zawad', 'paarijaat aditya', 'istemi ekin akkus', 'ruichuan chen', 'feng yan']"
2205.01876 ,fairlib: a unified framework for assessing and improving classification   fairness                                                                                                      ,cs.lg cs.ai cs.cy                                        ,"this paper presents fairlib, an open-source framework for assessing and improving classification fairness. it provides a systematic framework for quickly reproducing existing baseline models, developing new methods, evaluating models with different metrics, and visualizing their results. its modularity and extensibility enable the framework to be used for diverse types of inputs, including natural language, images, and audio. in detail, we implement 14 debiasing methods, including pre-processing, at-training-time, and post-processing approaches. the built-in metrics cover the most commonly used fairness criterion and can be further generalized and customized for fairness evaluation."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ,                                                                        ,2022-05-03 ,           ,"['xudong han', 'aili shen', 'yitong li', 'lea frermann', 'timothy baldwin', 'trevor cohn']"
2205.01893 ,crystal twins: self-supervised learning for crystalline material   property prediction                                                                                                  ,cs.lg cond-mat.mtrl-sci                                  ,"machine learning (ml) models have been widely successful in the prediction of material properties. however, large labeled datasets required for training accurate ml models are elusive and computationally expensive to generate. recent advances in self-supervised learning (ssl) frameworks capable of training ml models on unlabeled data have mitigated this problem and demonstrated superior performance in computer vision and natural language processing tasks. drawing inspiration from the developments in ssl, we introduce crystal twins (ct): an ssl method for crystalline materials property prediction. using a large unlabeled dataset, we pre-train a graph neural network (gnn) by applying the redundancy reduction principle to the graph latent embeddings of augmented instances obtained from the same crystalline system. by sharing the pre-trained weights when fine-tuning the gnn for regression tasks, we significantly improve the performance for 7 challenging material property prediction benchmarks"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,                                                                        ,2022-05-04 ,           ,"['rishikesh magar', 'yuyang wang', 'amir barati farimani']"
2205.01903 ,self-taught metric learning without labels                                                                                                                                              ,cs.cv cs.ai cs.lg                                        ,"we present a novel self-taught framework for unsupervised metric learning, which alternates between predicting class-equivalence relations between data through a moving average of an embedding model and learning the model with the predicted relations as pseudo labels. at the heart of our framework lies an algorithm that investigates contexts of data on the embedding space to predict their class-equivalence relations as pseudo labels. the algorithm enables efficient end-to-end training since it demands no off-the-shelf module for pseudo labeling. also, the class-equivalence relations provide rich supervisory signals for learning an embedding space. on standard benchmarks for metric learning, it clearly outperforms existing unsupervised learning methods and sometimes even beats supervised learning models using the same backbone network. it is also applied to semi-supervised metric learning as a way of exploiting additional unlabeled data, and achieves the state of the art by boosting performance of supervised learning substantially."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ,                                                                        ,2022-05-04 ,           ,"['sungyeon kim', 'dongwon kim', 'minsu cho', 'suha kwak']"
2205.01906 ,ase: large-scale reusable adversarial skill embeddings for physically   simulated characters                                                                                            ,cs.gr cs.ai cs.lg                                        ,"the incredible feats of athleticism demonstrated by humans are made possible in part by a vast repertoire of general-purpose motor skills, acquired through years of practice and experience. these skills not only enable humans to perform complex tasks, but also provide powerful priors for guiding their behaviors when learning new tasks. this is in stark contrast to what is common practice in physics-based character animation, where control policies are most typically trained from scratch for each task. in this work, we present a large-scale data-driven framework for learning versatile and reusable skill embeddings for physically simulated characters. our approach combines techniques from adversarial imitation learning and unsupervised reinforcement learning to develop skill embeddings that produce life-like behaviors, while also providing an easy to control representation for use on new downstream tasks. our models can be trained using large datasets of unstructured motion clips, without requiring any task-specific annotation or segmentation of the motion data. by leveraging a massively parallel gpu-based simulator, we are able to train skill embeddings using over a decade of simulated experiences, enabling our model to learn a rich and versatile repertoire of skills. we show that a single pre-trained model can be effectively applied to perform a diverse set of new tasks. our system also allows users to specify tasks through simple reward functions, and the skill embedding then enables the character to automatically synthesize complex and naturalistic strategies in order to achieve the task objectives."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,10.1145/3528223.3530110                                                 ,2022-05-04 ,2022-05-05 ,"['xue bin peng', 'yunrong guo', 'lina halper', 'sergey levine', 'sanja fidler']"
2205.01909 ,modeling task interactions in document-level joint entity and relation   extraction                                                                                                     ,cs.cl cs.lg                                              ,"we target on the document-level relation extraction in an end-to-end setting, where the model needs to jointly perform mention extraction, coreference resolution (coref) and relation extraction (re) at once, and gets evaluated in an entity-centric way. especially, we address the two-way interaction between coref and re that has not been the focus by previous work, and propose to introduce explicit interaction namely graph compatibility (gc) that is specifically designed to leverage task characteristics, bridging decisions of two tasks for direct task interference. our experiments are conducted on docred and dwie; in addition to gc, we implement and compare different multi-task settings commonly adopted in previous work, including pipeline, shared encoders, graph propagation, to examine the effectiveness of different interactions. the result shows that gc achieves the best performance by up to 2.3/5.1 f1 improvement over the baseline."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ,                                                                        ,2022-05-04 ,           ,"['liyan xu', 'jinho d. choi']"
2205.01915 ,generalized knowledge distillation via relationship matching                                                                                                                            ,cs.cv cs.lg                                              ,"the knowledge of a well-trained deep neural network (a.k.a. the ""teacher"") is valuable for learning similar tasks. knowledge distillation extracts knowledge from the teacher and integrates it with the target model (a.k.a. the ""student""), which expands the student's knowledge and improves its learning efficacy. instead of enforcing the teacher to work on the same task as the student, we borrow the knowledge from a teacher trained from a general label space -- in this ""generalized knowledge distillation (gkd)"", the classes of the teacher and the student may be the same, completely different, or partially overlapped. we claim that the comparison ability between instances acts as an essential factor threading knowledge across tasks, and propose the relationship facilitated local classifier distillation (refilled) approach, which decouples the gkd flow of the embedding and the top-layer classifier. in particular, different from reconciling the instance-label confidence between models, refilled requires the teacher to reweight the hard tuples pushed forward by the student and then matches the similarity comparison levels between instances. an embedding-induced classifier based on the teacher model supervises the student's classification confidence and adaptively emphasizes the most related supervision from the teacher. refilled demonstrates strong discriminative ability when the classes of the teacher vary from the same to a fully non-overlapped set w.r.t. the student. it also achieves state-of-the-art performance on standard knowledge distillation, one-step incremental learning, and few-shot learning tasks."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ,                                                                        ,2022-05-04 ,           ,"['han-jia ye', 'su lu', 'de-chuan zhan']"
2205.01924 ,zero-episode few-shot contrastive predictive coding: solving   intelligence tests without prior training                                                                                ,cs.cv cs.lg                                              ,"video prediction models often combine three components: an encoder from pixel space to a small latent space, a latent space prediction model, and a generative model back to pixel space. however, the large and unpredictable pixel space makes training such models difficult, requiring many training examples. we argue that finding a predictive latent variable and using it to evaluate the consistency of a future image enables data-efficient predictions because it precludes the necessity of a generative model training. to demonstrate it, we created sequence completion intelligence tests in which the task is to identify a predictably changing feature in a sequence of images and use this prediction to select the subsequent image. we show that a one-dimensional markov contrastive predictive coding (m-cpc_1d) model solves these tests efficiently, with only five examples. finally, we demonstrate the usefulness of m-cpc_1d in solving two tasks without prior training: anomaly detection and stochastic movement video prediction."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,                                                                        ,2022-05-04 ,           ,"['t. barak', 'y. loewenstein']"
2205.01938 ,deepfd: automated fault diagnosis and localization for deep learning   programs                                                                                                         ,cs.se cs.lg                                              ,"as deep learning (dl) systems are widely deployed for mission-critical applications, debugging such systems becomes essential. most existing works identify and repair suspicious neurons on the trained deep neural network (dnn), which, unfortunately, might be a detour. specifically, several existing studies have reported that many unsatisfactory behaviors are actually originated from the faults residing in dl programs. besides, locating faulty neurons is not actionable for developers, while locating the faulty statements in dl programs can provide developers with more useful information for debugging. though a few recent studies were proposed to pinpoint the faulty statements in dl programs or the training settings (e.g. too large learning rate), they were mainly designed based on predefined rules, leading to many false alarms or false negatives, especially when the faults are beyond their capabilities.   in view of these limitations, in this paper, we proposed deepfd, a learning-based fault diagnosis and localization framework which maps the fault localization task to a learning problem. in particular, it infers the suspicious fault types via monitoring the runtime features extracted during dnn model training and then locates the diagnosed faults in dl programs. it overcomes the limitations by identifying the root causes of faults in dl programs instead of neurons and diagnosing the faults by a learning approach instead of a set of hard-coded rules. the evaluation exhibits the potential of deepfd. it correctly diagnoses 52% faulty dl programs, compared with around half (27%) achieved by the best state-of-the-art works. besides, for fault localization, deepfd also outperforms the existing works, correctly locating 42% faulty programs, which almost doubles the best result (23%) achieved by the existing works."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,10.1145/3510003.3510099                                                 ,2022-05-04 ,           ,"['jialun cao', 'meiziniu li', 'xiao chen', 'ming wen', 'yongqiang tian', 'bo wu', 'shing-chi cheung']"
2205.01954 ,word tour: one-dimensional word embeddings via the traveling salesman   problem                                                                                                         ,cs.cl cs.ai cs.lg                                        ,"word embeddings are one of the most fundamental technologies used in natural language processing. existing word embeddings are high-dimensional and consume considerable computational resources. in this study, we propose wordtour, unsupervised one-dimensional word embeddings. to achieve the challenging goal, we propose a decomposition of the desiderata of word embeddings into two parts, completeness and soundness, and focus on soundness in this paper. owing to the single dimensionality, wordtour is extremely efficient and provides a minimal means to handle word embeddings. we experimentally confirmed the effectiveness of the proposed method via user study and document classification."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ,                                                                        ,2022-05-04 ,           ,['ryoma sato']
2205.01965 ,state representation learning for goal-conditioned reinforcement   learning                                                                                                             ,cs.lg                                                    ,"this paper presents a novel state representation for reward-free markov decision processes. the idea is to learn, in a self-supervised manner, an embedding space where distances between pairs of embedded states correspond to the minimum number of actions needed to transition between them. compared to previous methods, our approach does not require any domain knowledge, learning from offline and unlabeled data. we show how this representation can be leveraged to learn goal-conditioned policies, providing a notion of similarity between states and goals and a useful heuristic distance to guide planning and reinforcement learning algorithms. finally, we empirically validate our method in classic control domains and multi-goal environments, demonstrating that our method can successfully learn representations in large and/or continuous domains."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,                                                                        ,2022-05-04 ,           ,"['lorenzo steccanella', 'anders jonsson']"
2205.01981 ,the isabelle enigma                                                                                                                                                                     ,cs.ai cs.lg cs.lo                                        ,"we significantly improve the performance of the e automated theorem prover on the isabelle sledgehammer problems by combining learning and theorem proving in several ways. in particular, we develop targeted versions of the enigma guidance for the isabelle problems, targeted versions of neural premise selection, and targeted strategies for e. the methods are trained in several iterations over hundreds of thousands untyped and typed first-order problems extracted from isabelle. our final best single-strategy enigma and premise selection system improves the best previous version of e by 25.3% in 15 seconds, outperforming also all other previous atp and smt systems."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,                                                                        ,2022-05-04 ,           ,"['zarathustra a. goertzel', 'jan jakubův', 'cezary kaliszyk', 'miroslav olšák', 'jelle piepenbrock', 'josef urban']"
2205.01996 ,emobank: studying the impact of annotation perspective and   representation format on dimensional emotion analysis                                                                      ,cs.cl cs.ai cs.lg                                        ,"we describe emobank, a corpus of 10k english sentences balancing multiple genres, which we annotated with dimensional emotion metadata in the valence-arousal-dominance (vad) representation format. emobank excels with a bi-perspectival and bi-representational design. on the one hand, we distinguish between writer's and reader's emotions, on the other hand, a subset of the corpus complements dimensional vad annotations with categorical ones based on basic emotions. we find evidence for the supremacy of the reader's perspective in terms of iaa and rating intensity, and achieve close-to-human performance when mapping between dimensional and categorical formats."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ,                                                                        ,2022-05-04 ,           ,"['sven buechel', 'udo hahn']"
2205.02014 ,on continual model refinement in out-of-distribution data streams                                                                                                                       ,cs.cl cs.ai cs.lg                                        ,"real-world natural language processing (nlp) models need to be continually updated to fix the prediction errors in out-of-distribution (ood) data streams while overcoming catastrophic forgetting. however, existing continual learning (cl) problem setups cannot cover such a realistic and complex scenario. in response to this, we propose a new cl problem formulation dubbed continual model refinement (cmr). compared to prior cl settings, cmr is more practical and introduces unique challenges (boundary-agnostic and non-stationary distribution shift, diverse mixtures of multiple ood data clusters, error-centric streams, etc.). we extend several existing cl approaches to the cmr setting and evaluate them extensively. for benchmarking and analysis, we propose a general sampling algorithm to obtain dynamic ood data streams with controllable non-stationarity, as well as a suite of metrics measuring various aspects of online performance. our experiments and detailed analysis reveal the promise and challenges of the cmr problem, supporting that studying cmr in dynamic ood streams can benefit the longevity of deployed nlp models in production."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,                                                                        ,2022-05-04 ,           ,"['bill yuchen lin', 'sida wang', 'xi victoria lin', 'robin jia', 'lin xiao', 'xiang ren', 'wen-tau yih']"
2205.02052 ,exploring rawlsian fairness for k-means clustering                                                                                                                                      ,cs.lg                                                    ,"we conduct an exploratory study that looks at incorporating john rawls' ideas on fairness into existing unsupervised machine learning algorithms. our focus is on the task of clustering, specifically the k-means clustering algorithm. to the best of our knowledge, this is the first work that uses rawlsian ideas in clustering. towards this, we attempt to develop a postprocessing technique i.e., one that operates on the cluster assignment generated by the standard k-means clustering algorithm. our technique perturbs this assignment over a number of iterations to make it fairer according to rawls' difference principle while minimally affecting the overall utility. as the first step, we consider two simple perturbation operators -- $\mathbf{r_1}$ and $\mathbf{r_2}$ -- that reassign examples in a given cluster assignment to new clusters; $\mathbf{r_1}$ assigning a single example to a new cluster, and $\mathbf{r_2}$ a pair of examples to new clusters. our experiments on a sample of the adult dataset demonstrate that both operators make meaningful perturbations in the cluster assignment towards incorporating rawls' difference principle, with $\mathbf{r_2}$ being more efficient than $\mathbf{r_1}$ in terms of the number of iterations. however, we observe that there is still a need to design operators that make significantly better perturbations. nevertheless, both operators provide good baselines for designing and comparing any future operator, and we hope our findings would aid future work in this direction."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,                                                                        ,2022-05-04 ,           ,"['stanley simoes', 'deepak p', 'muiris maccarthaigh']"
2205.02092 ,learning abstract and transferable representations for planning                                                                                                                         ,cs.lg cs.ai                                              ,"we are concerned with the question of how an agent can acquire its own representations from sensory data. we restrict our focus to learning representations for long-term planning, a class of problems that state-of-the-art learning methods are unable to solve. we propose a framework for autonomously learning state abstractions of an agent's environment, given a set of skills. importantly, these abstractions are task-independent, and so can be reused to solve new tasks. we demonstrate how an agent can use an existing set of options to acquire representations from ego- and object-centric observations. these abstractions can immediately be reused by the same agent in new environments. we show how to combine these portable representations with problem-specific ones to generate a sound description of a specific task that can be used for abstract planning. finally, we show how to autonomously construct a multi-level hierarchy consisting of increasingly abstract representations. since these hierarchies are transferable, higher-order concepts can be reused in new tasks, relieving the agent from relearning them and improving sample efficiency. our results demonstrate that our approach allows an agent to transfer previous knowledge to new tasks, improving sample efficiency as the number of tasks increases."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,                                                                        ,2022-05-04 ,           ,"['steven james', 'benjamin rosman', 'george konidaris']"
2205.02101 ,dynamic sparse r-cnn                                                                                                                                                                    ,cs.cv cs.ai cs.lg                                        ,"sparse r-cnn is a recent strong object detection baseline by set prediction on sparse, learnable proposal boxes and proposal features. in this work, we propose to improve sparse r-cnn with two dynamic designs. first, sparse r-cnn adopts a one-to-one label assignment scheme, where the hungarian algorithm is applied to match only one positive sample for each ground truth. such one-to-one assignment may not be optimal for the matching between the learned proposal boxes and ground truths. to address this problem, we propose dynamic label assignment (dla) based on the optimal transport algorithm to assign increasing positive samples in the iterative training stages of sparse r-cnn. we constrain the matching to be gradually looser in the sequential stages as the later stage produces the refined proposals with improved precision. second, the learned proposal boxes and features remain fixed for different images in the inference process of sparse r-cnn. motivated by dynamic convolution, we propose dynamic proposal generation (dpg) to assemble multiple proposal experts dynamically for providing better initial proposal boxes and features for the consecutive training stages. dpg thereby can derive sample-dependent proposal boxes and features for inference. experiments demonstrate that our method, named dynamic sparse r-cnn, can boost the strong sparse r-cnn baseline with different backbones for object detection. particularly, dynamic sparse r-cnn reaches the state-of-the-art 47.2% ap on the coco 2017 validation set, surpassing sparse r-cnn by 2.2% ap with the same resnet-50 backbone."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,                                                                        ,2022-05-04 ,           ,"['qinghang hong', 'fengming liu', 'dong li', 'ji liu', 'lu tian', 'yi shan']"
2205.02102 ,concept activation vectors for generating user-defined 3d shapes                                                                                                                        ,cs.cv cs.gr cs.lg                                        ,"we explore the interpretability of 3d geometric deep learning models in the context of computer-aided design (cad). the field of parametric cad can be limited by the difficulty of expressing high-level design concepts in terms of a few numeric parameters. in this paper, we use a deep learning architectures to encode high dimensional 3d shapes into a vectorized latent representation that can be used to describe arbitrary concepts. specifically, we train a simple auto-encoder to parameterize a dataset of complex shapes. to understand the latent encoded space, we use the idea of concept activation vectors (cav) to reinterpret the latent space in terms of user-defined concepts. this allows modification of a reference design to exhibit more or fewer characteristics of a chosen concept or group of concepts. we also test the statistical significance of the identified concepts and determine the sensitivity of a physical quantity of interest across the dataset."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ,                                                                        ,2022-04-29 ,           ,"['stefan druc', 'aditya balu', 'peter wooldridge', 'adarsh krishnamurthy', 'soumik sarkar']"
2205.02103 ,efficient accelerator for dilated and transposed convolution with   decomposition                                                                                                       ,cs.ar cs.lg                                              ,"hardware acceleration for dilated and transposed convolution enables real time execution of related tasks like segmentation, but current designs are specific for these convolutional types or suffer from complex control for reconfigurable designs. this paper presents a design that decomposes input or weight for dilated and transposed convolutions respectively to skip redundant computations and thus executes efficiently on existing dense cnn hardware as well. the proposed architecture can cut down 87.8\% of the cycle counts to achieve 8.2x speedup over a naive execution for the enet case."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ,10.1109/iscas45731.2020.9180402                                         ,2022-05-02 ,           ,"['kuo-wei chang', 'tian-sheuan chang']"
2205.02107 ,prediction of fish location by combining fisheries data and sea bottom   temperature forecasting                                                                                        ,cs.cv cs.lg                                              ,"this paper combines fisheries dependent data and environmental data to be used in a machine learning pipeline to predict the spatio-temporal abundance of two species (plaice and sole) commonly caught by the belgian fishery in the north sea. by combining fisheries related features with environmental data, sea bottom temperature derived from remote sensing, a higher accuracy can be achieved. in a forecast setting, the predictive accuracy is further improved by predicting, using a recurrent deep neural network, the sea bottom temperature up to four days in advance instead of relying on the last previous temperature measurement."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2022-05-04 ,           ,"['matthieu ospici', 'klaas sys', 'sophie guegan-marat']"
2205.02108 ,using deep reinforcement learning to solve optimal power flow problem   with generator failures                                                                                         ,cs.lg cs.ai                                              ,"deep reinforcement learning (drl) is being used in many domains. one of the biggest advantages of drl is that it enables the continuous improvement of a learning agent. secondly, the drl framework is robust and flexible enough to be applicable to problems of varying nature and domain. presented work is evidence of using the drl technique to solve an optimal power flow (opf) problem. two classical algorithms have been presented to solve the opf problem. the drawbacks of the vanilla drl application are discussed, and an algorithm is suggested to improve the performance. secondly, a reward function for the opf problem is presented that enables the solution of inherent issues in drl. reasons for divergence and degeneration in drl are discussed, and the correct strategy to deal with them with respect to opf is presented."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,                                                                        ,2022-05-04 ,           ,['muhammad usman awais']
2205.02113 ,predicting vacant parking space availability zone-wisely: a graph based   spatio-temporal prediction approach                                                                           ,cs.lg                                                    ,"vacant parking space (vps) prediction is one of the key issues of intelligent parking guidance systems. accurately predicting vps information plays a crucial role in intelligent parking guidance systems, which can help drivers find parking space quickly, reducing unnecessary waste of time and excessive environmental pollution. through the simple analysis of historical data, we found that there not only exists a obvious temporal correlation in each parking lot, but also a clear spatial correlation between different parking lots. in view of this, this paper proposed a graph data-based model st-gbgru (spatial-temporal graph based gated recurrent unit), the number of vpss can be predicted both in short-term (i.e., within 30 min) and in long-term (i.e., over 30min). on the one hand, the temporal correlation of historical vps data is extracted by gru, on the other hand, the spatial correlation of historical vps data is extracted by gcn inside gru. two prediction methods, namely direct prediction and iterative prediction, are combined with the proposed model. finally, the prediction model is applied to predict the number vpss of 8 public parking lots in santa monica. the results show that in the short-term and long-term prediction tasks, st-gbgru model can achieve high accuracy and have good application prospects."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,                                                                        ,2022-05-03 ,           ,"['yajing feng', 'qian hu', 'zhenzhou tang']"
2205.02115 ,axonal delay as a short-term memory for feed forward deep spiking neural   networks                                                                                                     ,cs.ne cs.ai cs.lg q-bio.nc                               ,"the information of spiking neural networks (snns) are propagated between the adjacent biological neuron by spikes, which provides a computing paradigm with the promise of simulating the human brain. recent studies have found that the time delay of neurons plays an important role in the learning process. therefore, configuring the precise timing of the spike is a promising direction for understanding and improving the transmission process of temporal information in snns. however, most of the existing learning methods for spiking neurons are focusing on the adjustment of synaptic weight, while very few research has been working on axonal delay. in this paper, we verify the effectiveness of integrating time delay into supervised learning and propose a module that modulates the axonal delay through short-term memory. to this end, a rectified axonal delay (rad) module is integrated with the spiking model to align the spike timing and thus improve the characterization learning ability of temporal features. experiments on three neuromorphic benchmark datasets : nmnist, dvs gesture and n-tidigits18 show that the proposed method achieves the state-of-the-art performance while using the fewest parameters."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,                                                                        ,2022-04-20 ,           ,"['pengfei sun', 'longwei zhu', 'dick botteldooren']"
2205.02116 ,optimizing one-pixel black-box adversarial attacks                                                                                                                                      ,cs.cr cs.lg                                              ,"the output of deep neural networks (dnn) can be altered by a small perturbation of the input in a black box setting by making multiple calls to the dnn. however, the high computation and time required makes the existing approaches unusable. this work seeks to improve the one-pixel (few-pixel) black-box adversarial attacks to reduce the number of calls to the network under attack. the one-pixel attack uses a non-gradient optimization algorithm to find pixel-level perturbations under the constraint of a fixed number of pixels, which causes the network to predict the wrong label for a given image. we show through experimental results how the choice of the optimization algorithm and initial positions to search can reduce function calls and increase attack success significantly, making the attack more practical in real-world settings."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ,                                                                        ,2022-04-30 ,           ,"['tianxun zhou', 'shubhankar agrawal', 'prateek manocha']"
2205.02119 ,processing network controls via deep reinforcement learning                                                                                                                             ,math.oc cs.ai cs.lg                                      ,"novel advanced policy gradient (apg) algorithms, such as proximal policy optimization (ppo), trust region policy optimization, and their variations, have become the dominant reinforcement learning (rl) algorithms because of their ease of implementation and good practical performance. this dissertation is concerned with theoretical justification and practical application of the apg algorithms for solving processing network control optimization problems. processing network control problems are typically formulated as markov decision process (mdp) or semi-markov decision process (smdp) problems that have several unconventional for rl features: infinite state spaces, unbounded costs, long-run average cost objectives. policy improvement bounds play a crucial role in the theoretical justification of the apg algorithms. in this thesis we refine existing bounds for mdps with finite state spaces and prove novel policy improvement bounds for classes of mdps and smdps used to model processing network operations. we consider two examples of processing network control problems and customize the ppo algorithm to solve them. first, we consider parallel-server and multiclass queueing networks controls. second, we consider the drivers repositioning problem in a ride-hailing service system. for both examples the ppo algorithm with auxiliary modifications consistently generates control policies that outperform state-of-art heuristics."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ,                                                                        ,2022-05-01 ,           ,['mark gluzman']
2205.02121 ,accelerating phase-field-based simulation via machine learning                                                                                                                          ,cond-mat.mtrl-sci cs.lg physics.comp-ph                  ,"phase-field-based models have become common in material science, mechanics, physics, biology, chemistry, and engineering for the simulation of microstructure evolution. yet, they suffer from the drawback of being computationally very costly when applied to large, complex systems. to reduce such computational costs, a unet-based artificial neural network is developed as a surrogate model in the current work. training input for this network is obtained from the results of the numerical solution of initial-boundary-value problems (ibvps) based on the fan-chen model for grain microstructure evolution. in particular, about 250 different simulations with varying initial order parameters are carried out and 200 frames of the time evolution of the phase fields are stored for each simulation. the network is trained with 90% of this data, taking the $i$-th frame of a simulation, i.e. order parameter field, as input, and producing the $(i+1)$-th frame as the output. evaluation of the network is carried out with a test dataset consisting of 2200 microstructures based on different configurations than originally used for training. the trained network is applied recursively on initial order parameters to calculate the time evolution of the phase fields. the results are compared to the ones obtained from the conventional numerical solution in terms of the errors in order parameters and the system's free energy. the resulting order parameter error averaged over all points and all simulation cases is 0.005 and the relative error in the total free energy in all simulation boxes does not exceed 1%."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,                                                                        ,2022-05-04 ,           ,"['iman peivaste', 'nima h. siboni', 'ghasem alahyarizadeh', 'reza ghaderi', 'bob svendsen', 'dierk raabe', 'jaber r. mianroodi']"
2205.02130 ,the limits of word level differential privacy                                                                                                                                           ,cs.cr cs.cl cs.lg                                        ,"as the issues of privacy and trust are receiving increasing attention within the research community, various attempts have been made to anonymize textual data. a significant subset of these approaches incorporate differentially private mechanisms to perturb word embeddings, thus replacing individual words in a sentence. while these methods represent very important contributions, have various advantages over other techniques and do show anonymization capabilities, they have several shortcomings. in this paper, we investigate these weaknesses and demonstrate significant mathematical constraints diminishing the theoretical privacy guarantee as well as major practical shortcomings with regard to the protection against deanonymization attacks, the preservation of content of the original sentences as well as the quality of the language output. finally, we propose a new method for text anonymization based on transformer based language models fine-tuned for paraphrasing that circumvents most of the identified weaknesses and also offers a formal privacy guarantee. we evaluate the performance of our method via thorough experimentation and demonstrate superior performance over the discussed mechanisms."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2022-05-02 ,           ,"['justus mattern', 'benjamin weggenmann', 'florian kerschbaum']"
2205.02151 ,dual cross-attention learning for fine-grained visual categorization and   object re-identification                                                                                     ,cs.cv cs.ai cs.lg                                        ,"recently, self-attention mechanisms have shown impressive performance in various nlp and cv tasks, which can help capture sequential characteristics and derive global information. in this work, we explore how to extend self-attention modules to better learn subtle feature embeddings for recognizing fine-grained objects, e.g., different bird species or person identities. to this end, we propose a dual cross-attention learning (dcal) algorithm to coordinate with self-attention learning. first, we propose global-local cross-attention (glca) to enhance the interactions between global images and local high-response regions, which can help reinforce the spatial-wise discriminative clues for recognition. second, we propose pair-wise cross-attention (pwca) to establish the interactions between image pairs. pwca can regularize the attention learning of an image by treating another image as distractor and will be removed during inference. we observe that dcal can reduce misleading attentions and diffuse the attention response to discover more complementary parts for recognition. we conduct extensive evaluations on fine-grained visual categorization and object re-identification. experiments demonstrate that dcal performs on par with state-of-the-art methods and consistently improves multiple self-attention baselines, e.g., surpassing deit-tiny and vit-base by 2.8% and 2.4% map on msmt17, respectively."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,                                                                        ,2022-05-04 ,           ,"['haowei zhu', 'wenjing ke', 'dong li', 'ji liu', 'lu tian', 'yi shan']"
2205.02191 ,wavelet neural operator: a neural operator for parametric partial   differential equations                                                                                              ,physics.comp-ph cs.lg                                    ,"with massive advancements in sensor technologies and internet-of-things, we now have access to terabytes of historical data; however, there is a lack of clarity in how to best exploit the data to predict future events. one possible alternative in this context is to utilize operator learning algorithm that directly learn nonlinear mapping between two functional spaces; this facilitates real-time prediction of naturally arising complex evolutionary dynamics. in this work, we introduce a novel operator learning algorithm referred to as the wavelet neural operator (wno) that blends integral kernel with wavelet transformation. wno harnesses the superiority of the wavelets in time-frequency localization of the functions and enables accurate tracking of patterns in spatial domain and effective learning of the functional mappings. since the wavelets are localized in both time/space and frequency, wno can provide high spatial and frequency resolution. this offers learning of the finer details of the parametric dependencies in the solution for complex problems. the efficacy and robustness of the proposed wno are illustrated on a wide array of problems involving burger's equation, darcy flow, navier-stokes equation, allen-cahn equation, and wave advection equation. comparative study with respect to existing operator learning frameworks are presented. finally, the proposed approach is used to build a digital twin capable of predicting earth's air temperature based on available historical data."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,                                                                        ,2022-05-04 ,           ,"['tapas tripura', 'souvik chakraborty']"
2205.02209 ,semi-supervised cascaded clustering for classification of noisy label   data                                                                                                            ,cs.lg cs.ai                                              ,"the performance of supervised classification techniques often deteriorates when the data has noisy labels. even the semi-supervised classification approaches have largely focused only on the problem of handling missing labels. most of the approaches addressing the noisy label data rely on deep neural networks (dnn) that require huge datasets for classification tasks. this poses a serious challenge especially in process and manufacturing industries, where the data is limited and labels are noisy. we propose a semi-supervised cascaded clustering (sscc) algorithm to extract patterns and generate a cascaded tree of classes in such datasets. a novel cluster evaluation matrix (cem) with configurable hyperparameters is introduced to localize and eliminate the noisy labels and invoke a pruning criterion on cascaded clustering. the algorithm reduces the dependency on expensive human expertise for assessing the accuracy of labels. a classifier generated based on sscc is found to be accurate and consistent even when trained on noisy label datasets. it performed better in comparison with the support vector machines (svm) when tested on multiple noisy-label datasets, including an industrial dataset. the proposed approach can be effectively used for deriving actionable insights in industrial settings with minimal human expertise."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ,                                                                        ,2022-05-04 ,           ,"['ashit gupta', 'anirudh deodhar', 'tathagata mukherjee', 'venkataramana runkana']"
2205.02264 ,deepbayes -- an estimator for parameter estimation in stochastic   nonlinear dynamical models                                                                                           ,stat.ml cs.lg cs.sy eess.sy math.oc                      ,"stochastic nonlinear dynamical systems are ubiquitous in modern, real-world applications. yet, estimating the unknown parameters of stochastic, nonlinear dynamical models remains a challenging problem. the majority of existing methods employ maximum likelihood or bayesian estimation. however, these methods suffer from some limitations, most notably the substantial computational time for inference coupled with limited flexibility in application. in this work, we propose deepbayes estimators that leverage the power of deep recurrent neural networks in learning an estimator. the method consists of first training a recurrent neural network to minimize the mean-squared estimation error over a set of synthetically generated data using models drawn from the model set of interest. the a priori trained estimator can then be used directly for inference by evaluating the network with the estimation data. the deep recurrent neural network architectures can be trained offline and ensure significant time savings during inference. we experiment with two popular recurrent neural networks -- long short term memory network (lstm) and gated recurrent unit (gru). we demonstrate the applicability of our proposed method on different example models and perform detailed comparisons with state-of-the-art approaches. we also provide a study on a real-world nonlinear benchmark problem. the experimental evaluations show that the proposed approach is asymptotically as good as the bayes estimator."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,                                                                        ,2022-05-04 ,           ,"['anubhab ghosh', 'mohamed abdalmoaty', 'saikat chatterjee', 'håkan hjalmarsson']"
2205.02267 ,time shifts to reduce the size of reservoir computers                                                                                                                                   ,cs.ne cs.lg                                              ,"a reservoir computer is a type of dynamical system arranged to do computation. typically, a reservoir computer is constructed by connecting a large number of nonlinear nodes in a network that includes recurrent connections. in order to achieve accurate results, the reservoir usually contains hundreds to thousands of nodes. this high dimensionality makes it difficult to analyze the reservoir computer using tools from dynamical systems theory. additionally, the need to create and connect large numbers of nonlinear nodes makes it difficult to design and build analog reservoir computers that can be faster and consume less power than digital reservoir computers. we demonstrate here that a reservoir computer may be divided into two parts; a small set of nonlinear nodes (the reservoir), and a separate set of time-shifted reservoir output signals. the time-shifted output signals serve to increase the rank and memory of the reservoir computer, and the set of nonlinear nodes may create an embedding of the input dynamical system. we use this time-shifting technique to obtain excellent performance from an opto-electronic delay-based reservoir computer with only a small number of virtual nodes. because only a few nonlinear nodes are required, construction of a reservoir computer becomes much easier, and delay-based reservoir computers can operate at much higher speeds."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,                                                                        ,2022-05-03 ,           ,"['thomas l. carroll', 'joseph d. hart']"
2205.02269 ,fine-grained address segmentation for attention-based variable-degree   prefetching                                                                                                     ,cs.ar cs.lg                                              ,"machine learning algorithms have shown potential to improve prefetching performance by accurately predicting future memory accesses. existing approaches are based on the modeling of text prediction, considering prefetching as a classification problem for sequence prediction. however, the vast and sparse memory address space leads to large vocabulary, which makes this modeling impractical. the number and order of outputs for multiple cache line prefetching are also fundamentally different from text prediction. we propose transfetch, a novel way to model prefetching. to reduce vocabulary size, we use fine-grained address segmentation as input. to predict unordered sets of future addresses, we use delta bitmaps for multiple outputs. we apply an attention-based network to learn the mapping between input and output. prediction experiments demonstrate that address segmentation achieves 26% - 36% higher f1-score than delta inputs and 15% - 24% higher f1-score than page & offset inputs for spec 2006, spec 2017, and gap benchmarks. simulation results show that transfetch achieves 38.75% ipc improvement compared with no prefetching, outperforming the best-performing rule-based prefetcher bop by 10.44%, and ml-based prefetcher voyager by 6.64%."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,10.1145/3528416.3530236                                                 ,2022-05-01 ,           ,"['pengmiao zhang', 'ajitesh srivastava', 'anant v. nori', 'rajgopal kannan', 'viktor k. prasanna']"
2205.02283 ,pyrdf2vec: a python implementation and extension of rdf2vec                                                                                                                             ,cs.lg                                                    ,"this paper introduces pyrdf2vec, a python software package that reimplements the well-known rdf2vec algorithm along with several of its extensions. by making the algorithm available in the most popular data science language, and by bundling all extensions into a single place, the use of rdf2vec is simplified for data scientists. the package is released under a mit license and structured in such a way to foster further research into sampling, walking, and embedding strategies, which are vital components of the rdf2vec algorithm. several optimisations have been implemented in \texttt{pyrdf2vec} that allow for more efficient walk extraction than the original algorithm. furthermore, best practices in terms of code styling, testing, and documentation were applied such that the package is future-proof as well as to facilitate external contributions."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,                                                                        ,2022-05-04 ,           ,"['gilles vandewiele', 'bram steenwinckel', 'terencio agozzino', 'femke ongenae']"
2205.02318 ,language models in the loop: incorporating prompting into weak   supervision                                                                                                            ,cs.lg cs.cl                                              ,"we propose a new strategy for applying large pre-trained language models to novel tasks when labeled training data is limited. rather than apply the model in a typical zero-shot or few-shot fashion, we treat the model as the basis for labeling functions in a weak supervision framework. to create a classifier, we first prompt the model to answer multiple distinct queries about an example and define how the possible responses should be mapped to votes for labels and abstentions. we then denoise these noisy label sources using the snorkel system and train an end classifier with the resulting training data. our experimental evaluation shows that prompting large language models within a weak supervision framework can provide significant gains in accuracy. on the wrench weak supervision benchmark, this approach can significantly improve over zero-shot performance, an average 19.5% reduction in errors. we also find that this approach produces classifiers with comparable or superior accuracy to those trained from hand-engineered rules."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ,                                                                        ,2022-05-04 ,           ,"['ryan smith', 'jason a. fries', 'braden hancock', 'stephen h. bach']"
2205.02329 ,second-order sensitivity analysis for bilevel optimization                                                                                                                              ,math.oc cs.lg                                            ,"in this work we derive a second-order approach to bilevel optimization, a type of mathematical programming in which the solution to a parameterized optimization problem (the ""lower"" problem) is itself to be optimized (in the ""upper"" problem) as a function of the parameters. many existing approaches to bilevel optimization employ first-order sensitivity analysis, based on the implicit function theorem (ift), for the lower problem to derive a gradient of the lower problem solution with respect to its parameters; this ift gradient is then used in a first-order optimization method for the upper problem. this paper extends this sensitivity analysis to provide second-order derivative information of the lower problem (which we call the ift hessian), enabling the usage of faster-converging second-order optimization methods at the upper level. our analysis shows that (i) much of the computation already used to produce the ift gradient can be reused for the ift hessian, (ii) errors bounds derived for the ift gradient readily apply to the ift hessian, (iii) computing ift hessians can significantly reduce overall computation by extracting more information from each lower level solve. we corroborate our findings and demonstrate the broad range of applications of our method by applying it to problem instances of least squares hyperparameter auto-tuning, multi-class svm auto-tuning, and inverse optimal control."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ,                                                                        ,2022-05-04 ,           ,"['robert dyro', 'edward schmerling', 'nikos arechiga', 'marco pavone']"
2205.02333 ,equity and fairness of bayesian knowledge tracing                                                                                                                                       ,cs.lg                                                    ,"we consider the equity and fairness of curricula derived from knowledge tracing models. we begin by defining a unifying notion of an equitable tutoring system as a system that achieves maximum possible knowledge in minimal time for each student interacting with it. realizing perfect equity requires tutoring systems that can provide individualized curricula per student. in particular, we investigate the design of equitable tutoring systems that derive their curricula from knowledge tracing models. we first show that many existing models, including classical bayesian knowledge tracing (bkt) and deep knowledge tracing (dkt), and their derived curricula can fall short of achieving equitable tutoring. to overcome this issue, we then propose a novel model, bayesian-bayesian knowledge tracing (bbkt), that naturally enables online individualization and, thereby, more equitable tutoring. we demonstrate that curricula derived from our model are more effective and equitable than those derived from classical bkt models. furthermore, we highlight that improving models with a focus on the fairness of next-step predictions might be insufficient to develop equitable tutoring systems."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,                                                                        ,2022-05-04 ,           ,"['sebastian tschiatschek', 'maria knobelsdorf', 'adish singla']"
2205.02340 ,knowledge distillation of russian language models with reduction of   vocabulary                                                                                                        ,cs.cl cs.lg                                              ,"today, transformer language models serve as a core component for majority of natural language processing tasks. industrial application of such models requires minimization of computation time and memory footprint. knowledge distillation is one of approaches to address this goal. existing methods in this field are mainly focused on reducing the number of layers or dimension of embeddings/hidden representations. alternative option is to reduce the number of tokens in vocabulary and therefore the embeddings matrix of the student model. the main problem with vocabulary minimization is mismatch between input sequences and output class distributions of a teacher and a student models. as a result, it is impossible to directly apply kl-based knowledge distillation. we propose two simple yet effective alignment techniques to make knowledge distillation to the students with reduced vocabulary. evaluation of distilled models on a number of common benchmarks for russian such as russian superglue, sberquad, rusentiment, paraphaser, collection-3 demonstrated that our techniques allow to achieve compression from $17\times$ to $49\times$, while maintaining quality of $1.7\times$ compressed student with the full-sized vocabulary, but reduced number of transformer layers only. we make our code and distilled models available."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,                                                                        ,2022-05-04 ,           ,"['alina kolesnikova', 'yuri kuratov', 'vasily konovalov', 'mikhail burtsev']"
2205.02343 ,convolutional and residual networks provably contain lottery tickets                                                                                                                    ,cs.lg cs.ai                                              ,"the lottery ticket hypothesis continues to have a profound practical impact on the quest for small scale deep neural networks that solve modern deep learning tasks at competitive performance. these lottery tickets are identified by pruning large randomly initialized neural networks with architectures that are as diverse as their applications. yet, theoretical insights that attest their existence have been mostly focused on deep fully-connected feed forward networks with relu activation functions. we prove that also modern architectures consisting of convolutional and residual layers that can be equipped with almost arbitrary activation functions can contain lottery tickets with high probability."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,                                                                        ,2022-05-04 ,           ,['rebekka burkholz']
2205.02359 ,fedsplit: one-shot federated recommendation system based on non-negative   joint matrix factorization and knowledge distillation                                                        ,cs.lg cs.ir                                              ,"non-negative matrix factorization (nmf) with missing-value completion is a well-known effective collaborative filtering (cf) method used to provide personalized user recommendations. however, traditional cf relies on the privacy-invasive collection of users' explicit and implicit feedback to build a central recommender model. one-shot federated learning has recently emerged as a method to mitigate the privacy problem while addressing the traditional communication bottleneck of federated learning. in this paper, we present the first unsupervised one-shot federated cf implementation, named fedsplit, based on nmf joint factorization. in our solution, the clients first apply local cf in-parallel to build distinct client-specific recommenders. then, the privacy-preserving local item patterns and biases from each client are shared with the processor to perform joint factorization in order to extract the global item patterns. extracted patterns are then aggregated to each client to build the local models via knowledge distillation. in our experiments, we demonstrate the feasibility of our approach with standard recommendation datasets. fedsplit can obtain similar results than the state of the art (and even outperform it in certain situations) with a substantial decrease in the number of communications."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ,                                                                        ,2022-05-04 ,           ,"['maksim e. eren', 'luke e. richards', 'manish bhattarai', 'roberto yus', 'charles nicholas', 'boian s. alexandrov']"
2205.02360 ,gitrank: a framework to rank github repositories                                                                                                                                        ,cs.se cs.ai cs.lg                                        ,"open-source repositories provide wealth of information and are increasingly being used to build artificial intelligence (ai) based systems to solve problems in software engineering. open-source repositories could be of varying quality levels, and bad-quality repositories could degrade performance of these systems. evaluating quality of open-source repositories, which is not available directly on code hosting sites such as github, is thus important. in this hackathon, we utilize known code quality measures and grimoirelab toolkit to implement a framework, named gitrank, to rank open-source repositories on three different criteria. we discuss our findings and preliminary evaluation in this hackathon report."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2022-05-04 ,           ,['niranjan hasabnis']
2205.02376 ,uncertainty-based non-parametric active peak detection                                                                                                                                  ,cs.it cs.lg eess.sp math.it                              ,"active, non-parametric peak detection is considered. as a use case, active source localization is examined and an uncertainty-based sampling scheme algorithm to effectively localize the peak from a few energy measurements is designed. it is shown that under very mild conditions, the source localization error with $m$ actively chosen energy measurements scales as $o(\log^2 m/m)$. numerically, it is shown that in low-sample regimes, the proposed method enjoys superior performance on several types of data and outperforms the state-of-the-art passive source localization approaches and in the low sample regime, can outperform greedy methods as well."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,                                                                        ,2022-05-04 ,           ,"['praneeth narayanamurthy', 'urbashi mitra']"
2205.02393 ,optimising equal opportunity fairness in model training                                                                                                                                 ,cs.lg cs.cl                                              ,"real-world datasets often encode stereotypes and societal biases. such biases can be implicitly captured by trained models, leading to biased predictions and exacerbating existing societal preconceptions. existing debiasing methods, such as adversarial training and removing protected information from representations, have been shown to reduce bias. however, a disconnect between fairness criteria and training objectives makes it difficult to reason theoretically about the effectiveness of different techniques. in this work, we propose two novel training objectives which directly optimise for the widely-used criterion of {\it equal opportunity}, and show that they are effective in reducing bias while maintaining high performance over two classification tasks."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ,                                                                        ,2022-05-04 ,           ,"['aili shen', 'xudong han', 'trevor cohn', 'timothy baldwin', 'lea frermann']"
2205.02399 ,spot-adaptive knowledge distillation                                                                                                                                                    ,cs.cv cs.ai cs.lg                                        ,"knowledge distillation (kd) has become a well established paradigm for compressing deep neural networks. the typical way of conducting knowledge distillation is to train the student network under the supervision of the teacher network to harness the knowledge at one or multiple spots (i.e., layers) in the teacher network. the distillation spots, once specified, will not change for all the training samples, throughout the whole distillation process. in this work, we argue that distillation spots should be adaptive to training samples and distillation epochs. we thus propose a new distillation strategy, termed spot-adaptive kd (sakd), to adaptively determine the distillation spots in the teacher network per sample, at every training iteration during the whole distillation period. as sakd actually focuses on ""where to distill"" instead of ""what to distill"" that is widely investigated by most existing works, it can be seamlessly integrated into existing distillation methods to further improve their performance. extensive experiments with 10 state-of-the-art distillers are conducted to demonstrate the effectiveness of sakd for improving their distillation performance, under both homogeneous and heterogeneous distillation settings. code is available at https://github.com/zju-vipa/spot-adaptive-pytorch"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,10.1109/tip.2022.3170728                                                ,2022-05-04 ,           ,"['jie song', 'ying chen', 'jingwen ye', 'mingli song']"
2205.02406 ,dangling-aware entity alignment with mixed high-order proximities                                                                                                                       ,cs.cl cs.ai cs.lg                                        ,"we study dangling-aware entity alignment in knowledge graphs (kgs), which is an underexplored but important problem. as different kgs are naturally constructed by different sets of entities, a kg commonly contains some dangling entities that cannot find counterparts in other kgs. therefore, dangling-aware entity alignment is more realistic than the conventional entity alignment where prior studies simply ignore dangling entities. we propose a framework using mixed high-order proximities on dangling-aware entity alignment. our framework utilizes both the local high-order proximity in a nearest neighbor subgraph and the global high-order proximity in an embedding space for both dangling detection and entity alignment. extensive experiments with two evaluation settings shows that our framework more precisely detects dangling entities, and better aligns matchable entities. further investigations demonstrate that our framework can mitigate the hubness problem on dangling-aware entity alignment."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,                                                                        ,2022-05-04 ,           ,"['juncheng liu', 'zequn sun', 'bryan hooi', 'yiwei wang', 'dayiheng liu', 'baosong yang', 'xiaokui xiao', 'muhao chen']"
2205.02441 ,deepextrema: a deep learning approach for forecasting block maxima in   time series data                                                                                                ,cs.lg                                                    ,"accurate forecasting of extreme values in time series is critical due to the significant impact of extreme events on human and natural systems. this paper presents deepextrema, a novel framework that combines a deep neural network (dnn) with generalized extreme value (gev) distribution to forecast the block maximum value of a time series. implementing such a network is a challenge as the framework must preserve the inter-dependent constraints among the gev model parameters even when the dnn is initialized. we describe our approach to address this challenge and present an architecture that enables both conditional mean and quantile prediction of the block maxima. the extensive experiments performed on both real-world and synthetic data demonstrated the superiority of deepextrema compared to other baseline methods."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ,                                                                        ,2022-05-05 ,           ,"['asadullah hill galib', 'andrew mcdonald', 'tyler wilson', 'lifeng luo', 'pang-ning tan']"
2205.02446 ,multi-graph based multi-scenario recommendation in large-scale online   video services                                                                                                  ,cs.ai cs.lg                                              ,"recently, industrial recommendation services have been boosted by the continual upgrade of deep learning methods. however, they still face de-biasing challenges such as exposure bias and cold-start problem, where circulations of machine learning training on human interaction history leads algorithms to repeatedly suggest exposed items while ignoring less-active ones. additional problems exist in multi-scenario platforms, e.g. appropriate data fusion from subsidiary scenarios, which we observe could be alleviated through graph structured data integration via message passing.   in this paper, we present a multi-graph structured multi-scenario recommendation solution, which encapsulates interaction data across scenarios with multi-graph and obtains representation via graph learning. extensive offline and online experiments on real-world datasets are conducted where the proposed method demonstrates an increase of 0.63% and 0.71% in ctr and video views per capita on new users over deployed set of baselines and outperforms regular method in increasing the number of outer-scenario videos by 25% and video watches by 116%, validating its superiority in activating cold videos and enriching target recommendation."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,10.1145/3487553.3524729                                                 ,2022-05-05 ,           ,"['fan zhang', 'qiuying peng', 'yulin wu', 'zheng pan', 'rong zeng', 'da lin', 'yue qi']"
2205.02447 ,a deep learning approach to dst index prediction                                                                                                                                        ,cs.lg                                                    ,"the disturbance storm time (dst) index is an important and useful measurement in space weather research. it has been used to characterize the size and intensity of a geomagnetic storm. a negative dst value means that the earth's magnetic field is weakened, which happens during storms. in this paper, we present a novel deep learning method, called the dst transformer, to perform short-term, 1-6 hour ahead, forecasting of the dst index based on the solar wind parameters provided by the nasa space science data coordinated archive. the dst transformer combines a multi-head attention layer with bayesian inference, which is capable of quantifying both aleatoric uncertainty and epistemic uncertainty when making dst predictions. experimental results show that the proposed dst transformer outperforms related machine learning methods in terms of the root mean square error and r-squared. furthermore, the dst transformer can produce both data and model uncertainty quantification results, which can not be done by the existing methods. to our knowledge, this is the first time that bayesian deep learning has been used for dst index forecasting."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,                                                                        ,2022-05-05 ,           ,"['yasser abduallah', 'jason t. l. wang', 'prianka bose', 'genwei zhang', 'firas gerges', 'haimin wang']"
2205.02453 ,learning to solve vehicle routing problems: a survey                                                                                                                                    ,cs.lg                                                    ,"this paper provides a systematic overview of machine learning methods applied to solve np-hard vehicle routing problems (vrps). recently, there has been a great interest from both machine learning and operations research communities to solve vrps either by pure learning methods or by combining them with the traditional hand-crafted heuristics. we present the taxonomy of the studies for learning paradigms, solution structures, underlying models, and algorithms. we present in detail the results of the state-of-the-art methods demonstrating their competitiveness with the traditional methods. the paper outlines the future research directions to incorporate learning-based solutions to overcome the challenges of modern transportation systems."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2022-05-05 ,           ,"['aigerim bogyrbayeva', 'meraryslan meraliyev', 'taukekhan mustakhov', 'bissenbay dauletbayev']"
2205.02455 ,cogmen: contextualized gnn based multimodal emotion recognition                                                                                                                         ,cs.cl cs.ai cs.lg                                        ,"emotions are an inherent part of human interactions, and consequently, it is imperative to develop ai systems that understand and recognize human emotions. during a conversation involving various people, a person's emotions are influenced by the other speaker's utterances and their own emotional state over the utterances. in this paper, we propose contextualized graph neural network based multimodal emotion recognition (cogmen) system that leverages local information (i.e., inter/intra dependency between speakers) and global information (context). the proposed model uses graph neural network (gnn) based architecture to model the complex dependencies (local and global information) in a conversation. our model gives state-of-the-art (sota) results on iemocap and mosei datasets, and detailed ablation experiments show the importance of modeling information at both levels."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,                                                                        ,2022-05-05 ,           ,"['abhinav joshi', 'ashwani bhat', 'ayush jain', 'atin vikram singh', 'ashutosh modi']"
2205.02460 ,kgtuner: efficient hyper-parameter search for knowledge graph learning                                                                                                                  ,cs.lg                                                    ,"while hyper-parameters (hps) are important for knowledge graph (kg) learning, existing methods fail to search them efficiently. to solve this problem, we first analyze the properties of different hps and measure the transfer ability from small subgraph to the full graph. based on the analysis, we propose an efficient two-stage search algorithm kgtuner, which efficiently explores hp configurations on small subgraph at the first stage and transfers the top-performed configurations for fine-tuning on the large full graph at the second stage. experiments show that our method can consistently find better hps than the baseline algorithms within the same time budget, which achieves {9.1\%} average relative improvement for four embedding models on the large-scale kgs in open graph benchmark."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2022-05-05 ,           ,"['yongqi zhang', 'zhanke zhou', 'quanming yao', 'yong li']"
2205.02466 ,optimal algorithms for mean estimation under local differential privacy                                                                                                                 ,cs.lg cs.cr                                              ,"we study the problem of mean estimation of $\ell_2$-bounded vectors under the constraint of local differential privacy. while the literature has a variety of algorithms that achieve the asymptotically optimal rates for this problem, the performance of these algorithms in practice can vary significantly due to varying (and often large) hidden constants. in this work, we investigate the question of designing the protocol with the smallest variance. we show that privunit (bhowmick et al. 2018) with optimized parameters achieves the optimal variance among a large family of locally private randomizers. to prove this result, we establish some properties of local randomizers, and use symmetrization arguments that allow us to write the optimal randomizer as the optimizer of a certain linear program. these structural results, which should extend to other problems, then allow us to show that the optimal randomizer belongs to the privunit family.   we also develop a new variant of privunit based on the gaussian distribution which is more amenable to mathematical analysis and enjoys the same optimality guarantees. this allows us to establish several useful properties on the exact constants of the optimal error as well as to numerically estimate these constants."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ,                                                                        ,2022-05-05 ,           ,"['hilal asi', 'vitaly feldman', 'kunal talwar']"
2205.02468 ,alignahead: online cross-layer knowledge extraction on graph neural   networks                                                                                                          ,cs.lg cs.ai                                              ,"existing knowledge distillation methods on graph neural networks (gnns) are almost offline, where the student model extracts knowledge from a powerful teacher model to improve its performance. however, a pre-trained teacher model is not always accessible due to training cost, privacy, etc. in this paper, we propose a novel online knowledge distillation framework to resolve this problem. specifically, each student gnn model learns the extracted local structure from another simultaneously trained counterpart in an alternating training procedure. we further develop a cross-layer distillation strategy by aligning ahead one student layer with the layer in different depth of another student model, which theoretically makes the structure information spread over all layers. experimental results on five datasets including ppi, coauthor-cs/physics and amazon-computer/photo demonstrate that the student performance is consistently boosted in our collaborative training framework without the supervision of a pre-trained teacher model. in addition, we also find that our alignahead technique can accelerate the model convergence speed and its effectiveness can be generally improved by increasing the student numbers in training. code is available: https://github.com/guojy-eatstg/alignahead"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,                                                                        ,2022-05-05 ,           ,"['jiongyu guo', 'defang chen', 'can wang']"
2205.02564 ,one size does not fit all: the case for personalised word complexity   models                                                                                                           ,cs.cl cs.ai cs.hc cs.lg                                  ,"complex word identification (cwi) aims to detect words within a text that a reader may find difficult to understand. it has been shown that cwi systems can improve text simplification, readability prediction and vocabulary acquisition modelling. however, the difficulty of a word is a highly idiosyncratic notion that depends on a reader's first language, proficiency and reading experience. in this paper, we show that personal models are best when predicting word complexity for individual readers. we use a novel active learning framework that allows models to be tailored to individuals and release a dataset of complexity annotations and models as a benchmark for further research."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,                                                                        ,2022-05-05 ,           ,"['sian gooding', 'manuel tragut']"
2205.02596 ,natural language inference with self-attention for veracity assessment   of pandemic claims                                                                                             ,cs.cl cs.ai cs.cy cs.lg                                  ,"we present a comprehensive work on automated veracity assessment from dataset creation to developing novel methods based on natural language inference (nli), focusing on misinformation related to the covid-19 pandemic. we first describe the construction of the novel panacea dataset consisting of heterogeneous claims on covid-19 and their respective information sources. the dataset construction includes work on retrieval techniques and similarity measurements to ensure a unique set of claims. we then propose novel techniques for automated veracity assessment based on natural language inference including graph convolutional networks and attention based approaches. we have carried out experiments on evidence retrieval and veracity assessment on the dataset using the proposed techniques and found them competitive with sota methods, and provided a detailed discussion."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,                                                                        ,2022-05-05 ,           ,"['m. arana-catania', 'elena kochkina', 'arkaitz zubiaga', 'maria liakata', 'rob procter', 'yulan he']"
2205.02604 ,holistic approach to measure sample-level adversarial vulnerability and   its utility in building trustworthy systems                                                                   ,cs.cv cs.hc cs.lg stat.ml                                ,"adversarial attack perturbs an image with an imperceptible noise, leading to incorrect model prediction. recently, a few works showed inherent bias associated with such attack (robustness bias), where certain subgroups in a dataset (e.g. based on class, gender, etc.) are less robust than others. this bias not only persists even after adversarial training, but often results in severe performance discrepancies across these subgroups. existing works characterize the subgroup's robustness bias by only checking individual sample's proximity to the decision boundary. in this work, we argue that this measure alone is not sufficient and validate our argument via extensive experimental analysis. it has been observed that adversarial attacks often corrupt the high-frequency components of the input image. we, therefore, propose a holistic approach for quantifying adversarial vulnerability of a sample by combining these different perspectives, i.e., degree of model's reliance on high-frequency features and the (conventional) sample-distance to the decision boundary. we demonstrate that by reliably estimating adversarial vulnerability at the sample level using the proposed holistic metric, it is possible to develop a trustworthy system where humans can be alerted about the incoming samples that are highly likely to be misclassified at test time. this is achieved with better precision when our holistic metric is used over individual measures. to further corroborate the utility of the proposed holistic approach, we perform knowledge distillation in a limited-sample setting. we observe that the student network trained with the subset of samples selected using our combined metric performs better than both the competing baselines, viz., where samples are selected randomly or based on their distances to the decision boundary."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,                                                                        ,2022-05-05 ,           ,"['gaurav kumar nayak', 'ruchit rawal', 'rohit lal', 'himanshu patil', 'anirban chakraborty']"
2205.02618 ,contrastive multi-view hyperbolic hierarchical clustering                                                                                                                               ,cs.lg cs.ai                                              ,"hierarchical clustering recursively partitions data at an increasingly finer granularity. in real-world applications, multi-view data have become increasingly important. this raises a less investigated problem, i.e., multi-view hierarchical clustering, to better understand the hierarchical structure of multi-view data. to this end, we propose a novel neural network-based model, namely contrastive multi-view hyperbolic hierarchical clustering (cmhhc). it consists of three components, i.e., multi-view alignment learning, aligned feature similarity learning, and continuous hyperbolic hierarchical clustering. first, we align sample-level representations across multiple views in a contrastive way to capture the view-invariance information. next, we utilize both the manifold and euclidean similarities to improve the metric property. then, we embed the representations into a hyperbolic space and optimize the hyperbolic embeddings via a continuous relaxation of hierarchical clustering loss. finally, a binary clustering tree is decoded from optimized hyperbolic embeddings. experimental results on five real-world datasets demonstrate the effectiveness of the proposed method and its components."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,                                                                        ,2022-05-05 ,           ,"['fangfei lin', 'bing bai', 'kun bai', 'yazhou ren', 'peng zhao', 'zenglin xu']"
2205.02625 ,ganimator: neural motion synthesis from a single sequence                                                                                                                               ,cs.gr cs.ai cs.cv cs.lg                                  ,"we present ganimator, a generative model that learns to synthesize novel motions from a single, short motion sequence. ganimator generates motions that resemble the core elements of the original motion, while simultaneously synthesizing novel and diverse movements. existing data-driven techniques for motion synthesis require a large motion dataset which contains the desired and specific skeletal structure. by contrast, ganimator only requires training on a single motion sequence, enabling novel motion synthesis for a variety of skeletal structures e.g., bipeds, quadropeds, hexapeds, and more. our framework contains a series of generative and adversarial neural networks, each responsible for generating motions in a specific frame rate. the framework progressively learns to synthesize motion from random noise, enabling hierarchical control over the generated motion content across varying levels of detail. we show a number of applications, including crowd simulation, key-frame editing, style transfer, and interactive control, which all learn from a single input sequence. code and data for this paper are at https://peizhuoli.github.io/ganimator."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ,10.1145/3528223.3530157                                                 ,2022-05-05 ,           ,"['peizhuo li', 'kfir aberman', 'zihan zhang', 'rana hanocka', 'olga sorkine-hornung']"
2205.02637 ,towards fast simulation of environmental fluid mechanics with   multi-scale graph neural networks                                                                                       ,physics.flu-dyn cs.lg                                    ,"numerical simulators are essential tools in the study of natural fluid-systems, but their performance often limits application in practice. recent machine-learning approaches have demonstrated their ability to accelerate spatio-temporal predictions, although, with only moderate accuracy in comparison. here we introduce multiscalegnn, a novel multi-scale graph neural network model for learning to infer unsteady continuum mechanics in problems encompassing a range of length scales and complex boundary geometries. we demonstrate this method on advection problems and incompressible fluid dynamics, both fundamental phenomena in oceanic and atmospheric processes. our results show good extrapolation to new domain geometries and parameters for long-term temporal simulations. simulations obtained with multiscalegnn are between two and four orders of magnitude faster than those on which it was trained."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ,                                                                        ,2022-05-05 ,           ,"['mario lino', 'stathi fotiadis', 'anil a. bharath', 'chris cantwell']"
2205.02666 ,laws: look around and warm-start natural gradient descent for quantum   neural networks                                                                                                 ,quant-ph cs.lg                                           ,"variational quantum algorithms (vqas) have recently received significant attention from the research community due to their promising performance in noisy intermediate-scale quantum computers (nisq). however, vqas run on parameterized quantum circuits (pqc) with randomly initialized parameters are characterized by barren plateaus (bp) where the gradient vanishes exponentially in the number of qubits. in this paper, we first review quantum natural gradient (qng), which is one of the most popular algorithms used in vqa, from the classical first-order optimization point of view. then, we proposed a \underline{l}ook \underline{a}round \underline{w}arm-\underline{s}tart qng (laws) algorithm to mitigate the widespread existing bp issues. laws is a combinatorial optimization strategy taking advantage of model parameter initialization and fast convergence of qng. laws repeatedly reinitializes parameter search space for the next iteration parameter update. the reinitialized parameter search space is carefully chosen by sampling the gradient close to the current optimal. moreover, we present a unified framework (ws-sgd) for integrating parameter initialization techniques into the optimizer. we provide the convergence proof of the proposed framework for both convex and non-convex objective functions based on polyak-lojasiewicz (pl) condition. our experiment results show that the proposed algorithm could mitigate the bp and have better generalization ability in quantum classification problems."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ,                                                                        ,2022-05-05 ,           ,"['zeyi tao', 'jindi wu', 'qi xia', 'qun li']"
2205.02671 ,what is right for me is not yet right for you: a dataset for grounding   relative directions via multi-task learning                                                                    ,cs.cv cs.ai cs.lg                                        ,"understanding spatial relations is essential for intelligent agents to act and communicate in the physical world. relative directions are spatial relations that describe the relative positions of target objects with regard to the intrinsic orientation of reference objects. grounding relative directions is more difficult than grounding absolute directions because it not only requires a model to detect objects in the image and to identify spatial relation based on this information, but it also needs to recognize the orientation of objects and integrate this information into the reasoning process. we investigate the challenging problem of grounding relative directions with end-to-end neural networks. to this end, we provide grid-3d, a novel dataset that features relative directions and complements existing visual question answering (vqa) datasets, such as clevr, that involve only absolute directions. we also provide baselines for the dataset with two established end-to-end vqa models. experimental evaluations show that answering questions on relative directions is feasible when questions in the dataset simulate the necessary subtasks for grounding relative directions. we discover that those subtasks are learned in an order that reflects the steps of an intuitive pipeline for processing relative directions."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,                                                                        ,2022-05-05 ,           ,"['jae hee lee', 'matthias kerzel', 'kyra ahrens', 'cornelius weber', 'stefan wermter']"
2205.02672 ,multi-agent deep reinforcement learning in vehicular occ                                                                                                                                ,cs.lg cs.it cs.ma cs.ni math.it                          ,"optical camera communications (occ) has emerged as a key enabling technology for the seamless operation of future autonomous vehicles. in this paper, we introduce a spectral efficiency optimization approach in vehicular occ. specifically, we aim at optimally adapting the modulation order and the relative speed while respecting bit error rate and latency constraints. as the optimization problem is np-hard problem, we model the optimization problem as a markov decision process (mdp) to enable the use of solutions that can be applied online. we then relaxed the constrained problem by employing lagrange relaxation approach before solving it by multi-agent deep reinforcement learning (drl). we verify the performance of our proposed scheme through extensive simulations and compare it with various variants of our approach and a random method. the evaluation shows that our system achieves significantly higher sum spectral efficiency compared to schemes under comparison."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ,                                                                        ,2022-05-05 ,           ,"['amirul islam', 'leila musavian', 'nikolaos thomos']"
2205.02673 ,on disentangled and locally fair representations                                                                                                                                        ,cs.lg cs.ai                                              ,"we study the problem of performing classification in a manner that is fair for sensitive groups, such as race and gender. this problem is tackled through the lens of disentangled and locally fair representations. we learn a locally fair representation, such that, under the learned representation, the neighborhood of each sample is balanced in terms of the sensitive attribute. for instance, when a decision is made to hire an individual, we ensure that the $k$ most similar hired individuals are racially balanced. crucially, we ensure that similar individuals are found based on attributes not correlated to their race. to this end, we disentangle the embedding space into two representations. the first of which is correlated with the sensitive attribute while the second is not. we apply our local fairness objective only to the second, uncorrelated, representation. through a set of experiments, we demonstrate the necessity of both disentangled and local fairness for obtaining fair and accurate representations. we evaluate our method on real-world settings such as predicting income and re-incarceration rate and demonstrate the advantage of our method."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2022-05-05 ,           ,"['yaron gurovich', 'sagie benaim', 'lior wolf']"
2205.02679 ,"knitcity: a machine learning-based, game-theoretical framework for   prediction assessment and seismic risk policy design"                                                             ,cs.lg cond-mat.dis-nn cond-mat.stat-mech physics.soc-ph  ,"knitted fabric exhibits avalanche-like events when deformed: by analogy with eathquakes, we are interested in predicting these ""knitquakes"". however, as in most analogous seismic models, the peculiar statistics of the corresponding time-series severely jeopardize this endeavour, due to the time intermittence and scale-invariance of these events. but more importantly, such predictions are hard to {\it assess}: depending on the choice of what to predict, the results can be very different and not easily compared. furthermore, forecasting models may be trained with various generic metrics which ignore some important specificities of the problem at hand, in our case seismic risk. finally, these models often do not provide a clear strategy regarding the best way to use these predictions in practice. here we introduce a framework that allows to design, evaluate and compare not only predictors but also decision-making policies: a model seismically active {\it city} subjected to the crackling dynamics observed in the mechanical response of knitted fabric. we thus proceed to study the population of knitcity, introducing a policy through which the mayor of the town can decide to either keep people in, which in case of large events cause human loss, or evacuate the city, which costs a daily fee. the policy only relies on past seismic observations. we construct efficient policies using a reinforcement learning environment and various time-series predictors based on artificial neural networks. by inducing a physically motivated metric on the predictors, this mechanism allows quantitative assessment and comparison of their relevance in the decision-making process."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ,                                                                        ,2022-05-05 ,           ,"['adèle douin', 'j. p. bruneton', 'frédéric lechenault']"
2205.02706 ,sound event classification in an industrial environment: pipe leakage   detection use case                                                                                              ,cs.lg cs.ne cs.sd eess.as                                ,"in this work, a multi-stage machine learning (ml) pipeline is proposed for pipe leakage detection in an industrial environment. as opposed to other industrial and urban environments, the environment under study includes many interfering background noises, complicating the identification of leaks. furthermore, the harsh environmental conditions limit the amount of data collected and impose the use of low-complexity algorithms. to address the environment's constraints, the developed ml pipeline applies multiple steps, each addressing the environment's challenges. the proposed ml pipeline first reduces the data dimensionality by feature selection techniques and then incorporates time correlations by extracting time-based features. the resultant features are fed to a support vector machine (svm) of low-complexity that generalizes well to a small amount of data. an extensive experimental procedure was carried out on two datasets, one with background industrial noise and one without, to evaluate the validity of the proposed pipeline. the svm hyper-parameters and parameters specific to the pipeline steps were tuned as part of the experimental procedure. the best models obtained from the dataset with industrial noise and leaks were applied to datasets without noise and with and without leaks to test their generalizability. the results show that the model produces excellent results with 99\% accuracy and an f1-score of 0.93 and 0.9 for the respective datasets."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ,                                                                        ,2022-05-05 ,           ,"['ibrahim shaer', 'abdallah shami']"
2205.02752 ,"a collection of invited non-archival papers for the conference on   health, inference, and learning (chil) 2022"                                                                       ,cs.lg                                                    ,"a collection of invited non-archival papers for the conference on health, inference, and learning (chil) 2022. this index is incomplete as some authors of invited non-archival presentations opted not to include their papers in this index."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ,                                                                        ,2022-03-28 ,           ,"['gerardo flores', 'george h. chen', 'tom pollard', 'joyce c. ho', 'tristan naumann']"
2205.02760 ,general sum stochastic games with networked information flows                                                                                                                           ,cs.lg                                                    ,"inspired by applications such as supply chain management, epidemics, and social networks, we formulate a stochastic game model that addresses three key features common across these domains: 1) network-structured player interactions, 2) pair-wise mixed cooperation and competition among players, and 3) limited global information toward individual decision-making. in combination, these features pose significant challenges for black box approaches taken by deep learning-based multi-agent reinforcement learning (marl) algorithms and deserve more detailed analysis. we formulate a networked stochastic game with pair-wise general sum objectives and asymmetrical information structure, and empirically explore the effects of information availability on the outcomes of different marl paradigms such as individual learning and centralized learning decentralized execution."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ,                                                                        ,2022-05-05 ,           ,"['sarah h. q. li', 'lillian j. ratliff', 'peeyush kumar']"
2205.02771 ,finding bipartite components in hypergraphs                                                                                                                                             ,cs.ds cs.lg                                              ,"hypergraphs are important objects to model ternary or higher-order relations of objects, and have a number of applications in analysing many complex datasets occurring in practice. in this work we study a new heat diffusion process in hypergraphs, and employ this process to design a polynomial-time algorithm that approximately finds bipartite components in a hypergraph. we theoretically prove the performance of our proposed algorithm, and compare it against the previous state-of-the-art through extensive experimental analysis on both synthetic and real-world datasets. we find that our new algorithm consistently and significantly outperforms the previous state-of-the-art across a wide range of hypergraphs."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2022-05-05 ,           ,"['peter macgregor', 'he sun']"
2205.02807 ,quantum extremal learning                                                                                                                                                               ,quant-ph cs.lg stat.ml                                   ,"we propose a quantum algorithm for `extremal learning', which is the process of finding the input to a hidden function that extremizes the function output, without having direct access to the hidden function, given only partial input-output (training) data. the algorithm, called quantum extremal learning (qel), consists of a parametric quantum circuit that is variationally trained to model data input-output relationships and where a trainable quantum feature map, that encodes the input data, is analytically differentiated in order to find the coordinate that extremizes the model. this enables the combination of established quantum machine learning modelling with established quantum optimization, on a single circuit/quantum computer. we have tested our algorithm on a range of classical datasets based on either discrete or continuous input variables, both of which are compatible with the algorithm. in case of discrete variables, we test our algorithm on synthetic problems formulated based on max-cut problem generators and also considering higher order correlations in the input-output relationships. in case of the continuous variables, we test our algorithm on synthetic datasets in 1d and simple ordinary differential functions. we find that the algorithm is able to successfully find the extremal value of such problems, even when the training dataset is sparse or a small fraction of the input configuration space. we additionally show how the algorithm can be used for much more general cases of higher dimensionality, complex differential equations, and with full flexibility in the choice of both modeling and optimization ansatz. we envision that due to its general framework and simple construction, the qel algorithm will be able to solve a wide variety of applications in different fields, opening up areas of further research."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ,                                                                        ,2022-05-05 ,           ,"['savvas varsamopoulos', 'evan philip', 'herman w. t. van vlijmen', 'sairam menon', 'ann vos', 'natalia dyubankova', 'bert torfs', 'anthony rowe', 'vincent e. elfving']"
2205.02811 ,morphological wobbling can help robots learn                                                                                                                                            ,cs.lg cs.ro                                              ,"we propose to make the physical characteristics of a robot oscillate while it learns to improve its behavioral performance. we consider quantities such as mass, actuator strength, and size that are usually fixed in a robot, and show that when those quantities oscillate at the beginning of the learning process on a simulated 2d soft robot, the performance on a locomotion task can be significantly improved. we investigate the dynamics of the phenomenon and conclude that in our case, surprisingly, a high-frequency oscillation with a large amplitude for a large portion of the learning duration leads to the highest performance benefits. furthermore, we show that morphological wobbling significantly increases exploration of the search space."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ,                                                                        ,2022-05-05 ,           ,"['fabien c. y. benureau', 'jun tani']"
2205.02824 ,rapid locomotion via reinforcement learning                                                                                                                                             ,cs.ro cs.ai cs.lg                                        ,"agile maneuvers such as sprinting and high-speed turning in the wild are challenging for legged robots. we present an end-to-end learned controller that achieves record agility for the mit mini cheetah, sustaining speeds up to 3.9 m/s. this system runs and turns fast on natural terrains like grass, ice, and gravel and responds robustly to disturbances. our controller is a neural network trained in simulation via reinforcement learning and transferred to the real world. the two key components are (i) an adaptive curriculum on velocity commands and (ii) an online system identification strategy for sim-to-real transfer leveraged from prior work. videos of the robot's behaviors are available at: https://agility.csail.mit.edu/"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,                                                                        ,2022-05-05 ,           ,"['gabriel b margolis', 'ge yang', 'kartik paigwar', 'tao chen', 'pulkit agrawal']"
2205.02827 ,identifying cause-and-effect relationships of manufacturing errors using   sequence-to-sequence learning                                                                                ,cs.lg                                                    ,"in car-body production the pre-formed sheet metal parts of the body are assembled on fully-automated production lines. the body passes through multiple stations in succession, and is processed according to the order requirements. the timely completion of orders depends on the individual station-based operations concluding within their scheduled cycle times. if an error occurs in one station, it can have a knock-on effect, resulting in delays on the downstream stations. to the best of our knowledge, there exist no methods for automatically distinguishing between source and knock-on errors in this setting, as well as establishing a causal relation between them. utilizing real-time information about conditions collected by a production data acquisition system, we propose a novel vehicle manufacturing analysis system, which uses deep learning to establish a link between source and knock-on errors. we benchmark three sequence-to-sequence models, and introduce a novel composite time-weighted action metric for evaluating models in this context. we evaluate our framework on a real-world car production dataset recorded by volkswagen commercial vehicles. surprisingly we find that 71.68% of sequences contain either a source or knock-on error. with respect to seq2seq model training, we find that the transformer demonstrates a better performance compared to lstm and gru in this domain, in particular when the prediction range with respect to the durations of future actions is increased."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ,                                                                        ,2022-05-05 ,           ,"['jeff reimer', 'yandong wang', 'sofiane laridi', 'juergen urdich', 'sören wilmsmeier', 'gregory palmer']"
2205.02834 ,fixing malfunctional objects with learned physical simulation and   functional prediction                                                                                               ,cs.cv cs.ai cs.gr cs.lg cs.ro                            ,"this paper studies the problem of fixing malfunctional 3d objects. while previous works focus on building passive perception models to learn the functionality from static 3d objects, we argue that functionality is reckoned with respect to the physical interactions between the object and the user. given a malfunctional object, humans can perform mental simulations to reason about its functionality and figure out how to fix it. inspired by this, we propose fixit, a dataset that contains about 5k poorly-designed 3d physical objects paired with choices to fix them. to mimic humans' mental simulation process, we present fixnet, a novel framework that seamlessly incorporates perception and physical dynamics. specifically, fixnet consists of a perception module to extract the structured representation from the 3d point cloud, a physical dynamics prediction module to simulate the results of interactions on 3d objects, and a functionality prediction module to evaluate the functionality and choose the correct fix. experimental results show that our framework outperforms baseline models by a large margin, and can generalize well to objects with similar interaction types."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2022-05-05 ,           ,"['yining hong', 'kaichun mo', 'li yi', 'leonidas j. guibas', 'antonio torralba', 'joshua b. tenenbaum', 'chuang gan']"
2205.02835 ,contact points discovery for soft-body manipulations with differentiable   physics                                                                                                      ,cs.ro cs.cv cs.gr cs.lg                                  ,"differentiable physics has recently been shown as a powerful tool for solving soft-body manipulation tasks. however, the differentiable physics solver often gets stuck when the initial contact points of the end effectors are sub-optimal or when performing multi-stage tasks that require contact point switching, which often leads to local minima. to address this challenge, we propose a contact point discovery approach (cpdeform) that guides the stand-alone differentiable physics solver to deform various soft-body plasticines. the key idea of our approach is to integrate optimal transport-based contact points discovery into the differentiable physics solver to overcome the local minima from initial contact points or contact switching. on single-stage tasks, our method can automatically find suitable initial contact points based on transport priorities. on complex multi-stage tasks, we can iteratively switch the contact points of end-effectors based on transport priorities. to evaluate the effectiveness of our method, we introduce plasticinelab-m that extends the existing differentiable physics benchmark plasticinelab to seven new challenging multi-stage soft-body manipulation tasks. extensive experimental results suggest that: 1) on multi-stage tasks that are infeasible for the vanilla differentiable physics solver, our approach discovers contact points that efficiently guide the solver to completion; 2) on tasks where the vanilla solver performs sub-optimally or near-optimally, our contact point discovery method performs better than or on par with the manipulation performance obtained with handcrafted contact points."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ,                                                                        ,2022-05-05 ,           ,"['sizhe li', 'zhiao huang', 'tao du', 'hao su', 'joshua b. tenenbaum', 'chuang gan']"
